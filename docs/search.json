[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote sensing learning Diary",
    "section": "",
    "text": "Preface\nThis is a Learning Diary of CASA0023 Remotely Sensing Cities and Environments.\n\n\nAdd more in the future"
  },
  {
    "objectID": "Week_1.html#knowledge-from-the-lecture",
    "href": "Week_1.html#knowledge-from-the-lecture",
    "title": "1  Week_1 Intro to Remote Sensing",
    "section": "1.1 Knowledge From the Lecture",
    "text": "1.1 Knowledge From the Lecture\n\nThis week’s learning journey into the realm of remote sensing, unveiling the intricate world of electromagnetic waves and their interactions with Earth’s surface. Remote sensing, as I’ve learned, involves acquiring information about objects or areas from a distance, typically from aircraft or satellites, and is a vital tool in understanding our planet.\n\n\n1.1.1 Foundational Concepts of Remote Sensing\n\nOne of the foundational concepts we explored was the difference between passive and active remote sensing. Passive remote sensing relies on natural energy, usually from the sun, whereas active remote sensing systems emit their own energy to illuminate objects. This distinction is crucial for understanding the varied applications of remote sensing technologies like LiDAR, radar, and satellite imagery in observing earth’s landscapes, urban areas, and atmospheric conditions.\n\n\n\n\n\nPassive & Active Remote Sensing, Source: Abeer Nazar Abdul-Hameed\n\n\n\n\n\n\n\n1.1.2 Electromagnetic Waves: Core of Remote Sensing\n\nMuch of our learning knowledge focused on electromagnetic waves, the heart of remote sensing. These waves, a form of energy that propagates through electric and magnetic fields, are the backbone of how remote sensors collect data. Remote sensing is based on this principle to detect the reflection of electromagnetic waves by surface objects and their emission of electromagnetic waves, so as to extract information about these objects and complete the identification of objects at a distance.\n\n\n\n1.1.3 Interactions with Earth’s Surface\n\nWe have looked at the complexities of how electromagnetic radiation (EMR) interacts with the Earth’s surface. EMR can be absorbed, transmitted or scattered by the surface and atmosphere. Scattering, in particular, explains phenomena such as the blue colour of the sky or the blackness of the lunar sky due to the absence of an atmosphere.\n\n\n\n1.1.4 Synthetic Aperture Radar (SAR) and its Applications\n\nThe Synthetic Aperture Radar (SAR) was another fascinating topic. SAR’s ability to ‘see through clouds’ using longer wavelengths is revolutionary, offering a consistent observation capability irrespective of weather conditions. This technology’s potential in areas like topography, vegetation analysis, and urban planning is immense, showcasing how advanced remote sensing techniques can overcome environmental challenges\nThe study of SAR data also introduced us to the concept of polarization, a property of electromagnetic waves that describes their oscillation direction. This property is crucial for understanding how radar signals interact with different surface properties and is instrumental in enhancing the efficiency and bandwidth of communications.\n\n\n\n1.1.5 Technical Insights and Data Formats in Remote Sensing\n\nOn the technical side, we learned about the different data formats used in remote sensing, such as GeoTIFF, and the importance of resolutions - spatial, spectral, temporal and radiometric. These resolutions define the quality and type of data acquired, and influence how effectively we can interpret and use the data for various applications such as land cover mapping and environmental monitoring.\nIn the literature, these concepts are used to analyse environmental change, urban development and geological features. Understanding remote sensing data and their interpretation is essential for researchers and policy makers to make informed decisions."
  },
  {
    "objectID": "Week_1.html#application",
    "href": "Week_1.html#application",
    "title": "1  Week_1 Intro to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\n\nThroughout the week, remote sensing technology is a method of observing and analysing the Earth and its atmosphere from a distance using radio waves or other forms of electromagnetic waves. This technology enables imaging and analysis of distant targets in a non-contact manner by collecting and processing electromagnetic wave information from the Earth’s surface and atmosphere. With the development of technology, remote sensing has become an important tool in the field of geographic information science and is widely used in a number of research and practical applications(Q. Zhou 2023). In the field of urban environmental monitoring, remote sensing technology provides an efficient means of monitoring air quality, water quality and land use. Urban sprawl, traffic flow and pollution from industrial activities can be observed and analysed from the air through remote sensing technology, which helps in decision-making for urban planning and environmental protection(J. Zhou 2023).In the area of vegetation monitoring, remote sensing can be used to analyse the health, growth dynamics and coverage of plants, and by analysing reflected and absorbed electromagnetic waves of specific wavelengths, scientists are able to assess important parameters such as the biomass, water content and chlorophyll concentration of vegetation. This information is important for the optimisation of agricultural production, forestry management and ecological conservation(Adhikary et al. 2022a).Geological research has also benefited from the application of remote sensing technology, and by analysing the electromagnetic wave reflection characteristics of the earth’s surface, scientists have been able to identify different rock types, the distribution of mineral deposits and changes in topography and geomorphology. This is of great value for the exploration of mineral resources, the early warning of geological disasters and the monitoring of environmental changes(Torres Gil, Valdelamar Martínez, and Saba 2023).Agriculture is one of the areas in which remote sensing technology is most widely used. In addition to being used for assessing plant health and yield estimation, remote sensing is used to monitor irrigation needs, detect weeds and pests and make weather forecasts. This makes agricultural production more precise and efficient, helping to increase crop yields and reduce resource wastage(Adhikary et al. 2022b).\nIn addition, synthetic aperture radar (SAR) technology, as an advanced remote sensing technology, has a wide range of applications. By using radar waves to penetrate the limitations of cloud cover and lighting conditions, it provides a unique perspective for surface observation. This technology is capable of acquiring high-quality image data under any weather conditions, including dense fog, cloud cover, rain and snow, as well as at night. As a result, SAR has become an important tool for geological exploration, topographic mapping, disaster monitoring and prevention, traffic surveillance, and agricultural and forest monitoring, among other fields.(Hu et al. 2022)。\nSAR systems work by transmitting and receiving microwave signals, using the returned signals to calculate the position, shape and other characteristics of objects on the ground. A key advantage of this active sensing technology is its sensitivity to the type of ground material and moisture content, allowing it to play an important role in monitoring vegetation-covered areas, urban environments and bodies of water, where SAR imagery is unique in analysing surface changes, assessing the impacts of disasters and carrying out environmental monitoring, owing to its unique imaging properties(Navalgund, Jayaraman, and Roy 2007)."
  },
  {
    "objectID": "Week_1.html#reflection",
    "href": "Week_1.html#reflection",
    "title": "1  Week_1 Intro to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nReflecting on the week’s learning, the profound impact of remote sensing on our understanding of the world is truly remarkable. This technology, with its ability to observe and analyse our planet from afar, offers a unique perspective that ground-based observations simply cannot match. It’s like having a bird’s-eye view of the world, which opens up a whole new dimension in comprehending large-scale environmental patterns, urban sprawl, and the intricate dynamics of climate change.\nWhat strikes me the most is how remote sensing serves as a bridge across various disciplines. It’s not confined to the realm of geography or environmental science; rather, it embodies a synergy of physics, engineering, environmental science, and even policy-making. This multidisciplinary approach highlights the collective effort needed to tackle the complex challenges our world faces today. For instance, the data derived from remote sensing technologies play a pivotal role in shaping policies related to urban planning, optimizing agricultural practices, and enhancing disaster management strategies. It underscores the technology’s indispensability in driving sustainable development forward.\nThe rapid advancement in remote sensing technologies is nothing short of astonishing. Innovations such as high-resolution imagery and the capability for real-time data analysis are broadening the horizons of its applications at an unprecedented pace. These advancements are not only improving our current capabilities but are also paving the way for new possibilities in monitoring and managing the Earth’s resources more effectively. This week’s exploration into the world of remote sensing has deepened my appreciation for this powerful tool and its potential to contribute to a more sustainable and informed future."
  },
  {
    "objectID": "Week_1.html#reference",
    "href": "Week_1.html#reference",
    "title": "1  Week_1 Intro to Remote Sensing",
    "section": "1.4 Reference",
    "text": "1.4 Reference\n\n\n\n\nAdhikary, Saju, Benukar Biswas, Manish Kumar Naskar, Bishal Mukherjee, Aditya Pratap Singh, Kousik Atta, Saju Adhikary, et al. 2022a. “Remote Sensing for Agricultural Applications.” In. IntechOpen. https://doi.org/10.5772/intechopen.106876.\n\n\n———, et al. 2022b. “Remote Sensing for Agricultural Applications.” In. IntechOpen. https://doi.org/10.5772/intechopen.106876.\n\n\nHu, Jun, Lei Zhang, Changwook Lee, and Rong Gui. 2022. “Editorial: Advanced Big SAR Data Analytics and Applications.” Frontiers in Environmental Science 10. https://www.frontiersin.org/articles/10.3389/fenvs.2022.1063376.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. https://www.jstor.org/stable/24102069.\n\n\nTorres Gil, Leydy K., David Valdelamar Martínez, and Manuel Saba. 2023. “The Widespread Use of Remote Sensing in Asbestos, Vegetation, Oil and Gas, and Geology Applications.” Atmosphere 14 (1): 172. https://doi.org/10.3390/atmos14010172.\n\n\nZhou, Jianming. 2023. “Application of Remote Sensing Technology in Urban Environment Monitoring.” In. CRC Press.\n\n\nZhou, Qifeng. 2023. “Application of Remote Sensing Technologies in Environmental Monitoring and Geological Surveys.” Applied and Computational Engineering 3 (May): 178–85. https://doi.org/10.54254/2755-2721/3/20230403."
  },
  {
    "objectID": "Week_3.html#knowledge-from-the-lecture",
    "href": "Week_3.html#knowledge-from-the-lecture",
    "title": "3  Week_3 Corrections",
    "section": "3.1 Knowledge From the Lecture",
    "text": "3.1 Knowledge From the Lecture\n\nThis week’s study focuses on remote sensing image processing, with the main areas of interest being geometric corrections, atmospheric corrections, orthometric corrections, radiometric corrections and various image enhancement techniques.\n\n\n3.1.1 Correction\n\n3.1.1.1 Geometric Correction\n\nGeometric correction is the basis of image correction and addresses image distortion due to sensor and other factors. The goal of this correction is to make the image conform to the selected map projection system, adjusting the geometry of the entire image by modelling the relationship between control points (points with known geographic coordinates) on the image and the image coordinates.\n\n\n\n\n\n\nHow Geometric Correction Work, Source: Xiaopeng\n\n\n\n\n\n\n3.1.1.2 Atmospheric Correction\n\nAtmospheric corrections are essential to address distortions and inaccuracies in remotely sensed images caused by variations in the Earth’s atmosphere, sensor angles, and terrain. Several different correction methods were learned in class: Relative Atmospheric Correction, Pseudo-Invariant Correction, Absolute Atmospheric Correction, and Empirical Line Correction.\n\nThe different methods and characteristics of atmospheric correction have been summarised in the table below:\n\n\n\n\n\n\n\n\nMethod\nKey Steps\nFeature\n\n\n\n\nRelative\nSpectrally stable landmarks, linear relations, band operation\nConsistency between images\n\n\nAbsolute\nComplex models for atmospheric effects, surface reflectance\nPrecise, accurate surface information\n\n\nPseudo-Invariant\nHigh-quality reference, PIF, linear regression\nStable reference points, reduce atmospheric effects\n\n\nEmpirical Line\nGround reflectance, average DN values, linear regression\nUtilizes ground data for satellite correction\n\n\n\n\n\n3.1.1.3 Radiometric Correction\n\nThe role of radiometric correction in adjusting the pixel values of satellite imagery to accurately reflect the radiation at the Earth’s surface has been investigated. The main objective of radiometric correction is to convert the raw digital numbers (DN) acquired into physically meaningful units such as radiance or reflectance. This conversion is critical because DN values are arbitrary and can vary between sensors, acquisitions and platforms, making it difficult to consistently compare and analyse data. By converting DN values to radiance or reflectance, radiometric correction enables quantitative measurements and meaningful comparisons between different images and sensors.\n\n\n\n\n\n\nProcess of Radiometric Calibration\n\n\n\n\n\n\n3.1.1.4 Reflection of Collerallation\n\nIn the course of study, certain questions arise as to when atmospheric corrections are needed and whether or not the images we buy or otherwise acquire have been atmospherically corrected. In layman’s terms, if we need to use an image that truly reflects the Sun’s radiation for quantitative inversion or to obtain information about the Earth, accurately identify features, etc., then we need to make an atmospheric correction. When we buy an image, the description document says that it is radiometrically corrected. In fact, this radiometric correction refers to the coarse radiometric correction, which is just a systematic atmospheric correction, which has the same meaning as the systematic geometric correction.\nAt the moment there are many models and methods on the market, since there are how many methods, then there is the problem of method selection. Here is a summary for reference:\n\nif it is a fine quantitative study, then choose the atmospheric correction method based on the radiative transfer model.\nif you are doing dynamic monitoring, then you can choose relative atmospheric correction or simpler methods.\nif the parameters are missing, there is no choice but to choose the simpler method.\n\n\n\n\n\n3.1.2 Data Join Sets/Enhancement\n\n3.1.2.1 Data Join Sets\n\nAn area may need more than one satellite image to be spliced, using mosaic in the R package for the two datasets to be spliced. When selecting images, try to select two images with similar time and date, due to the different date of the image, the image display is different, the reason may be (cloud cover, sunshine), need to use the image increase technique to operate.\n\n\n\n\n3.1.3 Enhancement\n\n3.1.3.1 Ratio\n\nThe ratio is the difference between two spectral bands with a specific spectral response, using CampTown’s data for NDVI (The Normalised Difference Vegetation Index) The Normalised Difference Vegetation Index is based on the fact that healthy and green vegetation reflects more in the near infrared but absorbs in the red wavelengths.\nThis case above can be applied to other index calculations such as NDWI (Normalised Difference Water Index) and NDDI (Normalised Difference Drought Index). These are calculated using the reflectance of different objects in different light waves.\n\n\n\n3.1.3.2 Texture\n\nThe extraction method of texture features is relatively simple, it is to use an active window to slide continuously on the image, calculate the variance, mean, maximum, minimum and the difference between the two and the information entropy in the window, etc., respectively, to form the corresponding texture image, when the spectral characteristics of the target are relatively close to each other, the texture features can play a positive role in distinguishing the target. When the spectral characteristics of the target are close, the texture features can play a positive role in distinguishing the target. After selecting the appropriate dynamic range of the data and extracting the texture features, the texture features of the image can be highlighted, which is conducive to the extraction of constructive information."
  },
  {
    "objectID": "Week_3.html#application",
    "href": "Week_3.html#application",
    "title": "3  Week_3 Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\nImage correction is a key component of remote sensing technology, ensuring that the data we acquire from satellite or aerial imagery is both accurate and useful. As a student, I believe that understanding this process is critical to professional development. Radiometric correction is the first step, which adjusts image data to correct for errors due to sensor noise, response variations, or atmospheric conditions. For example, the method proposed by Duan(2014) utilises standard ground objects to achieve accurate correction without relying on artificial targets. On the other hand, the method developed by Tarasenkov(2019) enhances the accuracy of atmospheric correction by taking into account the effects of radiative polarisation.\nGeometric correction, on the other hand, is another key technique that ensures consistent image scale, which is essential for accurate map production and measurement. This correction helps to remove spatial distortions, align images, and even stitch multiple images into a complete view. For example, Yan et al. (2023) emphasised its importance in accurate mapping, while Özciğan et al. (2023) demonstrated advances based on orthogonal images and homonymous point matching techniques, which have greatly improved the geometric accuracy of images.\nAtmospheric correction is essential to ensure the accuracy and reliability of remote sensing applications by optimising the image data by correcting the effects of atmospheric disturbances. Various algorithms have been developed and evaluated to improve the performance of this correction process, such as 6S, FLAASH, DOS, etc. These techniques are not only critical for remote sensing analysis, but also have a wide range of applications in areas such as aircraft navigation and astronomical observation.\nImage enhancement technology aims to improve the quality and visual effect of remote sensing images. Various methods have been proposed to enhance these images, including histogram modification, transform domain methods, and hybrid approaches. Histogram modification methods focus on modifying the histogram of the input image to achieve a more uniform distribution, resulting in better contrast improvement. Transform domain methods apply specific transforms to enhance the image in the transform domain, leading to better edge enhancement and color preservation(Wang et al. 2023). Hybrid methods, which combine histogram modification and transform domain methods, have shown higher potential in enhancing remote sensing images(Deng et al. 2023). These enhancement techniques are crucial for image interpretation, improving image segmentation accuracy, and facilitating downstream tasks."
  },
  {
    "objectID": "Week_3.html#reflection",
    "href": "Week_3.html#reflection",
    "title": "3  Week_3 Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\n\nAs a student diving deep into remote sensing image correction technologies, it truly broadened my knowledge and also deepened my understanding of its complexities and challenges. I realized that although these technologies are crucial for enhancing the quality of image data, implementing them is not as straightforward as it might seem. For instance, radiometric correction sounds advanced, but if we lack precise ground objects for reference, the accuracy of the whole process becomes questionable. This got me thinking about whether we need to develop more adaptive correction methods that can adjust to varying conditions.\nThen there’s geometric correction, which indeed seems capable of solving issues with inconsistent image proportions, but if our initial data is not of good quality, or the processing is too complex, how do we balance precision with practical feasibility? It made me realize that sometimes we might need to find a balance between ideal accuracy and operational simplicity.\nWhen it comes to atmospheric correction, I was intrigued by the performance differences of various algorithms under specific conditions. This highlights the importance of selecting the right correction algorithm for reliable data, and also hints at the necessity for more detailed comparisons of algorithms in future research.\nRegarding image enhancement technologies, while they can make images appear clearer, I also began to worry about whether these techniques might inadvertently alter some crucial features in the images. This made me recognize the need to carefully maintain the authenticity of images while pursuing visual improvements.\nOverall, delving into remote sensing image correction technologies not only taught me about the importance of these techniques but also exposed the various challenges that need to be overcome in practical applications. It made me more aware that alongside technological innovation, a careful evaluation and improvement of existing methods are necessary to ensure we can enhance data quality while maintaining operational feasibility and data authenticity."
  },
  {
    "objectID": "Week_3.html#reference",
    "href": "Week_3.html#reference",
    "title": "3  Week_3 Corrections",
    "section": "3.4 Reference",
    "text": "3.4 Reference\n\n\n\n\nDeng, Jiqiu, Wuzhou Dong, Yiwei Guo, Xiaoyan Chen, Renhao Zhou, and Wenyi Liu. 2023. “A Novel Remote Sensing Image Enhancement Method, the Pseudo-Tasseled Cap Transformation: Taking Buildings and Roads in GF-2 as an Example.” Applied Sciences 13 (11): 6585. https://doi.org/10.3390/app13116585.\n\n\nDuan, YL, L. Zhang, L. Yan, Taixia Wu, Yan Liu, and Qiuping Tong. 2014. “Relative Radiometric Correction Methods for Remote Sensing Images and Their Applicability Analysis.” Journal of Remote Sensing 18 (January): 597–617. https://doi.org/10.11834/jrs.20143204.\n\n\nÖzciḣan, Buğrahan, Levent Doğukan Özlü, Mümin İlker Karakap, Halime Sürmeli̇, Ugur Alganci, and Elif Sertel. 2023. “A Comprehensive Analysis of Different Geometric Correction Methods for the Pleiades -1A and Spot-6 Satellite Images.” International Journal of Engineering and Geosciences 8 (2): 146–53. https://doi.org/10.26833/ijeg.1086861.\n\n\nTarasenkov, M. V., A. V. Zimovaya, V. V. Belov, and M. V. Engel. 2019. “25th International Symposium on Atmospheric and Ocean Optics: Atmospheric Physics.” In, 11208:197–202. SPIE. https://doi.org/10.1117/12.2539123.\n\n\nWang, Yu, Zhenfeng Shao, Tao Lu, Changzhi Wu, and Jiaming Wang. 2023. “Remote Sensing Image Super-Resolution via Multiscale Enhancement Network.” IEEE Geoscience and Remote Sensing Letters 20: 1–5. https://doi.org/10.1109/LGRS.2023.3248069.\n\n\nYan, Shi, Liuwei Sheng, Gu Chao, Liu Hui, Zhang Yang, and Huangchun Hao. 2023. “Multi-Source Satellite Remote Sensing Image Processing and Processing Method Based on Geometric Correction Model.” In, edited by Roumen Kountchev, Kazumi Nakamatsu, Wenfeng Wang, and Roumiana Kountcheva, 293–303. Smart Innovation, Systems and Technologies. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-7184-6_26."
  },
  {
    "objectID": "Week_4.html#summary-of-the-policy-and-city",
    "href": "Week_4.html#summary-of-the-policy-and-city",
    "title": "4  Week_4 Flooding Issues In Dublin",
    "section": "4.1 Summary of the Policy and City",
    "text": "4.1 Summary of the Policy and City\n\n4.1.1 Dublin City\n\nDublin’s exposure to flood risk is influenced by a number of factors, including urbanisation and climate change(Paranunzio et al. 2022a). This city on the coast has a complex system of rivers, canals, surface water sewers, sewers and urban watercourses, making it particularly sensitive to flooding. Causes of flooding include sea level rise, runoff water, heavy rainfall, extreme events, storms and tidal fluctuations. Flooding events caused by extreme weather have increased significantly over the last decade and this is expected to continue. It is also expected that the number of days of heavy rainfall per year will increase, leading to an increased risk of fluvial (fluvial) and pluvial (pluvial) flooding(Paranunzio et al. 2022b).\nAlso sea level rise in Dublin is an important consideration. As a result of climate change, Dublin City Council has undertaken a review of existing coastal flood defences to ensure they provide protection for the city region. Records show that average sea levels in Dublin Bay have risen faster than the global average between 2000 and 2016(Shoari Nejad et al. 2022).\n\n\n\n4.1.2 Policy Background\n\nThe Dublin City Development Plan (DCDP) 2016-2022 includes a key component, the Strategic Flood Risk Assessment (SFRA). This plan is intended to guide the direction and location of development in Dublin City over the life of the plan(Dublin City Council 2020a). It provides an integrated and coherent spatial framework to ensure that the city develops in an inclusive manner, whilst enhancing the quality of life for its citizens and making Dublin a more attractive place to live and work. This plan was adopted by Dublin City Council at a special meeting on 23rd September 2016 and came into force on 21st October 2016\nThe Strategic Flood Risk Assessment (SFRA) is Volume 7 of the Dublin City Development Plan (DCDP) and is specifically designed to assess and manage flood risk. The purpose of the assessment is to comply with the requirements of the Floods Directive and flood risk/hazard maps are being produced to enable the development of a comprehensive Flood Risk Management Scheme (FRAMS)(Dublin City Council 2020b). The plan also addresses project-specific flood defense infrastructure to protect the more vulnerable parts of the city.\n\n\n\n\n\nExample of Flood Risk Assessment Map( Liffey: Sean Heuston Br. – Sarah Bridge, South Circular Road), Source: Dublin City Council\n\n\n\n\n\n\n\n\n\nExample of Flood Alleviation Programme ( Liffey: Sean Heuston Br. – Sarah Bridge, South Circular Road), Source: Dublin City Council\n\n\n\n\nDublin City Council is also working on various projects to address areas of the city that are susceptible to coastal flooding during extreme events and therefore require new protection works. These projects include the South Bank Flood Defence Project, Sandymount Promenade and Flood Defence Project(O’Connell, n.d.), and Clontarf Promenade Development and Flood Defence Project(Cooke et al. 2005). As part of the Sutton to Sandycove promenade and cycle path project(Lyne 2021), the part of the scheme nearer to Bull Island has commenced and includes flood defence work.\n\n\n\n4.1.3 Policy & Objectives\n\n\nClimate Change Mitigation and Adaptation: Implementing strategies to address climate change impacts on flooding.\nStrategic Flood Risk Assessment: Conducting assessments to inform and improve the city’s flood defenses.\nSustainable Environmental Infrastructure: Mitigating flood and drought effects through environmental assessments and planning.\nDevelopment Compliance: Ensuring new developments respect and enhance existing flood defense mechanisms.\nSustainable Urban Drainage Systems (SUDS): Mandating SUDS in new developments for better water management.\nSite-Specific Flood Risk Assessments: Requiring detailed flood risk analyses for all new development proposals.\nCollaborative Flood Management: Working with neighboring authorities and incorporating catchment-based flood risk management plans.\nGreen Infrastructure Integration: Utilizing green spaces for flood management, biodiversity, and recreation, in line with SUDS principles."
  },
  {
    "objectID": "Week_4.html#applications",
    "href": "Week_4.html#applications",
    "title": "4  Week_4 Flooding Issues In Dublin",
    "section": "4.2 Applications",
    "text": "4.2 Applications\n\n4.2.1 How Remote Sensing Data Should Address Policy Objectives\n\n\nFlood Risk Mapping: The use of remote sensing technology in flood prevention can mention its monitoring, provide real-time data, and can provide a guarantee of the timeliness of flood monitoring(Diao, Sang, and Wang 2022).Radar data can be used to focus on the extraction of past flood inundation areas, and to analyse the characteristics of spatial and temporal changes in flooding. At the same time, it can be used to draw high-resolution maps of the impact of river flooding, and use Google Earth Engine to process geospatial data, so as to carry out flood risk management and monitoring of flood disasters(Colacicco et al. 2022).\nImpact Assessment and Recovery Planning: The use of remote sensing data can facilitate post-flood impact assessment and recovery planning. Remote sensing provides clear spatial information for flood inundation mapping, which is critical for timely damage assessment and planning of recovery efforts. By using near real-time (NRT) remote sensing data after a flood event in combination with real-time (RT) volunteer geographic information (VGI), probabilistic flood maps can be generated to identify areas requiring urgent attention(Luo, Liao, and Shen 2023)。In addition, aerial imagery captured by drones can be used to reconstruct 3D models and digital elevation models for flood modelling and damage assessment(Whitehurst et al. 2022). Simulations based on pre- and post-flood digital elevation models can help predict the impact of future rainfall events and guide recovery efforts (Sajjad et al. 2023).\nWatershed management:The use of remote sensing data can improve post-flood impact watershed management. Remote sensing technologies such as satellite imagery can be used to monitor and assess damage caused by floods, including the extent of flooding, infrastructure damage, and changes in land cover and land use (Sridharan, Kumar, and Madhur Kumar 2022). This information helps to assess the effectiveness of watershed development interventions and identify areas for improvement. Geographic Information Systems (GIS) can be integrated with remote sensing data to enhance stakeholder and public participation in the watershed planning process(Quinn et al. 2022). By utilising GIS and remotely sensed datasets, stakeholders can gain valuable information for decision-making and planning(Quinn et al. 2022).\n\n\n\n\n4.2.2 Connecting to the Big Picture\n\n4.2.2.1 With Local Development\n\nThis policy and its associated Strategic Flood Risk Assessment (SFRA) has had a significant impact on the Local Development Strategy, focussing on sustainable infrastructure and flood risk management. The Plan emphasises the importance of managing surface water drainage and the potential impact of local development on downstream watercourses such as the River Carmichael and the River Liffey. It emphasises the need for additional infrastructure to support development sites, Sustainable Urban Drainage Systems (SuDS) to effectively manage surface water run-off and improve water quality(Dublin City Council 2020c).\nSuDS infrastructure has been highlighted as a core strategy in the Local Plan, designed to manage surface water sustainably, whilst ensuring that there is no increased risk of flooding either upstream or downstream. The approach includes a variety of SuDS features such as detention ponds, infiltration trenches and depressions designed to reduce runoff and improve water quality. This holistic water management strategy supports the vision of creating a vibrant and sustainable urban area in Dublin(South Dublin City Council, n.d.).\nIn addition, the Plan sets out the need for a comprehensive review of existing and future infrastructure (including sewerage and water supply networks) to accommodate development while managing environmental impacts. This includes considerations for upgrading existing infrastructure (e.g. water mains and sewerage systems) to meet the needs of new development(South Dublin City Council, n.d.).\n\n\n\n\n\nDublin Flooding Protection Location, Author: I.Cooke\n\n\n\n\n\n\n\n4.2.2.2 With Global Agenda\n\nIn order to address the identified flood risks, the Plan outlines several strategies and measures. These include the Dublin Coastal Flood Protection Project and participation in the EU Interreg Programme IIIB SAFER project which focuses on coastal flood risk. Dublin City Council works closely with the Office of Public Works (OPW), Ireland’s lead agency for flood risk management, under the Catchment Flood Risk Assessment and Management (CFRAM) programme. The programme is at the heart of Ireland’s medium to long term strategy for flood risk reduction and management and involves the production of detailed flood risk maps and management plans for Dublin’s main rivers and coastal areas.(Dublin City Council 2020c)。\nMore broadly the Plan can explicitly link its objectives and strategies to the relevant SDGs, particularly those relating to Sustainable Cities and Communities (SDG 11), Climate Action (SDG 13) and Water Resources Management (SDG 6). By integrating the flood risk management strategy with these objectives, Dublin can demonstrate its commitment to the global sustainable development agenda while addressing local challenges(Anthony F and Max, n.d.)。\nSchemes should ensure compliance with EU Directives relevant to flood risk management, such as the EU Floods Directive, which requires Member States to assess and manage flood risk in order to reduce the impact of flooding on human health, the environment, cultural heritage and economic activities. By aligning the SFRA with these directives, Dublin City Council can integrate European standards into local practice, facilitate cross-border co-operation and share best practice(herve 2021)。\n\n\n\n\n4.2.3 Types of Remotely Sense Data Can be use for the Urban Flooding Analysis\n\n4.2.3.1 General Data\n\nThe following table presents general data\n\n\n\n\n\n\n\n\n\nSatellites\nSensors\nSpectral Measurements\nParameter\n\n\n\n\nLandsat 5, 7, 8\nETM+, OLI\nVisible, Near IR, Middle IR,\nReflectance/True Color Image,\n\n\n\n\nThermal IR\nLand Cover, Surface Inundation\n\n\nTRMM & GPM\nMicrowave\nTMI: 10-85 Ghz; GMI: 10-183 GHZ;\nPrecipitation\n\n\n\nRadiometer and\nPR and DPR (Ku and Ka)\n\n\n\n\nRADAR (TMI, PR,\n\n\n\n\n\nGMI, DPR)\n\n\n\n\nTerra & Aqua\nMODIS\nVisible, Near IR, Middle IR\nReflectance/True Color Image,\n\n\n\n\n\nSurface Inundation, Land Cover\n\n\nSNPP\nVIIRS\nVisible, Near IR, Middle IR\nDay/Night Imagery\n\n\nSMAP\nMicrowave\n1.41 GHz\nSoil Moisture\n\n\n\nRadiometer\n\n\n\n\nSentinel 1A and 1B\nSynthetic\nC-Band\nBackscatter/Surface Inundation\n\n\n\nAperture RADAR\n\n\n\n\n\n(SAR)\n\n\n\n\nSpace Shuttle\nSRTM\nC-Band\nTerrain\n\n\n\n\n4.2.3.2 Global Precipitation Measurement (GPM) Mission\nThe Global Precipitation Measurement (GPM) mission plays a crucial role in analyzing global rainfall patterns. It stands at the forefront of flooding trend analysis, thanks to its comprehensive and derived algorithms. Recognized for its unparalleled popularity and reliability, GPM serves as the primary source of data and analysis method for studying precipitation(Skofronick-Jackson et al. 2018).\nGPM represents an international collaboration, involving a network of satellites dedicated to providing advanced observations of rain and snow across the globe. It builds on the achievements of the Tropical Rainfall Measuring Mission (TRMM) and introduces the concept of a Core Observatory. This central satellite is equipped with sophisticated radar and radiometer systems designed to accurately measure precipitation from space. This Core Observatory also plays a pivotal role in standardizing precipitation measurements collected from a constellation of both research and operational satellites, ensuring consistent and reliable data worldwide(Hou 2012).\n\n\n\n\n\n\n\nGlobal Precipitation Measurement (GPM) Mission, Source: NASA\n\n\n\n\n\n\n4.2.3.3 Relative Data Source Link\n\nGPM IMERG Data Access: https://gpm.nasa.gov/data\nPrecipitation Data Access and Analysis: https://giovanni.gsfc.nasa.gov/giovanni/\nMODerate Resolution Imaging Spectroradiometer (MODIS): https://lpdaac.usgs.gov/ or https://search.earthdata.nasa.gov/\nVisible Infrared Imaging Radiometer Suite (VIIRS): https://worldview.earthdata.nasa.gov/\nSoil Moisture Active Passive (SMAP): https://nsidc.org/data/search#keywords=soil+moisture/\nETC……"
  },
  {
    "objectID": "Week_4.html#reflection",
    "href": "Week_4.html#reflection",
    "title": "4  Week_4 Flooding Issues In Dublin",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nIncorporating the application of remote sensing technologies into the context of the Dublin City Development Plan 2016-2022 and its Strategic Flood Risk Assessment (SFRA) not only broadens the scope of my reflection but also enhances the depth of analysis on how technological advancements can be synergized with urban planning and environmental management practices. This expanded consideration allows for a multifaceted approach towards sustainable urban development, emphasizing the critical role of innovative technologies in addressing complex urban challenges.\nRemote sensing, with its capacity to collect detailed environmental data from a distance, presents an invaluable tool for urban planners and policymakers. By facilitating a comprehensive analysis of land use changes, vegetation cover, water bodies, and urban infrastructure, remote sensing data can significantly contribute to informed decision-making processes. For Dublin, leveraging such technologies means the ability to dynamically monitor urban expansion and its impacts on flood risks, assess vulnerabilities across the urban landscape, and develop targeted strategies for flood mitigation and urban resilience.\nThis integration goes beyond traditional planning methods by enabling a proactive rather than reactive approach to urban development and environmental stewardship. The precision and timeliness of data provided by remote sensing can lead to the early identification of potential flood-prone areas, changes in land cover that may affect hydrological cycles, and the effectiveness of existing flood defense structures. Consequently, this facilitates the optimization of land use planning, infrastructure development, and environmental conservation efforts to mitigate flood risks effectively.\nFurthermore, the application of remote sensing technologies underscores the importance of interdisciplinary collaboration and capacity building among urban planners, environmental scientists, and the broader community. Engaging with a diverse range of stakeholders in the interpretation and application of remote sensing data can foster a more inclusive and participatory approach to urban planning. This collaborative framework not only enhances the understanding and management of flood risks but also promotes a shared sense of responsibility and collective action towards sustainable urban development. Moreover, the ongoing advancement in remote sensing technologies, including higher resolution imagery, real-time data acquisition, and improved analytical tools, offers new opportunities for innovation in urban planning and environmental management. As cities like Dublin strive to align their development strategies with global sustainability goals, the integration of such technologies becomes increasingly crucial. It allows for a more nuanced understanding of urban ecosystems, the interconnections between human activities and natural processes, and the pathways towards achieving a harmonious balance between urban development and environmental preservation.\nIn summary, the reflection on integrating remote sensing technologies into Dublin’s urban planning and flood risk management efforts highlights the transformative potential of such tools in advancing sustainable urban development. It points towards a future where technology and data-driven insights become central to crafting resilient, inclusive, and sustainable urban landscapes. This expanded perspective not only enriches my understanding of the complexities involved in urban planning but also inspires a forward-looking approach to leveraging technology for the betterment of our urban environments."
  },
  {
    "objectID": "Week_4.html#reference",
    "href": "Week_4.html#reference",
    "title": "4  Week_4 Flooding Issues In Dublin",
    "section": "4.4 Reference",
    "text": "4.4 Reference\n\n\n\n\nAnthony F, Pipa, and Bouchet Max. n.d. “Local Leadership Driving Progress on the Sustainable Development Goals.” https://www.brookings.edu/articles/local-leadership-driving-progress-on-the-sustainable-development-goals/.\n\n\nColacicco, Rosa, Alberto Refice, Raffaele Nutricato, Annarita D’Addabbo, Davide Oscar Nitti, and Domenico Capolongo. 2022. “High Spatial and Temporal Resolution Flood Monitoring Through Integration of Multisensor Remotely Sensed Data and Google Earth Engine Processing.” https://doi.org/10.5194/egusphere-egu22-4403.\n\n\nCooke, I, A D Maguire, O McManus, and B Bliek. 2005. “The Dublin Coastal Protection Project.” WIT Transactions on The Built Environment 78.\n\n\nDiao, Chao, Guoqing Sang, and JunNuo Wang. 2022. “Research on the Application of Remote Sensing Monitoring to Flood Monitoring Based on Sentinel-1A in Linyi City.” 2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS), April. https://doi.org/10.1109/icgmrs55602.2022.9849305.\n\n\nDublin City Council. 2020c. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\n———. 2020a. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\n———. 2020b. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\nherve. 2021. “Global Policies in Local Context: Local Transformation Through International Engagement - Platforma.” https://platforma-dev.eu/global-policies-in-local-context-local-transformation-through-international-engagement/, https://platforma-dev.eu/global-policies-in-local-context-local-transformation-through-international-engagement/.\n\n\nHou, Arthur Y. 2012. “Global Precipitation Measurement (GPM) Mission: Overview and Status,” October. https://ntrs.nasa.gov/citations/20120015575.\n\n\nLuo, Huanzhang, Jingjuan Liao, and Guozhuang Shen. 2023. “Combining Remote Sensing and Social Media Data for Flood Mapping: A Case Study in Linhai, Zhejiang Province, China.” Journal of Applied Remote Sensing 17 (2): 024507. https://doi.org/10.1117/1.JRS.17.024507.\n\n\nLyne, Laura. 2021. “Dublin Residents Fearing Worst as Dream Cycleway at Risk Due to Plan Changes.” https://www.dublinlive.ie/news/dublin-news/residents-fear-dream-sutton-sandycove-20368777.\n\n\nO’Connell, Gerard. n.d. “Sandymount Coastal Flood Defence SchemePhase 1&2.”\n\n\nParanunzio, Roberta, Marco Guerrini, Edward Dwyer, Paul J. Alexander, and Barry O’Dwyer. 2022a. “Assessing Coastal Flood Risk in a Changing Climate for Dublin, Ireland.” Journal of Marine Science and Engineering 10 (11): 1715. https://doi.org/10.3390/jmse10111715.\n\n\n———. 2022b. “Assessing Coastal Flood Risk in a Changing Climate for Dublin, Ireland.” Journal of Marine Science and Engineering 10 (11): 1715. https://doi.org/10.3390/jmse10111715.\n\n\nQuinn, Nigel W. T., Vamsi Sridharan, John Ramirez-Avila, Sanaz Imen, Huilin Gao, Rocky Talchabhadel, Saurav Kumar, and Walter McDonald. 2022. “Applications of GIS and Remote Sensing in Public Participation and Stakeholder Engagement for Watershed Management.” Socio-Environmental Systems Modelling 4 (October): 18149–49. https://doi.org/10.18174/sesmo.18149.\n\n\nSajjad, Asif, Jianzhong Lu, Xiaoling Chen, Chikondi Chisenga, and Nausheen Mazhar. 2023. “Rapid Assessment of Riverine Flood Inundation in Chenab Floodplain Using Remote Sensing Techniques.” Geoenvironmental Disasters 10 (1): 9. https://doi.org/10.1186/s40677-023-00236-7.\n\n\nShoari Nejad, Amin, Andrew C. Parnell, Alice Greene, Peter Thorne, Brian P. Kelleher, Robert J. N. Devoy, and Gerard McCarthy. 2022. “A Newly Reconciled Dataset for Identifying Sea Level Rise and Variability in Dublin Bay.” Ocean Science 18 (2): 511–22. https://doi.org/10.5194/os-18-511-2022.\n\n\nSkofronick-Jackson, Gail, Wesley Berg, Chris Kidd, Dalia B. Kirschbaum, Walter A. Petersen, George J. Huffman, and Yukari N. Takayabu. 2018. “Global Precipitation Measurement (GPM): Unified Precipitation Estimation from Space.” In, edited by Constantin Andronache, 175–93. Springer Remote Sensing/Photogrammetry. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-72583-3_7.\n\n\nSouth Dublin City Council. n.d. “Sustainable Drainage Systems (SuDS).” https://www.sdcc.ie/en/services/environment/environmental-health/water-services/sustainable-drainage-systems/https:/www.sdcc.ie/en/services/environment/environmental-health/water-services/sustainable-drainage-systems/sustainable-drainage-systems-suds.html.\n\n\nSridharan, Vamsi Krishna, Saurav Kumar, and Swetha Madhur Kumar. 2022. “Can Remote Sensing Fill the United States’ Monitoring Gap for Watershed Management?” Water 14 (13): 1985. https://doi.org/10.3390/w14131985.\n\n\nWhitehurst, Daniel, Kunal Joshi, Kevin Kochersberger, and James Weeks. 2022. “Post-Flood Analysis for Damage and Restoration Assessment Using Drone Imagery.” Remote Sensing 14 (19): 4952. https://doi.org/10.3390/rs14194952."
  },
  {
    "objectID": "Week_6.html#knowledge-from-the-lecture",
    "href": "Week_6.html#knowledge-from-the-lecture",
    "title": "5  Week_6 Intro to GEE",
    "section": "5.1 Knowledge From the Lecture",
    "text": "5.1 Knowledge From the Lecture\n\nGoogle Earth Engine is a cloud-based platform provided by Google for online visual computation and analysis of large amounts of global-scale geoscience data (especially satellite data). It is characterised by allowing large-scale geospatial analyses, running very fast, having code that runs on the client side, and storing the data on the server.\n\n5.1.1 Raster and vector data in GEE\n\nRaster data, called “Image”, has bands.\nVector data, called “Feature”, has geometry and a dictionary of properties.。\n\n\n\n5.1.2 Image scaling in GEE\n\nRefers to the resolution of the image, i.e. the actual ground distance represented by each pixel.\nGEE automatically selects the appropriate zoom level based on the analysis requirements.\n\n\n\n5.1.3 Projection in GEE\nGEE supports a variety of projections, including Mercator projection, Albers projection, and isometric cylindrical projection. The user can select the appropriate projection for analysis.\n\n\n5.1.4 How to use GEE\n\n\n\n\n\nHow to use GEE, Source: Google Earth Engine\n\n\n\n\n\n\n5.1.5 Operations that can be performed in GEE\n\nGeometric operations: e.g. spatial operations, joins (Joins), region statistics (e.g. average temperature of a neighbourhood), filtering of images or specific values.\nMachine learning, both supervised and unsupervised, deep learning using TensorFlow, exploring relationships between variables.\nApplications/outputs: online graphs, scalable geospatial applications using GEE data\n\n\n\n5.1.6 Reduce the Image in GEE\nReducing the image by region and reducing the image by neighbour are both functions that are used to regionalise or neighbourhoodise an image. The main difference between them is:\n\nReducing the image by region operates on the image according to a specified region. Each region can be any shape and can overlap.\nReducing the image by neighbour is to operate on the image according to the specified neighbourhood. The neighbourhood of each pixel is the pixels within a certain range around it.\n\n\n\n5.2 Practical\n\n5.2.1 Compare with RGB & NDVI\n\n\n\n\n\nCompare with RGB & NDVI Slide the slider to see the changes in RGB and NDVI.\n\n\n5.2.2 PCA Analysis\nSelecting a region, it first normalizes the image bands, calculates the covariance matrix, extracts the eigenvalues and eigenvectors, and then projects the image data into the principal component space. Finally, it displays the first principal component of the PCA result on the map.\n\n\n\n\n\nPCA Analysis\n\n\n\n\n\n\n\n5.3 Applications\nGEE has been the focus of attention in remote sensing big data processing.GEE is a cloud-based platform for parallel processing of geospatial data globally using Google’s cloud.GEE is a free cloud-based platform hosting more than 40 years of data(Aghamiri et al., n.d.). GEE also includes climate-weather and geophysical datasets. Other off-the-shelf products such as the Enhanced Vegetation Index (EVI) and the Normalised Vegetation Index (NDVI) are also available. In addition to having access to a large repository of raw remote sensing imagery, users can access pre-processed imagery, cloud removal imagery and mosaics in the GEE data catalogue(Ritika, n.d.).\nThe wide range of applications by GEE users shows that optical images are easier to process and interpret for non-remote sensing experts. This is one of the reasons why GEE has a global reach in a wide range of scientific fields. At the same time, the combination of SAR and optical satellite data can help researchers to solve problems such as cloud cover. Especially in the tropics, the efficacy of optical images can be greatly affected due to continuous cloud cover and situations such as forest fires. Therefore, combining optical and SAR data can improve the accuracy of classification and provide more information to monitor surface changes.(Lea et al. 2023).\nLandsat is considered an important source of remote sensing data in the GEE, as it provides a continuous image of the Earth’s surface.The Landsat 9 satellite will be launched in 2020 with the aim of continuing the Landsat programme’s key role in monitoring the Earth’s resources. Long-term land cover change studies can be carried out on a regional and global scale(Pham-Duc et al. 2023).\nSentinel-1 is another popular source of satellite imagery and has achieved very accurate classification results.Sentinel-1 consists of two satellites, Sentinel-1A and Sentinel 1-B, which were launched in 2014 and 2016, respectively, with a spatial resolution of 10 m and a revisit time of 6 days(Arias Cuenca 2023). It is equipped with a dual-polarised C-band SAR sensor that provides data in all-weather, day and night conditions. Sentinel-2A (launched in 2015) and Sentinel-2B (launched in 2017), which provide spatially resolved 10 m, 20 m and 60 m optical images, and temporal resolution of about 5 days(Xu, Heremans, and Somers 2022; Lechner et al. 2022).\nThe Moderate Resolution Imaging Spectroradiometer (MODIS) was launched on the Terra satellite in 1999 and on the Aqua satellite in 2002. Researchers can access MODIS data in GEE in 36 spectral bands and at three varying spatial resolutions (250 m, 500 m, and 1 km) at 1-day revisit times(Wu and Xiong 2020).\nGEE provides a wide range of image processing tools suitable for the analysis of remotely sensed data. These tools cover time series analysis, feature extraction, colour compositing of images and image preprocessing, mainly for satellite images, rather than machine learning-based methods(“Google Earth Engine and Machine Learning for Earth Monitoring,” n.d.). With the rapid changes in the Earth’s surface, time-series analysis of satellite imagery has become critical, helping to track trends, monitor changes and develop predictive models.GEE has been used for such analyses in a number of studies because of its ability to handle high resolution or large amounts of data, and is particularly good at monitoring changes in the land surface. Feature extraction techniques, by analysing spectral and geometric attributes of images, help to identify regional relationships in images, which is critical for resource conservation and information retention(Pham-Duc et al. 2023). In addition, GEE’s visual interpretation tools are widely used in land monitoring studies to extract key information from colour composite images. In addition, GEE’s image pre-processing capabilities support image mosaicing, cloud processing and error detection, and although cloud coverage is a major challenge when working with optical data, GEE provides effective tools and algorithms to support these tasks(Lea et al. 2023).\n\n\n5.4 Reflection\nReflecting on the past week’s immersion in Google Earth Engine (GEE), I’ve traversed a transformative path in remote sensing, gaining invaluable insights into both the tool’s technical nuances and its broad environmental applications. My exploration delved into GEE’s adept handling of geospatial data, particularly the enlightening nuances of image reduction techniques. Understanding the distinctions between region-based and neighbor-based reductions was a revelation, showcasing GEE’s ability to transform complex data into insightful, actionable knowledge.\nThis intellectual journey illuminated the vast interdisciplinary potential of remote sensing, emphasizing how integrating diverse data types can lead to a more nuanced understanding of our planet’s environmental systems. Such comprehensive analysis not only improves environmental evaluations but also contributes to a holistic grasp of Earth’s complexities, underpinning sustainable solutions to ecological challenges.\nThe week was a fusion of learning, discovery, and enhanced appreciation for remote sensing’s pivotal role in environmental science. It reinforced my resolve to utilize technology for sustainable environmental stewardship, recognizing GEE’s profound capabilities to analyze and visualize intricate geospatial datasets. This experience has deepened my commitment to using innovative tools like GEE for advanced environmental monitoring, highlighting the importance of technological engagement in addressing today’s ecological issues."
  },
  {
    "objectID": "Week_6.html#practical",
    "href": "Week_6.html#practical",
    "title": "5  Week_6 Intro to GEE",
    "section": "5.2 Practical",
    "text": "5.2 Practical\n\n5.2.1 Compare with RGB & NDVI\n\n\n\n\n\nCompare with RGB & NDVI Slide the slider to see the changes in RGB and NDVI.\n\n\n5.2.2 PCA Analysis\nSelecting a region, it first normalizes the image bands, calculates the covariance matrix, extracts the eigenvalues and eigenvectors, and then projects the image data into the principal component space. Finally, it displays the first principal component of the PCA result on the map.\n\n\n\n\n\nPCA Analysis"
  },
  {
    "objectID": "Week_6.html#applications",
    "href": "Week_6.html#applications",
    "title": "5  Week_6 Intro to GEE",
    "section": "5.3 Applications",
    "text": "5.3 Applications\nGEE has been the focus of attention in remote sensing big data processing.GEE is a cloud-based platform for parallel processing of geospatial data globally using Google’s cloud.GEE is a free cloud-based platform hosting more than 40 years of data(Aghamiri et al., n.d.). GEE also includes climate-weather and geophysical datasets. Other off-the-shelf products such as the Enhanced Vegetation Index (EVI) and the Normalised Vegetation Index (NDVI) are also available. In addition to having access to a large repository of raw remote sensing imagery, users can access pre-processed imagery, cloud removal imagery and mosaics in the GEE data catalogue(Ritika, n.d.).\nThe wide range of applications by GEE users shows that optical images are easier to process and interpret for non-remote sensing experts. This is one of the reasons why GEE has a global reach in a wide range of scientific fields. At the same time, the combination of SAR and optical satellite data can help researchers to solve problems such as cloud cover. Especially in the tropics, the efficacy of optical images can be greatly affected due to continuous cloud cover and situations such as forest fires. Therefore, combining optical and SAR data can improve the accuracy of classification and provide more information to monitor surface changes.(Lea et al. 2023).\nLandsat is considered an important source of remote sensing data in the GEE, as it provides a continuous image of the Earth’s surface.The Landsat 9 satellite will be launched in 2020 with the aim of continuing the Landsat programme’s key role in monitoring the Earth’s resources. Long-term land cover change studies can be carried out on a regional and global scale(Pham-Duc et al. 2023).\nSentinel-1 is another popular source of satellite imagery and has achieved very accurate classification results.Sentinel-1 consists of two satellites, Sentinel-1A and Sentinel 1-B, which were launched in 2014 and 2016, respectively, with a spatial resolution of 10 m and a revisit time of 6 days(Arias Cuenca 2023). It is equipped with a dual-polarised C-band SAR sensor that provides data in all-weather, day and night conditions. Sentinel-2A (launched in 2015) and Sentinel-2B (launched in 2017), which provide spatially resolved 10 m, 20 m and 60 m optical images, and temporal resolution of about 5 days(Xu, Heremans, and Somers 2022; Lechner et al. 2022).\nThe Moderate Resolution Imaging Spectroradiometer (MODIS) was launched on the Terra satellite in 1999 and on the Aqua satellite in 2002. Researchers can access MODIS data in GEE in 36 spectral bands and at three varying spatial resolutions (250 m, 500 m, and 1 km) at 1-day revisit times(Wu and Xiong 2020).\nGEE provides a wide range of image processing tools suitable for the analysis of remotely sensed data. These tools cover time series analysis, feature extraction, colour compositing of images and image preprocessing, mainly for satellite images, rather than machine learning-based methods(“Google Earth Engine and Machine Learning for Earth Monitoring,” n.d.). With the rapid changes in the Earth’s surface, time-series analysis of satellite imagery has become critical, helping to track trends, monitor changes and develop predictive models.GEE has been used for such analyses in a number of studies because of its ability to handle high resolution or large amounts of data, and is particularly good at monitoring changes in the land surface. Feature extraction techniques, by analysing spectral and geometric attributes of images, help to identify regional relationships in images, which is critical for resource conservation and information retention(Pham-Duc et al. 2023). In addition, GEE’s visual interpretation tools are widely used in land monitoring studies to extract key information from colour composite images. In addition, GEE’s image pre-processing capabilities support image mosaicing, cloud processing and error detection, and although cloud coverage is a major challenge when working with optical data, GEE provides effective tools and algorithms to support these tasks(Lea et al. 2023)."
  },
  {
    "objectID": "Week_6.html#reflection",
    "href": "Week_6.html#reflection",
    "title": "5  Week_6 Intro to GEE",
    "section": "5.4 Reflection",
    "text": "5.4 Reflection\nReflecting on the past week’s immersion in Google Earth Engine (GEE), I’ve traversed a transformative path in remote sensing, gaining invaluable insights into both the tool’s technical nuances and its broad environmental applications. My exploration delved into GEE’s adept handling of geospatial data, particularly the enlightening nuances of image reduction techniques. Understanding the distinctions between region-based and neighbor-based reductions was a revelation, showcasing GEE’s ability to transform complex data into insightful, actionable knowledge.\nThis intellectual journey illuminated the vast interdisciplinary potential of remote sensing, emphasizing how integrating diverse data types can lead to a more nuanced understanding of our planet’s environmental systems. Such comprehensive analysis not only improves environmental evaluations but also contributes to a holistic grasp of Earth’s complexities, underpinning sustainable solutions to ecological challenges.\nThe week was a fusion of learning, discovery, and enhanced appreciation for remote sensing’s pivotal role in environmental science. It reinforced my resolve to utilize technology for sustainable environmental stewardship, recognizing GEE’s profound capabilities to analyze and visualize intricate geospatial datasets. This experience has deepened my commitment to using innovative tools like GEE for advanced environmental monitoring, highlighting the importance of technological engagement in addressing today’s ecological issues."
  },
  {
    "objectID": "Week_6.html#reference",
    "href": "Week_6.html#reference",
    "title": "5  Week_6 Intro to GEE",
    "section": "5.5 Reference",
    "text": "5.5 Reference\n\n\n\n\nAghamiri, Mahtab, Amineh Ghorbani, Jolien Ubacht, Igor Nikolic, and Paulein Herder. n.d. “Enabling Citizen Participation in Sustainable Collec- Tive Action In Smart Cities: The Case Of Buiksloter- Ham.”\n\n\nArias Cuenca, María. 2023. “Sentinel-1 time series applications over agricultural fields: proposal, evaluation and comparison of different methodologies.” https://doi.org/10.48035/Tesis/2454/45156.\n\n\n“Google Earth Engine and Machine Learning for Earth Monitoring.” n.d. https://pos.sissa.it/429/021.\n\n\nLea, James, Robert Fitt, Stephen Brough, Georgia Carr, Jonathan Dick, Natasha Jones, Eli Saetnan, and Richard Webster. 2023. “Google Earth Engine Climate Tool (GEEClimT): Enabling Rapid, Easy Access to Global Climate Reanalysis Data.” https://doi.org/10.5194/egusphere-egu23-7760.\n\n\nLechner, Michael, Alena Dostálová, Markus Hollaus, Clement Atzberger, and Markus Immitzer. 2022. “Combination of Sentinel-1 and Sentinel-2 Data for Tree Species Classification in a Central European Biosphere Reserve.” Remote Sensing 14 (11): 2687. https://doi.org/10.3390/rs14112687.\n\n\nPham-Duc, Binh, Ho Nguyen, Hien Phan, and Quan Tran-Anh. 2023. “Trends and Applications of Google Earth Engine in Remote Sensing and Earth Science Research: A Bibliometric Analysis Using Scopus Database.” Earth Science Informatics 16 (3): 2355–71. https://doi.org/10.1007/s12145-023-01035-2.\n\n\nRitika, Prasai. n.d. “Earth Engine Application to Retrieve Long-Term Terrestrial and Aquatic Time Series of Satellite Reflectance Data.” International Journal of Multidisciplinary Research and Growth Evaluation.\n\n\nWu, A., and X. Xiong. 2020. “Sensors, Systems, and Next-Generation Satellites XXIV.” In, 11530:267–77. SPIE. https://doi.org/10.1117/12.2573018.\n\n\nXu, Fei, Stien Heremans, and Ben Somers. 2022. “Urban Land Cover Mapping with Sentinel-2: A Spectro-Spatio-Temporal Analysis.” Urban Informatics 1 (1): 8. https://doi.org/10.1007/s44212-022-00008-y."
  },
  {
    "objectID": "Week_7.html#knowledge-from-the-lecture",
    "href": "Week_7.html#knowledge-from-the-lecture",
    "title": "6  Week_7 Classification I",
    "section": "6.1 Knowledge From the Lecture",
    "text": "6.1 Knowledge From the Lecture\n\n\n6.1.1 Classification and regression trees (CART)\n\n6.1.1.1 Classification\nClassification trees are used to categorise data into two or more discrete categories Regression trees deal with situations where linear regression does not apply Improve the predictive power of the model by splitting the data into smaller chunks When creating a decision tree, the final leaf nodes may be a mixture of categories (impurity) and the Gini impurity is used to quantify this impurity. Select the attribute with the lowest impurity as the top of the tree to begin the decision process. Calculate the Gini impurity and use it to assess the quality of the data segmented when constructing the decision tree, with smaller values indicating purer data\n\n\n\n\n\nLand Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition, Source: (Phan, Kuch, and Lehnert 2020)\n\n\n\n\n\n\n6.1.1.2 Regression trees\nRegression trees predict continuous values, such as the amount of pollution, while classification trees predict discrete values, such as land cover type. When linear regression does not fit the data well, regression trees are recommended as an alternative. In a regression tree, the data is divided into multiple parts based on thresholds or nodes. The sum of squared residuals (SSR) of these parts is calculated and the threshold with the lowest SSR becomes the starting point or root of the tree. The process can be repeated to further segment the data, and a minimum number of observations can be set to prevent overfitting.\n\n\n\n\n\nTree classification procedure in Google Earth Engine, Source: (Laengner, Siteur, and Wal 2019)\n\n\n\n\n\n\n\n6.1.2 Overfitting\nIf a leaf node contains only one person or one pixel value, overfitting may occur. The best models have low bias and low variability and are able to make consistent predictions across different datasets (e.g., training and test sets). To prevent overgrowth of the decision tree, its methods include limiting the growth of the tree (e.g., a leaf contains at least 20 pixels), and weakest link pruning (pruning based on the tree score). The number of leaves per tree and the value of α (regularisation parameter) were adjusted to reduce overfitting. Starting from α = 0, the α values were gradually increased until the pruning could reduce the tree score, and then these α values were saved. The tree score is the sum of squared residuals (SSR) plus the tree penalty (α multiplied by the number of leaves T). Different α values produce different subtrees and tree scores. Use different values of α to train the data and calculate the SSR on the test data to select the tree with the smallest score. Repeat the above process with cross-validation (10 cross validations) so as to find the α value that on average has the lowest SSR on the test data. The tree corresponding to this α-value, trained using all the data, is then selected. For classification trees, the SSR will be replaced by an impurity metric (e.g., Gini impurity).\n\n\n6.1.3 Random Tress\nA random forest consists of a number of categorical decision trees that are constructed by self-sampling the data (bootstrap samples) and constructing decision trees from randomly selected variables. At the nodes, the algorithm again selects from a random subset of variables. This process is repeated over and over again, resulting in multiple trees, or a “forest”. As new data passes through these trees, each tree gives a prediction, and the one with the most votes is chosen as the final prediction. The “bagging” technique in Random Forest is self-sampling by replacing data. Each tree is trained using approximately 70% of the training data, and the remaining 30% is called out-of-bag (OOB) data. The out-of-bag data is used to test the forest to evaluate the performance of the model and finally the classification result with the most votes is selected. The percentage of classification errors for out-of-bag data is known as OOB error. No pruning is done in a random forest and the tree can grow as much as possible. The out-of-bag error is derived by calculating the average prediction error for all trees that do not use certain values (e.g., rows in the data). Validation data, unlike out-of-bag data, is never included in the construction of the decision tree.\n\n\n6.1.4 How to apply to the imagery\nTwo main approaches to image classification: supervised learning and unsupervised learning. Supervised learning learns from data and labels new data through machine learning pattern recognition, while unsupervised learning analyses undefined data through clustering and then labels these clusters.\nSupervised Learning:\n\nGeneric of supervised learning basically follows the process includes: category definition, preprocessing, training, pixel assignment and accuracy assessment.\n\nUnsupervised Learning:\n\nThe DBSCAN algorithm, which forms clusters by setting a radius (Epsilon) and a minimum number of points, and can be optimised by iteration and PCA.\nThe ISODATA algorithm, a variant of k-means, which adds the ability to merge clusters that are too close together or to split clusters that are too long, and controls the clustering process according to the number of pixels in the cluster, the number of iterations, etc. 3. the “Cluster busting” algorithm, which forms clusters by setting a radius (Epsilon) and a minimum number of points.\nThe “Cluster busting” method, which improves classification accuracy by masking and reclassifying clusters that are difficult to label or incorrectly labelled.\n\nMaximum likelihood\nMaximum likelihood & Support Vector Machine Maximum Likelihood Estimation (MLE) is a statistical method for estimating parameters in probabilistic models. The basic idea of the method is to select the parameter value that best explains the observed data from all possible parameter values. In remote sensing, for example, it uses probabilities to assign each pixel in an image to the most likely land cover type, and probability thresholds can be set to determine whether or not to classify it.\n\n\n\n\n\nMaximum likelihood classifier, Source: (Núñez et al. 2019)\n\n\n\n\nSupport Vector Machine\nSupport Vector Machine (SVM) is a supervised learning model used for classification and regression analysis. Suppose we have a training dataset in which each data point belongs to one of two classes.The goal of the SVM is to find a hyperplane such that the hyperplane separates the two classes of data points as much as possible.\n\n\n\n\n\nSVM example of linearly separable data, Source: (Sheykhmousa and Mahdianpari 2020)\n\n\n\n\n\n\n6.2 Practical\n\n6.2.1 Supervised Classification\nSelect a Study Area, select the training feature collections on the map, in the following figure selected forest, water,developed,herbaceous as the collect feature.Use ee.Classifier.smileCart) and train it. But the result is not very good, maybe the initial data set selection is not very good.\n\n\n\n\n\nSupervised trained Classification Result\n\n\n\n\n\n\n6.2.2 Unsupervised Classification\nSame result of Unsupervised trained Classification\n\n\n\n\n\nUnsupervised trained Classification Result\n\n\n\n\n\n\n\n6.3 Application\nThe roots of remote sensing machine learning can be traced back to the 1990s. It was initially introduced as an approach to remote sensing for automated knowledge infrastructure building. Since then it has evolved and found applications in a variety of fields, including remote sensing and geoscience(Challa, Sridhar, and Shyam Mohan 2022). Machine learning algorithms such as deep learning are popular in remote sensing due to their ability to analyse large amounts of data and achieve high accuracy(Jeon 2023). These algorithms have been used for tasks such as image classification, scene understanding and material recognition(Rewhel et al. 2023). The availability of datasets with domain-specific attributes further facilitates the application of machine learning techniques in remote sensing.\nThe popularity of the Random Forest algorithm in the remote sensing community is attributed to its excellent classification accuracy. The algorithm utilises an integrated classifier consisting of multiple decision trees to effectively deal with high-dimensional data, and especially excels in reducing the dimensionality of hyperspectral data, thanks to the variable importance scores it provides(Bahrami, Hassani, and Maghsoudi 2018). I believe that Random Forest is efficient because it incorporates the judgement of numerous decision trees to improve the overall accuracy by aggregating their predictions and adapting to the complexity and diversity of remote sensing data.\nSupport Vector Machines (SVMs) are particularly suitable for dealing with classification problems, distinguishing categories by defining optimal hyperplanes in high-dimensional spaces. It has demonstrated its strong performance in applications such as classification of multispectral remote sensing images(Feizi and Nazemi 2022).The ability of SVM to deal with nonlinear and high-dimensional data is particularly well suited to the needs of the remote sensing domain, but its optimal performance relies on accurate kernel function selection and parameter tuning.\nOverfitting is a problem that occurs when model complexity is too high, causing the model to memorise noise in the training data rather than regularities. While such a model is effective on the training set, it may not generalise to new data. Strategies to avoid overfitting include using appropriate dataset sizes, simplifying model complexity, and employing methods such as cross-validation to ensure that models generalise well(Schmidt, n.d.). Understanding the limitations of the model and continuously monitoring its predictive ability on new data during training are key to avoiding overfitting.\n\n\n6.4 Reflection\nReviewing this week’s learning diary on remote sensing, I found the exploration of classification trees and regression trees (CART) particularly enlightening. The distinction between classification trees, which categorize data into discrete sets, and regression trees, which predict continuous values, is a fundamental concept that resonates with me. The application of the Gini impurity measure in the improved classification tree decision process highlights the importance of data purity and precision in environmental analysis, which I had not fully appreciated before.\nThe discussion of overfitting is equally crucial, illustrating the delicate balance needed to avoid creating overly complex models. The strategies mentioned, such as limiting tree growth or applying the weakest link pruning, are practical solutions that I could envision applying in future projects to improve model reliability.\nThe introduction of random forests expanded my understanding of set learning techniques. This approach combines multiple decision trees, improves prediction accuracy and controls overfitting, and demonstrates the power of collective intelligence over a single predictive model, which is fascinating.\nApplying these concepts to images, especially through supervised and unsupervised learning, is the most fascinating part. Practical examples, such as the use of random forest classifiers in Google Earth Engine, give us a first-hand sense of the potential of remote sensing in environmental analysis. It’s curious to think about the wide range of applications these methods have, from land cover classification to pollution monitoring.\nThis week’s diary reveals the multifaceted nature of remote sensing and machine learning, giving me a greater appreciation of their role in understanding and protecting the environment. The evolving nature of these technologies, and their potential to have a profound impact on real-world issues, is incredibly motivating."
  },
  {
    "objectID": "Week_7.html#practical",
    "href": "Week_7.html#practical",
    "title": "6  Week_7 Classification I",
    "section": "6.2 Practical",
    "text": "6.2 Practical\n\n6.2.1 Supervised Classification\nSelect a Study Area, select the training feature collections on the map, in the following figure selected forest, water,developed,herbaceous as the collect feature.Use ee.Classifier.smileCart) and train it. But the result is not very good, maybe the initial data set selection is not very good.\n\n\n\n\n\nSupervised trained Classification Result\n\n\n\n\n\n\n6.2.2 Unsupervised Classification\nSame result of Unsupervised trained Classification\n\n\n\n\n\nUnsupervised trained Classification Result"
  },
  {
    "objectID": "Week_7.html#application",
    "href": "Week_7.html#application",
    "title": "6  Week_7 Classification I",
    "section": "6.3 Application",
    "text": "6.3 Application\nThe roots of remote sensing machine learning can be traced back to the 1990s. It was initially introduced as an approach to remote sensing for automated knowledge infrastructure building. Since then it has evolved and found applications in a variety of fields, including remote sensing and geoscience(Challa, Sridhar, and Shyam Mohan 2022). Machine learning algorithms such as deep learning are popular in remote sensing due to their ability to analyse large amounts of data and achieve high accuracy(Jeon 2023). These algorithms have been used for tasks such as image classification, scene understanding and material recognition(Rewhel et al. 2023). The availability of datasets with domain-specific attributes further facilitates the application of machine learning techniques in remote sensing.\nThe popularity of the Random Forest algorithm in the remote sensing community is attributed to its excellent classification accuracy. The algorithm utilises an integrated classifier consisting of multiple decision trees to effectively deal with high-dimensional data, and especially excels in reducing the dimensionality of hyperspectral data, thanks to the variable importance scores it provides(Bahrami, Hassani, and Maghsoudi 2018). I believe that Random Forest is efficient because it incorporates the judgement of numerous decision trees to improve the overall accuracy by aggregating their predictions and adapting to the complexity and diversity of remote sensing data.\nSupport Vector Machines (SVMs) are particularly suitable for dealing with classification problems, distinguishing categories by defining optimal hyperplanes in high-dimensional spaces. It has demonstrated its strong performance in applications such as classification of multispectral remote sensing images(Feizi and Nazemi 2022).The ability of SVM to deal with nonlinear and high-dimensional data is particularly well suited to the needs of the remote sensing domain, but its optimal performance relies on accurate kernel function selection and parameter tuning.\nOverfitting is a problem that occurs when model complexity is too high, causing the model to memorise noise in the training data rather than regularities. While such a model is effective on the training set, it may not generalise to new data. Strategies to avoid overfitting include using appropriate dataset sizes, simplifying model complexity, and employing methods such as cross-validation to ensure that models generalise well(Schmidt, n.d.). Understanding the limitations of the model and continuously monitoring its predictive ability on new data during training are key to avoiding overfitting."
  },
  {
    "objectID": "Week_7.html#reflection",
    "href": "Week_7.html#reflection",
    "title": "6  Week_7 Classification I",
    "section": "6.4 Reflection",
    "text": "6.4 Reflection\nReviewing this week’s learning diary on remote sensing, I found the exploration of classification trees and regression trees (CART) particularly enlightening. The distinction between classification trees, which categorize data into discrete sets, and regression trees, which predict continuous values, is a fundamental concept that resonates with me. The application of the Gini impurity measure in the improved classification tree decision process highlights the importance of data purity and precision in environmental analysis, which I had not fully appreciated before.\nThe discussion of overfitting is equally crucial, illustrating the delicate balance needed to avoid creating overly complex models. The strategies mentioned, such as limiting tree growth or applying the weakest link pruning, are practical solutions that I could envision applying in future projects to improve model reliability.\nThe introduction of random forests expanded my understanding of set learning techniques. This approach combines multiple decision trees, improves prediction accuracy and controls overfitting, and demonstrates the power of collective intelligence over a single predictive model, which is fascinating.\nApplying these concepts to images, especially through supervised and unsupervised learning, is the most fascinating part. Practical examples, such as the use of random forest classifiers in Google Earth Engine, give us a first-hand sense of the potential of remote sensing in environmental analysis. It’s curious to think about the wide range of applications these methods have, from land cover classification to pollution monitoring.\nThis week’s diary reveals the multifaceted nature of remote sensing and machine learning, giving me a greater appreciation of their role in understanding and protecting the environment. The evolving nature of these technologies, and their potential to have a profound impact on real-world issues, is incredibly motivating."
  },
  {
    "objectID": "Week_7.html#reference",
    "href": "Week_7.html#reference",
    "title": "6  Week_7 Classification I",
    "section": "6.5 Reference",
    "text": "6.5 Reference\n\n\n\n\nBahrami, Yousef, Hossein Hassani, and Abbas Maghsoudi. 2018. “Investigating the Capabilities of Multispectral Remote Sensors Data to Map Alteration Zones in the Abhar Area, NW Iran.” Geosystem Engineering 24 (December): 1–13. https://doi.org/10.1080/12269328.2018.1557083.\n\n\nChalla, Nagendra Panini, Parupally Sridhar, and J. S. Shyam Mohan. 2022. “A Machine Learning Perspective for Remote Sensing.” In, edited by Pala Gireesh Kumar, Kolluru V. L. Subramaniam, S. Moses Santhakumar, and Neelima Satyam D., 553–59. Lecture Notes in Civil Engineering. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-0189-8_45.\n\n\nFeizi, Amir, and Alireza Nazemi. 2022. “Classifying Random Variables Based on Support Vector Machine and a Neural Network Scheme.” Journal of Experimental & Theoretical Artificial Intelligence 0 (0): 1–24. https://doi.org/10.1080/0952813X.2022.2104385.\n\n\nJeon, Gwanggil. 2023. “Advanced Machine Learning and Deep Learning Approaches for Remote Sensing.” Remote Sensing 15 (11): 2876. https://doi.org/10.3390/rs15112876.\n\n\nLaengner, Marieke, Koen Siteur, and Daphne Wal. 2019. “Trends in the Seaward Extent of Saltmarshes Across Europe from Long-Term Satellite Data.” Remote Sensing 11 (July): 1653. https://doi.org/10.3390/rs11141653.\n\n\nNúñez, Juan Manuel, Sandra Medina-Fernández, F. Gerardo Ávila, and Jorge Montejano. 2019. “High-Resolution Satellite Imagery Classification for Urban Form Detection.” In, 1–9. https://doi.org/10.5772/intechopen.82729.\n\n\nPhan, Thanh Noi, Verena Kuch, and Lukas W. Lehnert. 2020. “Land Cover Classification Using Google Earth Engine and Random Forest ClassifierThe Role of Image Composition.” Remote Sensing 12 (15): 2411. https://doi.org/10.3390/rs12152411.\n\n\nRewhel, Ekram M., Jianqiang Li, Amal A. Hamed, Hatem M. Keshk, Amira S. Mahmoud, Sayed A. Sayed, Ehab Samir, et al. 2023. “Deep Learning Methods Used in Remote Sensing Images: A Review.” Journal of Environmental & Earth Sciences 5 (1): 33–64. https://doi.org/10.30564/jees.v5i1.5232.\n\n\nSchmidt, James. n.d. “Testing for Overfitting.” https://doi.org/10.48550/arXiv.2305.05792.\n\n\nSheykhmousa, Reza M, and Masoud Mahdianpari. 2020. “Support Vector Machine Vs. Random Forest for Remote Sensing Image Classification: A Meta-Analysis and Systematic Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, October. https://doi.org/10.1109/JSTARS.2020.3026724."
  },
  {
    "objectID": "Week_8.html#knowledge-from-the-lecture",
    "href": "Week_8.html#knowledge-from-the-lecture",
    "title": "7  Week_8 Classification II",
    "section": "7.1 Knowledge From the Lecture",
    "text": "7.1 Knowledge From the Lecture\n\n7.1.1 Object based image analysis (OBIA)\n\nThis is an analytical method that considers how ground objects are represented on raster cells. The Simple Linear Iterative Clustering algorithm is the most common method for generating hyperpixels. It segments the image into regions with similar colours and spatial locations called hyperpixels. Hyperpixel segmentation can be used for tasks such as image noise reduction, edge detection, texture analysis etc.The basic idea of SLIC algorithm is to iteratively update the clustering labels for each pixel point. In each iterative step, the algorithm calculates the distance of each pixel point from its neighbouring pixel points and assigns it to the closest cluster centre.\nThe SLIC algorithm is like a “game” of grouping pixels. The rules of the game are as follows:\n\nFirst, need to randomly select some points in the image as “cluster centres”. Then, you need to calculate the distance of each pixel from all the cluster centres.\nEach pixel will be assigned to the cluster centre closest to it.\nNext, the coordinates of each cluster centre need to be updated so that they are located at the average position of all pixels in the cluster.\nRepeat the above steps until all pixel points are assigned to a cluster centre.\nTour At the end of the game, a set of pixel points with similar colours and spatial locations, i.e., hyperpixels, will be obtained.\n\n\n\n\n\n\nComparison of Simple Linear Iterative Clustering (SLIC) and SLICO superpixel adherence to natural image boundaries derived using initial clustering of 10 × 10 pixels., Source: (Csillik 2017)\n\n\n\n\n\n7.1.2 Sub pixel analysis\nSubpixel analysis is a technique that analyses an image between its pixels. While traditional image processing methods focus only on the grey value of each pixel, subpixel analysis can take advantage of the subtle differences in grey scale between pixels to obtain more precise information. It has a wide range of applications, including: image enhancement, edge detection, texture analysis, target recognition.\n\n\n\n\n\nSuperpixel Generation Algorithm\n\n\n\n\n\n\n7.1.3 Assessment of the accuracy of classification of remotely sensed data\nDescribes how accuracy assessment is performed after producing remote sensing data as part of the machine learning workflow. Three of the key metrics are Producer’s Accuracy, User’s Accuracy, and Overall Accuracy, and how these metrics can be calculated using the Confusion Matrix.\n\n\n\n\n\n\n\nTerm\nDescription\n\n\n\n\nTrue Positive (TP)\nThe model correctly predicts the positive class.\n\n\nTrue Negative (TN)\nThe model correctly predicts the negative class.\n\n\nFalse Positive (FP)\nThe model incorrectly predicts positive, but the actual class is negative.\n\n\nFalse Negative (FN)\nThe model incorrectly predicts negative, but the actual class is positive.\n\n\n\nOn this basis the Kappa coefficient can be used to carry out an effective assessment of the performance of the classification model to ensure the reliability and accuracy of the classification results. The value of the Kappa coefficient ranges from -1 (complete inconsistency) to 1 (complete agreement). A value of 0 indicates that the consistency is the same as random chance, while a value close to 1 indicates very high consistency. It is calculated as (actual consistency - random consistency)/(1 - random consistency).\n\n\n\n\n\nExample of Accuracies and kappa coefficient of land use:land cover (LULC) classifications in the SMA, Source: (Priyankara et al. 2019)\n\n\n\n\n\n\n7.1.4 F1 Score\nWhen the classes in your dataset are unbalanced, i.e. one class has far more samples than another, the kappa coefficient will not be used, but the F1 Score is particularly useful. In this case, using precision alone may not be sufficient to reflect the model’s performance, as the model may only perform well in predicting the dominant class while ignoring a few.The F1 Score provides a more comprehensive performance metric by balancing precision (the proportion of predicted-positive classes that are actually positive) and recall (the proportion of actual-positive classes that are predicted-positive). If precision and recall are equally valued in your task, i.e. you want to reduce the number of false positives and false negatives, then F1 Score is an appropriate choice. It ensures that you don’t sacrifice one of the metrics by improving the other. Although the F1 Score can be extended to multi-class classification problems, it is mainly suitable for binary classification problems, especially when the importance of positive and negative samples is essentially equal. The ROC curve can be invoked when studying binary classification problems, which provides a way to compare multiple classifiers under different class distributions or different cost/weight conditions. ROC curves and AUC values provide a consistent evaluation criterion for model comparisons, even when the data sets vary over time or across data sets.\n\n\n7.1.5 Spatial cross validation\nIn the traditional machine Learning cross-validation approach, the dataset is randomly divided into a training set and a test set. Models are trained on the training set and evaluated on the test set. However, this random division approach ignores a key property —— spatial autocorrelation in remotely sensed data, i.e., neighbouring regions often have similar attributes to each other.\nAs an example now there is a large remote sensing image that contains a variety of terrain such as forests, lakes and urban areas. The goal of the task is to create a computer model that can look at any part of this image and tell you exactly whether it is a forest, lake or city. To train this model, you need to select some samples from the image (i.e., a small part of the image) and tell the model which terrain each of these samples belongs to. The model then learns these samples and tries to understand the appearance of the different terrains.\nBut here’s the catch: if you randomly select samples, then samples that are very close together may appear in both the training data (the data the model uses to learn) and the test data (the data used to check the model’s accuracy). This is like knowing part of the test questions before you take the test, which may make the model seem to perform well, but in reality it may not have actually learnt how to differentiate between different terrains, but only remembered those particular samples.\nSpatial cross-validation is designed to solve this problem. Instead of randomly selecting samples, we divide the entire image into several large regions. We can make sure that certain regions are only used to train the model, while others are used to test the model. This way, we can be sure that the model is evaluated with data it has never seen before, which helps us to judge the actual performance of the model more accurately.\nFor example, suppose you have a large map containing cities, forests, and lakes. You divide the map into two parts, east and west. You train your model with the data from the eastern half, which means that the model will see and learn what the cities, forests, and lakes in this area look like. Then you test the model on the western half of the map to see if it can accurately recognise different terrain in areas it has never “seen” before. In this way, you can better assess how well the model actually performs when dealing with new and unknown areas.\n\n\n\n\n\nImportance of spatial predictor variable selection in machine learning applications – Moving from data reproduction to spatial prediction, Source: (Meyer et al. 2019)\n\n\n\n\n\n\n7.2 Practical\n\n7.2.1 Accuracy Assessment Result & Hyperparameter Tuning\nA reference dataset of Milan was introduced, defining a series of prediction bands, and the dataset was divided into a training and a test set, with 80% used for training and 20% for testing. A Random Forest classifier was trained for predicting the target category based on the input band data. The accuracy of the model was evaluated using the test set and a confusion matrix was generated to detail the performance of the model (results below).\n\n\n\n\n\nAccuracy Assessment Result\n\n\n\n\nThe overall accuracy of 83.33% indicates the proportion of samples correctly classified by the model. The model has high confidence for each predicted category with a Kappa value of 0.773 implying good agreement.\n\n\n\n7.3 Application\nObject-based image analysis (OBIA) techniques have been widely used in remote sensing, especially in improving the accuracy of high-resolution (HR) remote sensing image classification. By considering the spatial relationship between segmented objects and integrating the a priori knowledge, the OBIA method not only improves the classification accuracy, but also enhances the recognition of complex surface features. For example, Gun and Chen (2023) proposed a novel classification scheme for HR remotely sensed images, which maintains spatial relationships and significantly improves classification accuracy by utilising a knowledge graph (KG). In addition, Ghorbanzadeh, Gholamnia, and Ghamisi (2023) evaluated a rule-based OBIA landslide detection method that combines a probabilistic deep learning model with image segmentation and rule-based classification to effectively improve the detection accuracy.\nThe application of F1 score in remote sensing image analysis shows that it is an important tool for evaluating the performance of different feature selection methods in object-oriented remote sensing image classification experiments.The F1 score provides a balanced and reliable performance evaluation metric in remote sensing by combining precision and recall.Lv et al. (2022) provide a balanced and reliable performance evaluation metric in remote sensing by combining the Fisher Score and the minimum redundancy maximum relevance (mRMR) feature selection method, showing how the F1 score can be used to improve the efficiency and accuracy of remote sensing image classification. Meanwhile, in the Through-the-Wall Radar Imaging (TWRI) technique, the F1 score is used to evaluate the ability of compression-aware (CS) algorithms to reconstruct images at different signal-to-noise ratios (SNR) and compression rates, as studied by John and Brad(2018).\nThe importance of spatial cross-validation as an important technique in remote sensing data classification is that it provides an unbiased estimate of the prediction error and ensures the reliability of remote sensing data analysis. This approach pays special attention to the spatial autocorrelation of the data and ensures the generalisation ability of the classification model through spatial leave-one-out cross-validation or similar techniques.Karasiak et al. (2022) showed how spatial leave-one-out cross-validation can provide unbiased estimation of the prediction error and ensures the fidelity of the resultant maps. Similarly, Routh et al. (2018) showed through the iSLOOCV method how spatial autocorrelation can be taken into account in marine remote sensing data to improve classification accuracy through the integration of iterative error estimation over an interval range.\n\n\n7.4 Reflection\nThe journey through remote sensing is exhilarating, merging complex technology with real-world applications and personal development. My recent deep dive into advanced techniques like Object-Based Image Analysis (OBIA), subpixel analysis, and hyperpixel algorithms, along with accuracy assessment practices, has profoundly expanded my understanding of remote sensing’s potential and challenges. The transformative learning of OBIA, which emphasizes the significance of object-oriented analysis over mere pixel examination, has revolutionized my approach to data interpretation, particularly through hands-on applications in areas like landslide detection with deep learning, thereby enriching my practical understanding of the field’s innovative frontiers.\nThe hands-on engagement with accuracy assessment methodologies, especially through random forest classifiers, offered deep insights into the practical application of theoretical knowledge, emphasizing the storytelling aspect of data and the power of analytical tools to uncover it. Additionally, delving into spatial cross-validation illuminated the importance of acknowledging spatial autocorrelation to enhance the generalizability and reliability of models, a crucial step in ensuring their effectiveness on unseen data. This educational journey not only bolstered my knowledge and analytical prowess but also stoked a deeper passion for remote sensing, inspiring confidence to navigate new challenges and apply these techniques to make meaningful real-world impacts."
  },
  {
    "objectID": "Week_8.html#practical",
    "href": "Week_8.html#practical",
    "title": "7  Week_8 Classification II",
    "section": "7.2 Practical",
    "text": "7.2 Practical\n\n7.2.1 Accuracy Assessment Result & Hyperparameter Tuning\nA reference dataset of Milan was introduced, defining a series of prediction bands, and the dataset was divided into a training and a test set, with 80% used for training and 20% for testing. A Random Forest classifier was trained for predicting the target category based on the input band data. The accuracy of the model was evaluated using the test set and a confusion matrix was generated to detail the performance of the model (results below).\n\n\n\n\n\nAccuracy Assessment Result\n\n\n\n\nThe overall accuracy of 83.33% indicates the proportion of samples correctly classified by the model. The model has high confidence for each predicted category with a Kappa value of 0.773 implying good agreement."
  },
  {
    "objectID": "Week_8.html#application",
    "href": "Week_8.html#application",
    "title": "7  Week_8 Classification II",
    "section": "7.3 Application",
    "text": "7.3 Application\nObject-based image analysis (OBIA) techniques have been widely used in remote sensing, especially in improving the accuracy of high-resolution (HR) remote sensing image classification. By considering the spatial relationship between segmented objects and integrating the a priori knowledge, the OBIA method not only improves the classification accuracy, but also enhances the recognition of complex surface features. For example, Gun and Chen (2023) proposed a novel classification scheme for HR remotely sensed images, which maintains spatial relationships and significantly improves classification accuracy by utilising a knowledge graph (KG). In addition, Ghorbanzadeh, Gholamnia, and Ghamisi (2023) evaluated a rule-based OBIA landslide detection method that combines a probabilistic deep learning model with image segmentation and rule-based classification to effectively improve the detection accuracy.\nThe application of F1 score in remote sensing image analysis shows that it is an important tool for evaluating the performance of different feature selection methods in object-oriented remote sensing image classification experiments.The F1 score provides a balanced and reliable performance evaluation metric in remote sensing by combining precision and recall.Lv et al. (2022) provide a balanced and reliable performance evaluation metric in remote sensing by combining the Fisher Score and the minimum redundancy maximum relevance (mRMR) feature selection method, showing how the F1 score can be used to improve the efficiency and accuracy of remote sensing image classification. Meanwhile, in the Through-the-Wall Radar Imaging (TWRI) technique, the F1 score is used to evaluate the ability of compression-aware (CS) algorithms to reconstruct images at different signal-to-noise ratios (SNR) and compression rates, as studied by John and Brad(2018).\nThe importance of spatial cross-validation as an important technique in remote sensing data classification is that it provides an unbiased estimate of the prediction error and ensures the reliability of remote sensing data analysis. This approach pays special attention to the spatial autocorrelation of the data and ensures the generalisation ability of the classification model through spatial leave-one-out cross-validation or similar techniques.Karasiak et al. (2022) showed how spatial leave-one-out cross-validation can provide unbiased estimation of the prediction error and ensures the fidelity of the resultant maps. Similarly, Routh et al. (2018) showed through the iSLOOCV method how spatial autocorrelation can be taken into account in marine remote sensing data to improve classification accuracy through the integration of iterative error estimation over an interval range."
  },
  {
    "objectID": "Week_8.html#reflection",
    "href": "Week_8.html#reflection",
    "title": "7  Week_8 Classification II",
    "section": "7.4 Reflection",
    "text": "7.4 Reflection\nThe journey through remote sensing is exhilarating, merging complex technology with real-world applications and personal development. My recent deep dive into advanced techniques like Object-Based Image Analysis (OBIA), subpixel analysis, and hyperpixel algorithms, along with accuracy assessment practices, has profoundly expanded my understanding of remote sensing’s potential and challenges. The transformative learning of OBIA, which emphasizes the significance of object-oriented analysis over mere pixel examination, has revolutionized my approach to data interpretation, particularly through hands-on applications in areas like landslide detection with deep learning, thereby enriching my practical understanding of the field’s innovative frontiers.\nThe hands-on engagement with accuracy assessment methodologies, especially through random forest classifiers, offered deep insights into the practical application of theoretical knowledge, emphasizing the storytelling aspect of data and the power of analytical tools to uncover it. Additionally, delving into spatial cross-validation illuminated the importance of acknowledging spatial autocorrelation to enhance the generalizability and reliability of models, a crucial step in ensuring their effectiveness on unseen data. This educational journey not only bolstered my knowledge and analytical prowess but also stoked a deeper passion for remote sensing, inspiring confidence to navigate new challenges and apply these techniques to make meaningful real-world impacts."
  },
  {
    "objectID": "Week_8.html#reference",
    "href": "Week_8.html#reference",
    "title": "7  Week_8 Classification II",
    "section": "7.5 Reference",
    "text": "7.5 Reference\n\n\n\n\nCsillik, Ovidiu. 2017. “Fast Segmentation and Classification of Very High Resolution Remote Sensing Data Using SLIC Superpixels.” Remote Sensing 9 (March): 243. https://doi.org/10.3390/rs9030243.\n\n\nGhorbanzadeh, Omid, Khalil Gholamnia, and Pedram Ghamisi. 2023. “The Application of ResU-Net and OBIA for Landslide Detection from Multi-Temporal Sentinel-2 Images.” Big Earth Data 7 (4): 961–85. https://doi.org/10.1080/20964471.2022.2031544.\n\n\nGun, Zhao, and Jianyu Chen. 2023. “Novel Knowledge Graph- and Knowledge Reasoning-Based Classification Prototype for OBIA Using High Resolution Remote Sensing Imagery.” Remote Sensing 15 (2): 321. https://doi.org/10.3390/rs15020321.\n\n\nJohn, F. Silny, and A. Flanders Brad. 2018. “Imaging Spectrometer f-Number Optimization for Remote Sensing of Gases.” https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10768/2323616/Imaging-spectrometer-F-number-optimization-for-remote-sensing-of-gases/10.1117/12.2323616.full#_=_.\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning 111 (7): 2715–40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nLv, Chengzhe, Yuefeng Lu, Miao Lu, Xinyi Feng, Huadan Fan, Changqing Xu, and Lei Xu. 2022. “A Classification Feature Optimization Method for Remote Sensing Imagery Based on Fisher Score and mRMR.” Applied Sciences 12 (September): 8845. https://doi.org/10.3390/app12178845.\n\n\nMeyer, Hanna, Christoph Reudenbach, Stephan Wöllauer, and Thomas Nauss. 2019. Importance of Spatial Predictor Variable Selection in Machine Learning Applications – Moving from Data Reproduction to Spatial Prediction.\n\n\nPriyankara, Prabath, Manjula Ranagalage, Dr Dissanayake, Takehiro Morimoto, and Yuji Murayama. 2019. “Spatial Process of Surface Urban Heat Island in Rapidly Growing Seoul Metropolitan Area for Sustainable Urban Planning Using Landsat Data.” Journal of Climate 7 (September): 110. https://doi.org/10.3390/cli7090110.\n\n\nRouth, Devin, Lindsi Seegmiller, Charlie Bettigole, Catherine Kuhn, Chadwick Oliver, and Henry Glick. 2018. “Improving the Reliability of Mixture Tuned Matched Filtering Remote Sensing Classification Results Using Supervised Learning Algorithms and Cross-Validation.” Remote Sensing 10 (October): 1675. https://doi.org/10.3390/rs10111675."
  },
  {
    "objectID": "Week_9.html#section",
    "href": "Week_9.html#section",
    "title": "8  Week_9 SAR",
    "section": "8.1 ",
    "text": "8.1"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliography",
    "section": "",
    "text": "‘Remote Sensing - NASA’, n.d. https://www.nasa.gov/directorates/somd/space-communications-navigation-program/remote-sensing/.\n‘Types Of Remote Sensing: Devices And Their Applications’, 18 November 2020. https://eos.com/blog/types-of-remote-sensing/."
  },
  {
    "objectID": "Week_9.html#knowledge-from-the-lecture",
    "href": "Week_9.html#knowledge-from-the-lecture",
    "title": "8  Week_9 SAR",
    "section": "8.1 Knowledge From the Lecture",
    "text": "8.1 Knowledge From the Lecture\n\nAs the basic part of SAR was covered in the first week, this diary is going to cover the details of SAR.\n\n8.1.1 SAR Data\nSAR data are usually available in three scales: the power scale (raw data) is suitable for statistical analysis but not for visualisation because bright areas are easily affected and not easily distinguishable; the amplitude scale improves visualisation by taking the square root of the power scale value but reduces the dynamic range; and the decibel (dB) scale emphasises the differences in dark pixels (e.g., bodies of water) but can lead to over-brightening of the image and is not suitable for statistical analysis. In selecting an appropriate scale for SAR data processing, consideration needs to be given to the detection target (e.g., surface roughness or volume of material), the purpose of data processing (analysis or visualisation), and the type of surface being observed (e.g., extent of water).\n\n\n8.1.2 Identifying Change\nWhile direct subtraction of SAR images is not recommended for change detection due to the high variance in bright regions and sensitivity to calibration errors, alternative methods such as ratio and log-ratio techniques may be more effective. Improved methods such as improved ratios and improved log ratios can better distinguish changing pixels by normalising the variance, which makes them more robust to the challenges inherent in SAR change detection.\n\n\n8.1.3 Methods and Evaluation of Image Change Detection\nWhen performing change detection in SAR images, traditional statistical methods such as t-tests may be challenged by the distributional characteristics of the data, especially when the data do not follow a normal distribution. Nevertheless, changes in a collection of images can be effectively identified by varying the evaluation method and applying algorithms designed specifically for SAR imagery, such as the continuous change detection algorithm proposed by Canty.The ROC curve is an important tool for evaluating the performance of different change detection methods, especially in terms of their ability to identify true changes (true positives) versus mislabelled changes (false positives). Historically, this concept was used to differentiate between aircraft and noise (e.g. clouds) in radar signals.The ROC curve can be used to vary the true positive rate by changing the threshold of the classifier to optimise the accuracy of the model predictions. The goal is to maximise true positives (correctly identified aircraft) whilst minimising false positives (incorrectly identified clouds).\n\n\n8.2 Practical\n\n\n8.3 Application\n\n\n\n\n\nDisaster Monitoring Solutions, Source: (NEC?)\n\n\n\n\nSAR technology is extremely widely used in the field of agriculture, which provides strong technical support for crop identification and classification by taking advantage of the unique representation of the canopy structure, geometric properties and dielectric properties of different crops in SAR images. This technique can reveal the subtle changes of crops in different growth stages, which is of great significance for precise agricultural management and optimisation of agricultural production. The accuracy of crop classification can be significantly improved by the combined use of SAR data, optical remote sensing data and ground monitoring data(Dave et al. 2023), For example, the backscattering characteristics of SAR data can be used to accurately distinguish rice under different growing conditions, which provides a scientific basis for crop planting planning and seasonal management.\nSAR data has also demonstrated its unique advantages in monitoring crop development. It can provide detailed information on important agricultural parameters such as biomass, plant height and density, which are essential for assessing crop growth, predicting yields and planning harvests(Aloshree, Vazeer, and K. H. V. Durga, n.d.).In addition, SAR techniques are very effective in assessing soil moisture and vegetation water content, which are important applications for developing irrigation strategies, monitoring drought conditions and improving crop water management.\nIn land cover change monitoring and feature classification, the use of multi-frequency, multi-polarisation SAR data allows for the preservation of geometric features of features in combination with spectral features, texture information and polarisation attributes, which reduces noise interference to a certain extent and improves the accuracy of feature classification(Huang et al. 2023).The use of multi-temporal SAR data allows for the acquisition of more detailed and accurate information on land cover change, which is of great contribution to environmental monitoring, resource management and sustainable development planning. In the field of geological exploration, SAR technology has demonstrated its unique advantages in wide-area and high-precision detection. It can effectively analyse geomorphological features, tectonic phenomena and lithology of rock bodies, which is of great value for geological disaster prevention, resource exploration and environmental assessment, etc. SAR data are particularly suitable for extracting fracture information, analysing regional tectonics, and researching topography and geomorphology, thus providing high-precision data support for geological research and resource development."
  },
  {
    "objectID": "Week_9.html#practical",
    "href": "Week_9.html#practical",
    "title": "8  Week_9 SAR",
    "section": "8.2 Practical",
    "text": "8.2 Practical"
  },
  {
    "objectID": "Week_9.html#application",
    "href": "Week_9.html#application",
    "title": "8  Week_9 SAR",
    "section": "8.3 Application",
    "text": "8.3 Application\n\n\n\n\n\nDisaster Monitoring Solutions, Source: (NEC?)\n\n\n\n\nSAR technology is extremely widely used in the field of agriculture, which provides strong technical support for crop identification and classification by taking advantage of the unique representation of the canopy structure, geometric properties and dielectric properties of different crops in SAR images. This technique can reveal the subtle changes of crops in different growth stages, which is of great significance for precise agricultural management and optimisation of agricultural production. The accuracy of crop classification can be significantly improved by the combined use of SAR data, optical remote sensing data and ground monitoring data(Dave et al. 2023), For example, the backscattering characteristics of SAR data can be used to accurately distinguish rice under different growing conditions, which provides a scientific basis for crop planting planning and seasonal management.\nSAR data has also demonstrated its unique advantages in monitoring crop development. It can provide detailed information on important agricultural parameters such as biomass, plant height and density, which are essential for assessing crop growth, predicting yields and planning harvests(Aloshree, Vazeer, and K. H. V. Durga, n.d.).In addition, SAR techniques are very effective in assessing soil moisture and vegetation water content, which are important applications for developing irrigation strategies, monitoring drought conditions and improving crop water management.\nIn land cover change monitoring and feature classification, the use of multi-frequency, multi-polarisation SAR data allows for the preservation of geometric features of features in combination with spectral features, texture information and polarisation attributes, which reduces noise interference to a certain extent and improves the accuracy of feature classification(Huang et al. 2023).The use of multi-temporal SAR data allows for the acquisition of more detailed and accurate information on land cover change, which is of great contribution to environmental monitoring, resource management and sustainable development planning. In the field of geological exploration, SAR technology has demonstrated its unique advantages in wide-area and high-precision detection. It can effectively analyse geomorphological features, tectonic phenomena and lithology of rock bodies, which is of great value for geological disaster prevention, resource exploration and environmental assessment, etc. SAR data are particularly suitable for extracting fracture information, analysing regional tectonics, and researching topography and geomorphology, thus providing high-precision data support for geological research and resource development."
  },
  {
    "objectID": "Week_9.html#reference",
    "href": "Week_9.html#reference",
    "title": "8  Week_9 SAR",
    "section": "8.4 Reference",
    "text": "8.4 Reference\n\n\n\n\nAloshree, Choudhury, Mahammood Vazeer, and Rao K. H. V. Durga. n.d. “Rice Mapping and Various Stages of Rice Growth Using Sentinel-1 SAR Data-a Case Study of Mahabubnagar District, Telangana.” https://www.ijrte.org/portfolio-item/c72590911322/.\n\n\nDave, Rucha B., Koushik Saha, Amit Kushwaha, Manisha Vithalpura, Nidhin P, and Abishek Murugesan. 2023. “Analysing the Potential of Polarimetric Decomposition Parameters of Sentinel1 Dual-Pol SAR Data for Estimation of Rice Crop Biophysical Parameters.” Journal of Agrometeorology 25 (1): 105–12. https://doi.org/10.54386/jam.v25i1.2039.\n\n\nHuang, Yabo, Mengmeng Meng, Zhuoyan Hou, Lin Wu, Zhengwei Guo, Xiajiong Shen, Wenkui Zheng, and Ning Li. 2023. “Land Cover Classification of SAR Based on 1DCNN-MRF Model Using Improved Dual-Polarization Radar Vegetation Index.” Remote Sensing 15 (13): 3221. https://doi.org/10.3390/rs15133221."
  }
]