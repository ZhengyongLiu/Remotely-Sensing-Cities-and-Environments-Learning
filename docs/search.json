[
  {
    "objectID": "Week_1.html#knowledge-gain-from-the-lecture",
    "href": "Week_1.html#knowledge-gain-from-the-lecture",
    "title": "1  Week_1",
    "section": "1.1 Knowledge gain From the Lecture",
    "text": "1.1 Knowledge gain From the Lecture\n\nThis week’s learning journey into the realm of remote sensing, unveiling the intricate world of electromagnetic waves and their interactions with Earth’s surface. Remote sensing, as I’ve learned, involves acquiring information about objects or areas from a distance, typically from aircraft or satellites, and is a vital tool in understanding our planet.\n\n\n1.1.1 Foundational Concepts of Remote Sensing\n\nOne of the foundational concepts we explored was the difference between passive and active remote sensing. Passive remote sensing relies on natural energy, usually from the sun, whereas active remote sensing systems emit their own energy to illuminate objects. This distinction is crucial for understanding the varied applications of remote sensing technologies like LiDAR, radar, and satellite imagery in observing earth’s landscapes, urban areas, and atmospheric conditions.\n\n\n\n\n\nPassive & Active Remote Sensing, Source: Abeer Nazar Abdul-Hameed\n\n\n\n\n\n\n\n1.1.2 Electromagnetic Waves: Core of Remote Sensing\n\nMuch of our learning knowledge focused on electromagnetic waves, the heart of remote sensing. These waves, a form of energy that propagates through electric and magnetic fields, are the backbone of how remote sensors collect data. Remote sensing is based on this principle to detect the reflection of electromagnetic waves by surface objects and their emission of electromagnetic waves, so as to extract information about these objects and complete the identification of objects at a distance.\n\n\n\n\n\n\nThe Electromagnetic Spectrum, Source: Cssonawala\n\n\n\n\n\n\n1.1.3 Interactions with Earth’s Surface\n\nWe have looked at the complexities of how electromagnetic radiation (EMR) interacts with the Earth’s surface. EMR can be absorbed, transmitted or scattered by the surface and atmosphere. Scattering, in particular, explains phenomena such as the blue colour of the sky or the blackness of the lunar sky due to the absence of an atmosphere.\n\n\n\n\n\n\nInteraction of EMR with Earth’s Surface, Source: Geographicbook\n\n\n\n\n\n\n1.1.4 Synthetic Aperture Radar (SAR) and its Applications\n\nThe Synthetic Aperture Radar (SAR) was another fascinating topic. SAR’s ability to ‘see through clouds’ using longer wavelengths is revolutionary, offering a consistent observation capability irrespective of weather conditions. This technology’s potential in areas like topography, vegetation analysis, and urban planning is immense, showcasing how advanced remote sensing techniques can overcome environmental challenges\nThe study of SAR data also introduced us to the concept of polarization, a property of electromagnetic waves that describes their oscillation direction. This property is crucial for understanding how radar signals interact with different surface properties and is instrumental in enhancing the efficiency and bandwidth of communications.\n\n\n\n1.1.5 Technical Insights and Data Formats in Remote Sensing\n\nOn the technical side, we learned about the different data formats used in remote sensing, such as GeoTIFF, and the importance of resolutions - spatial, spectral, temporal and radiometric. These resolutions define the quality and type of data acquired, and influence how effectively we can interpret and use the data for various applications such as land cover mapping and environmental monitoring.\nIn the literature, these concepts are used to analyse environmental change, urban development and geological features. Understanding remote sensing data and their interpretation is essential for researchers and policy makers to make informed decisions."
  },
  {
    "objectID": "Week_1.html#reflecting-from-the-practical",
    "href": "Week_1.html#reflecting-from-the-practical",
    "title": "1  Week_1",
    "section": "1.2 Reflecting From the Practical",
    "text": "1.2 Reflecting From the Practical\n\n1.2.1 Using of SNAP\nI am still trying to figure out how to fix the bug with snap while using the MacOS."
  },
  {
    "objectID": "Week_1.html#reflecting-from-the-lecture",
    "href": "Week_1.html#reflecting-from-the-lecture",
    "title": "1  Week_1",
    "section": "1.2 Reflecting From the Lecture",
    "text": "1.2 Reflecting From the Lecture\n\nReflecting on the week’s learning, I am struck by the profound impact that remote sensing has on our understanding of the world. The ability to observe and analyse our planet from a distance provides a unique perspective that is not possible through ground-based observations alone. It literally allows us to see the bigger picture, providing a comprehensive understanding of large-scale environmental patterns, urban development and even climate change.\nRemote sensing is interdisciplinary in nature. It’s not just a tool for geographers or environmental scientists; it integrates physics, engineering, environmental science and even policy-making. This integration demonstrates the collaborative effort required to address complex global issues. For example, remote sensing data can inform policies on urban planning, agricultural practices and disaster management, making it a critical tool for sustainable development.\nAnother aspect is the rapid evolution of remote sensing technology. With innovations such as high-resolution imagery and real-time data analysis, the potential applications of this technology are expanding at an incredible rate."
  },
  {
    "objectID": "Week_1.html#reference",
    "href": "Week_1.html#reference",
    "title": "1  Week_1",
    "section": "1.4 Reference",
    "text": "1.4 Reference\n\n\n\n\nAdhikary, Saju, Benukar Biswas, Manish Kumar Naskar, Bishal Mukherjee, Aditya Pratap Singh, Kousik Atta, Saju Adhikary, et al. 2022a. “Remote Sensing for Agricultural Applications.” In. IntechOpen. https://doi.org/10.5772/intechopen.106876.\n\n\n———, et al. 2022b. “Remote Sensing for Agricultural Applications.” In. IntechOpen. https://doi.org/10.5772/intechopen.106876.\n\n\nHu, Jun, Lei Zhang, Changwook Lee, and Rong Gui. 2022. “Editorial: Advanced Big SAR Data Analytics and Applications.” Frontiers in Environmental Science 10. https://www.frontiersin.org/articles/10.3389/fenvs.2022.1063376.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. https://www.jstor.org/stable/24102069.\n\n\nTorres Gil, Leydy K., David Valdelamar Martínez, and Manuel Saba. 2023. “The Widespread Use of Remote Sensing in Asbestos, Vegetation, Oil and Gas, and Geology Applications.” Atmosphere 14 (1): 172. https://doi.org/10.3390/atmos14010172.\n\n\nZhou, Jianming. 2023. “Application of Remote Sensing Technology in Urban Environment Monitoring.” In. CRC Press.\n\n\nZhou, Qifeng. 2023. “Application of Remote Sensing Technologies in Environmental Monitoring and Geological Surveys.” Applied and Computational Engineering 3 (May): 178–85. https://doi.org/10.54254/2755-2721/3/20230403."
  },
  {
    "objectID": "Week_3.html#knowledge-gain-from-the-lecture",
    "href": "Week_3.html#knowledge-gain-from-the-lecture",
    "title": "3  Week_3",
    "section": "3.1 Knowledge gain From the Lecture",
    "text": "3.1 Knowledge gain From the Lecture\n\nThis week’s study focuses on remote sensing image processing, with the main areas of interest being geometric corrections, atmospheric corrections, orthometric corrections, radiometric corrections and various image enhancement techniques.\n\n\n3.1.1 Correction\n\n3.1.1.1 Geometric Correction\n\nGeometric correction is the basis of image correction and addresses image distortion due to sensor and other factors. The goal of this correction is to make the image conform to the selected map projection system, adjusting the geometry of the entire image by modelling the relationship between control points (points with known geographic coordinates) on the image and the image coordinates.\n\n\n\n\n\n\nHow Geometric Correction Work, Source: Xiaopeng\n\n\n\n\n\n\n3.1.1.2 Atmospheric Correction\n\nAtmospheric corrections are essential to address distortions and inaccuracies in remotely sensed images caused by variations in the Earth’s atmosphere, sensor angles, and terrain. Several different correction methods were learned in class: Relative Atmospheric Correction, Pseudo-Invariant Correction, Absolute Atmospheric Correction, and Empirical Line Correction.\n\nThe different methods and characteristics of atmospheric correction have been summarised in the table below:\n\n\n\n\n\n\n\n\nMethod\nKey Steps\nFeature\n\n\n\n\nRelative\nSpectrally stable landmarks, linear relations, band operation\nConsistency between images\n\n\nAbsolute\nComplex models for atmospheric effects, surface reflectance\nPrecise, accurate surface information\n\n\nPseudo-Invariant\nHigh-quality reference, PIF, linear regression\nStable reference points, reduce atmospheric effects\n\n\nEmpirical Line\nGround reflectance, average DN values, linear regression\nUtilizes ground data for satellite correction\n\n\n\n\n\n3.1.1.3 Radiometric Correction\n\nThe role of radiometric correction in adjusting the pixel values of satellite imagery to accurately reflect the radiation at the Earth’s surface has been investigated. The main objective of radiometric correction is to convert the raw digital numbers (DN) acquired into physically meaningful units such as radiance or reflectance. This conversion is critical because DN values are arbitrary and can vary between sensors, acquisitions and platforms, making it difficult to consistently compare and analyse data. By converting DN values to radiance or reflectance, radiometric correction enables quantitative measurements and meaningful comparisons between different images and sensors.\n\n\n\n\n\n\nProcess of Radiometric Calibration\n\n\n\n\n\n\n3.1.1.4 Reflection of Collerallation\n\nIn the course of study, certain questions arise as to when atmospheric corrections are needed and whether or not the images we buy or otherwise acquire have been atmospherically corrected. In layman’s terms, if we need to use an image that truly reflects the Sun’s radiation for quantitative inversion or to obtain information about the Earth, accurately identify features, etc., then we need to make an atmospheric correction. When we buy an image, the description document says that it is radiometrically corrected. In fact, this radiometric correction refers to the coarse radiometric correction, which is just a systematic atmospheric correction, which has the same meaning as the systematic geometric correction.\nAt the moment there are many models and methods on the market, since there are how many methods, then there is the problem of method selection. Here is a summary for reference:\n\nif it is a fine quantitative study, then choose the atmospheric correction method based on the radiative transfer model.\nif you are doing dynamic monitoring, then you can choose relative atmospheric correction or simpler methods.\nif the parameters are missing, there is no choice but to choose the simpler method.\n\n\n\n\n\n3.1.2 Data Join Sets/Enhancement\n\n3.1.2.1 Data Join Sets\n\nAn area may need more than one satellite image to be spliced, using mosaic in the R package for the two datasets to be spliced. When selecting images, try to select two images with similar time and date, due to the different date of the image, the image display is different, the reason may be (cloud cover, sunshine), need to use the image increase technique to operate.\n\n\n\n\n3.1.3 Enhancement\n\n3.1.3.1 Ratio\n\nThe ratio is the difference between two spectral bands with a specific spectral response, using CampTown’s data for NDVI (The Normalised Difference Vegetation Index) The Normalised Difference Vegetation Index is based on the fact that healthy and green vegetation reflects more in the near infrared but absorbs in the red wavelengths. Therefore, the red wavelength band is used for the operation in the formula below.\n\\[\nNDVI = \\frac{NIR - Red}{NIR + Red}\n\\]\nThe following figure shows the image after manipulation for NDVI (a. After NDVI Formula, b. Extraction only if NDVI is equal to or greater than 0.2)\n\n\n\n\n\n\nProcess of Radiometric Calibration\n\n\n\n\nThis case above can be applied to other index calculations such as NDWI (Normalised Difference Water Index) and NDDI (Normalised Difference Drought Index). These are calculated using the reflectance of different objects in different light waves.\n\n\n3.1.3.2 Texture\n\nThe extraction method of texture features is relatively simple, it is to use an active window to slide continuously on the image, calculate the variance, mean, maximum, minimum and the difference between the two and the information entropy in the window, etc., respectively, to form the corresponding texture image, when the spectral characteristics of the target are relatively close to each other, the texture features can play a positive role in distinguishing the target. When the spectral characteristics of the target are close, the texture features can play a positive role in distinguishing the target. After selecting the appropriate dynamic range of the data and extracting the texture features, the texture features of the image can be highlighted, which is conducive to the extraction of constructive information. Below is an example of a texture treatment for the Cape Town area.\n\n\n\n\n\n\nAfter of Texture Process"
  },
  {
    "objectID": "Week_3.html#application-in-literature",
    "href": "Week_3.html#application-in-literature",
    "title": "3  Week_3",
    "section": "3.2 Application in Literature",
    "text": "3.2 Application in Literature\n\nImage correction is a critical step in remote sensing to ensure the accuracy and usability of data obtained from satellite or aerial imagery. Radiometric correction involves adjusting digital image data to correct for sensor noise, sensor response variations and atmospheric conditions. Various methods have been proposed for radiometric correction of remote sensing images. Duan(2014) proposed a radiation correction method that replaces artificial targets with standard ground objects, resulting in accurate and precise correction. Tarasenkov(2019) developed a program complex for atmospheric correction of satellite images that considers radiation polarization.\nGeometric correction corrects the image so that the proportions are uniform throughout the image. This correction is essential for accurate mapping and measurement tasks. Geometric correction is useful for removing spatial distortion, aligning images of the same sample, and stitching overlapping images together.(Yan et al. 2023). Various methods and devices have been developed for geometric correction, including those based on orthographic images and homonymous point matching. These techniques improve the accuracy and stability of the geometric information in the corrected image(Özciḣan et al. 2023).\nAtmospheric correction is necessary for various remote sensing applications to improve the accuracy and reliability of derived information. Different algorithms, such as 6S, FLAASH, DOS, LaSRC, and Sen2Cor, have been evaluated for their performance in atmospheric correction(Muchsin et al. 2023). Atmospheric corrections are essential for a variety of applications such as aircraft navigation, astronomical observations and accurate estimation of cloud heights(Shah, Raval, and Divakaran 2022). It ensures that satellite images provide reliable and accurate results by taking into account atmospheric disturbance(Jonah and Aketi, n.d.).\nImage enhancement technology aims to improve the quality and visual effect of remote sensing images. Various methods have been proposed to enhance these images, including histogram modification, transform domain methods, and hybrid approaches. Histogram modification methods focus on modifying the histogram of the input image to achieve a more uniform distribution, resulting in better contrast improvement. Transform domain methods apply specific transforms to enhance the image in the transform domain, leading to better edge enhancement and color preservation(Wang et al. 2023). Hybrid methods, which combine histogram modification and transform domain methods, have shown higher potential in enhancing remote sensing images(Deng et al. 2023). These enhancement techniques are crucial for image interpretation, improving image segmentation accuracy, and facilitating downstream tasks."
  },
  {
    "objectID": "Week_3.html#personal-reflection",
    "href": "Week_3.html#personal-reflection",
    "title": "3  Week_3",
    "section": "3.3 Personal Reflection",
    "text": "3.3 Personal Reflection\n\nAs a student diving deep into remote sensing image correction technologies, it truly broadened my knowledge and also deepened my understanding of its complexities and challenges. I realized that although these technologies are crucial for enhancing the quality of image data, implementing them is not as straightforward as it might seem. For instance, radiometric correction sounds advanced, but if we lack precise ground objects for reference, the accuracy of the whole process becomes questionable. This got me thinking about whether we need to develop more adaptive correction methods that can adjust to varying conditions.\nThen there’s geometric correction, which indeed seems capable of solving issues with inconsistent image proportions, but if our initial data is not of good quality, or the processing is too complex, how do we balance precision with practical feasibility? It made me realize that sometimes we might need to find a balance between ideal accuracy and operational simplicity.\nWhen it comes to atmospheric correction, I was intrigued by the performance differences of various algorithms under specific conditions. This highlights the importance of selecting the right correction algorithm for reliable data, and also hints at the necessity for more detailed comparisons of algorithms in future research.\nRegarding image enhancement technologies, while they can make images appear clearer, I also began to worry about whether these techniques might inadvertently alter some crucial features in the images. This made me recognize the need to carefully maintain the authenticity of images while pursuing visual improvements.\nOverall, delving into remote sensing image correction technologies not only taught me about the importance of these techniques but also exposed the various challenges that need to be overcome in practical applications. It made me more aware that alongside technological innovation, a careful evaluation and improvement of existing methods are necessary to ensure we can enhance data quality while maintaining operational feasibility and data authenticity."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "3  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliography",
    "section": "",
    "text": "‘Remote Sensing - NASA’, n.d. https://www.nasa.gov/directorates/somd/space-communications-navigation-program/remote-sensing/.\n‘Types Of Remote Sensing: Devices And Their Applications’, 18 November 2020. https://eos.com/blog/types-of-remote-sensing/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote sensing learning Diary",
    "section": "",
    "text": "Preface\nThis is a Learning Diary of CASA0023 Remotely Sensing Cities and Environments.\n\n\nAdd more in the future"
  },
  {
    "objectID": "Week_3.html#application-in-literature-unfinished",
    "href": "Week_3.html#application-in-literature-unfinished",
    "title": "3  Week_3",
    "section": "3.2 Application in Literature (Unfinished)",
    "text": "3.2 Application in Literature (Unfinished)\nImage correction is a critical step in remote sensing to ensure the accuracy and usability of data obtained from satellite or aerial imagery. Radiometric correction involves adjusting digital image data to correct for sensor noise, sensor response variations and atmospheric conditions. Various methods have been proposed for radiometric correction of remote sensing images. Duan(2014) proposed a radiation correction method that replaces artificial targets with standard ground objects, resulting in accurate and precise correction@duan2014.Tarasenkov et al. developed a program complex for atmospheric correction of satellite images that considers radiation polarization@tarasenkov2019.\n几何校正对图像进行校正，使整个图像的比例均匀。这种校正对于准确的绘图和测量任务至关重要。几何校正对于消除空间失真、对齐同一样本的图像以及将重叠图像缝合在一起非常有用@yan2023。人们已经开发了各种用于几何校正的方法和设备，包括基于正射图像和同名点匹配的方法和设备。这些技术提高了校正图像中几何信息的准确性和稳定性。; Özciḣan et al. (2023)\nAtmospheric correction is necessary for various remote sensing applications to improve the accuracy and reliability of derived information. Different algorithms, such as 6S, FLAASH, DOS, LaSRC, and Sen2Cor, have been evaluated for their performance in atmospheric correction@muchsin2023. 大气校正对于飞机导航、天文观测和准确估计云高等各种应用至关重要@shah2022。它通过考虑大气干扰来确保卫星图像提供可靠且精确的结果。; “Atmospheric Correction of Landsat Image | Journal of Environmental and Geographical Studies” (n.d.)\nimage enhancement technology aims to improve the quality and visual effect of remote sensing images. Various methods have been proposed to enhance these images, including histogram modification, transform domain methods, and hybrid approaches. Histogram modification methods focus on modifying the histogram of the input image to achieve a more uniform distribution, resulting in better contrast improvement. Transform domain methods apply specific transforms to enhance the image in the transform domain, leading to better edge enhancement and color preservation@wang2023. Hybrid methods, which combine histogram modification and transform domain methods, have shown higher potential in enhancing remote sensing images@deng2023. These enhancement techniques are crucial for image interpretation, improving image segmentation accuracy, and facilitating downstream tasks."
  },
  {
    "objectID": "Week_3.html#personal-reflection-unfinished",
    "href": "Week_3.html#personal-reflection-unfinished",
    "title": "3  Week_3",
    "section": "3.3 Personal Reflection (Unfinished)",
    "text": "3.3 Personal Reflection (Unfinished)\n\nAs a student diving deep into remote sensing image correction technologies, it truly broadened my knowledge and also deepened my understanding of its complexities and challenges. I realized that although these technologies are crucial for enhancing the quality of image data, implementing them is not as straightforward as it might seem. For instance, radiometric correction sounds advanced, but if we lack precise ground objects for reference, the accuracy of the whole process becomes questionable. This got me thinking about whether we need to develop more adaptive correction methods that can adjust to varying conditions.\nThen there’s geometric correction, which indeed seems capable of solving issues with inconsistent image proportions, but if our initial data is not of good quality, or the processing is too complex, how do we balance precision with practical feasibility? It made me realize that sometimes we might need to find a balance between ideal accuracy and operational simplicity.\nWhen it comes to atmospheric correction, I was intrigued by the performance differences of various algorithms under specific conditions. This highlights the importance of selecting the right correction algorithm for reliable data, and also hints at the necessity for more detailed comparisons of algorithms in future research.\nRegarding image enhancement technologies, while they can make images appear clearer, I also began to worry about whether these techniques might inadvertently alter some crucial features in the images. This made me recognize the need to carefully maintain the authenticity of images while pursuing visual improvements.\nOverall, delving into remote sensing image correction technologies not only taught me about the importance of these techniques but also exposed the various challenges that need to be overcome in practical applications. It made me more aware that alongside technological innovation, a careful evaluation and improvement of existing methods are necessary to ensure we can enhance data quality while maintaining operational feasibility and data authenticity."
  },
  {
    "objectID": "Week_4.html#summary-of-the-policy-and-city",
    "href": "Week_4.html#summary-of-the-policy-and-city",
    "title": "4  Week_4",
    "section": "4.1 Summary of the Policy and City",
    "text": "4.1 Summary of the Policy and City\n\n4.1.1 Dublin City\n\nDublin’s exposure to flood risk is influenced by a number of factors, including urbanisation and climate change(Paranunzio et al. 2022a). This city on the coast has a complex system of rivers, canals, surface water sewers, sewers and urban watercourses, making it particularly sensitive to flooding. Causes of flooding include sea level rise, runoff water, heavy rainfall, extreme events, storms and tidal fluctuations. Flooding events caused by extreme weather have increased significantly over the last decade and this is expected to continue. It is also expected that the number of days of heavy rainfall per year will increase, leading to an increased risk of fluvial (fluvial) and pluvial (pluvial) flooding(Paranunzio et al. 2022b).\nAlso sea level rise in Dublin is an important consideration. As a result of climate change, Dublin City Council has undertaken a review of existing coastal flood defences to ensure they provide protection for the city region. Records show that average sea levels in Dublin Bay have risen faster than the global average between 2000 and 2016(Shoari Nejad et al. 2022).\n\n\n\n4.1.2 Policy Background\n\nThe Dublin City Development Plan (DCDP) 2016-2022 includes a key component, the Strategic Flood Risk Assessment (SFRA). This plan is intended to guide the direction and location of development in Dublin City over the life of the plan(Dublin City Council 2020a). It provides an integrated and coherent spatial framework to ensure that the city develops in an inclusive manner, whilst enhancing the quality of life for its citizens and making Dublin a more attractive place to live and work. This plan was adopted by Dublin City Council at a special meeting on 23rd September 2016 and came into force on 21st October 2016\nThe Strategic Flood Risk Assessment (SFRA) is Volume 7 of the Dublin City Development Plan (DCDP) and is specifically designed to assess and manage flood risk. The purpose of the assessment is to comply with the requirements of the Floods Directive and flood risk/hazard maps are being produced to enable the development of a comprehensive Flood Risk Management Scheme (FRAMS)(Dublin City Council 2020b). The plan also addresses project-specific flood defense infrastructure to protect the more vulnerable parts of the city.\n\n\n\n\n\nExample of Flood Risk Assessment Map( Liffey: Sean Heuston Br. – Sarah Bridge, South Circular Road), Source: Dublin City Council\n\n\n\n\n\n\n\n\n\nExample of Flood Alleviation Programme ( Liffey: Sean Heuston Br. – Sarah Bridge, South Circular Road), Source: Dublin City Council\n\n\n\n\nDublin City Council is also working on various projects to address areas of the city that are susceptible to coastal flooding during extreme events and therefore require new protection works. These projects include the South Bank Flood Defence Project, Sandymount Promenade and Flood Defence Project(O’Connell, n.d.), and Clontarf Promenade Development and Flood Defence Project(Cooke et al. 2005). As part of the Sutton to Sandycove promenade and cycle path project(Lyne 2021), the part of the scheme nearer to Bull Island has commenced and includes flood defence work.\n\n\n\n4.1.3 Policy & Objectives\n\n\nClimate Change Mitigation and Adaptation: Implementing strategies to address climate change impacts on flooding.\nStrategic Flood Risk Assessment: Conducting assessments to inform and improve the city’s flood defenses.\nSustainable Environmental Infrastructure: Mitigating flood and drought effects through environmental assessments and planning.\nDevelopment Compliance: Ensuring new developments respect and enhance existing flood defense mechanisms.\nSustainable Urban Drainage Systems (SUDS): Mandating SUDS in new developments for better water management.\nSite-Specific Flood Risk Assessments: Requiring detailed flood risk analyses for all new development proposals.\nCollaborative Flood Management: Working with neighboring authorities and incorporating catchment-based flood risk management plans.\nGreen Infrastructure Integration: Utilizing green spaces for flood management, biodiversity, and recreation, in line with SUDS principles."
  },
  {
    "objectID": "Week_4.html#how-should-the-remotely-sense-data-address-the-policy-objectives",
    "href": "Week_4.html#how-should-the-remotely-sense-data-address-the-policy-objectives",
    "title": "4  Week_4",
    "section": "4.2 How should the remotely sense data address the policy objectives",
    "text": "4.2 How should the remotely sense data address the policy objectives\n\n洪水风险映射：使用遥感技术在洪水预防方面可以提对其的监测，提供实时数据，并且可以对洪水监测的时效性提供保障(Diao, Sang, and Wang 2022)。可以利用雷达数据重点提取往期洪水淹没区域，分析洪水时空变化特征。同时可以来绘制河流洪水影响的高分辨率地图，并且使用Google Earth Engine 来处理地理空间数据，从而进行洪水风险管理以及洪涝灾害进行监测分析(Colacicco et al. 2022)。\n影响评估和恢复规划：使用遥感数据可以促进洪水后影响评估和恢复规划。遥感技术为洪水淹没绘图提供了清晰的空间信息，这对于及时评估损失和规划恢复工作至关重要。通过利用事件后近实时（NRT）遥感数据与实时（RT）志愿者地理信息（VGI）相结合，可以生成洪水概率图来识别需要紧急关注的区域(Luo, Liao, and Shen 2023)。此外，无人机捕获的航空图像可用于重建 3 维模型和数字高程模型，以进行洪水建模和损害评估(Whitehurst et al. 2022)。基于洪水前和洪水后数字高程模型的模拟可以帮助预测未来降雨事件的影响并指导恢复工作 (Sajjad et al. 2023)。\n生态系统和流域管理：使用遥感数据可以改善洪水后影响流域管理。卫星图像等遥感技术可用于监测和评估洪水造成的损害，包括洪水的范围、基础设施的破坏以及土地覆盖和土地利用的变化(Sridharan, Kumar, and Madhur Kumar 2022)。这些信息有助于评估流域开发干预措施的有效性并确定需要改进的领域。地理信息系统（GIS）可以与遥感数据集成，以增强利益相关者和公众对流域规划过程的参与(Quinn et al. 2022)。通过利用 GIS 和遥感数据集，利益相关者可以获得有价值的信息以进行决策和规划(Quinn et al. 2022)。"
  },
  {
    "objectID": "Week_4.html#flooding-data-come-from",
    "href": "Week_4.html#flooding-data-come-from",
    "title": "4  Week_4",
    "section": "4.3 Flooding Data come from",
    "text": "4.3 Flooding Data come from\n爱尔兰公共工程办公室（Office of Public Works, OPW）提供了全国指示性河流地图（National Indicative Fluvial Mapping），这是洪水风险管理的关键工具。这些地图提供了关于洪水范围、危险和风险的详细信息，包括频繁、轻微的洪水事件到非常罕见、极端事件的评估和映射。\n\n\n\n\nColacicco, Rosa, Alberto Refice, Raffaele Nutricato, Annarita D’Addabbo, Davide Oscar Nitti, and Domenico Capolongo. 2022. “High Spatial and Temporal Resolution Flood Monitoring Through Integration of Multisensor Remotely Sensed Data and Google Earth Engine Processing.” https://doi.org/10.5194/egusphere-egu22-4403.\n\n\nDiao, Chao, Guoqing Sang, and JunNuo Wang. 2022. “Research on the Application of Remote Sensing Monitoring to Flood Monitoring Based on Sentinel-1A in Linyi City.” 2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS), April. https://doi.org/10.1109/icgmrs55602.2022.9849305.\n\n\nLuo, Huanzhang, Jingjuan Liao, and Guozhuang Shen. 2023. “Combining Remote Sensing and Social Media Data for Flood Mapping: A Case Study in Linhai, Zhejiang Province, China.” Journal of Applied Remote Sensing 17 (2): 024507. https://doi.org/10.1117/1.JRS.17.024507.\n\n\nQuinn, Nigel W. T., Vamsi Sridharan, John Ramirez-Avila, Sanaz Imen, Huilin Gao, Rocky Talchabhadel, Saurav Kumar, and Walter McDonald. 2022. “Applications of GIS and Remote Sensing in Public Participation and Stakeholder Engagement for Watershed Management.” Socio-Environmental Systems Modelling 4 (October): 18149–49. https://doi.org/10.18174/sesmo.18149.\n\n\nSajjad, Asif, Jianzhong Lu, Xiaoling Chen, Chikondi Chisenga, and Nausheen Mazhar. 2023. “Rapid Assessment of Riverine Flood Inundation in Chenab Floodplain Using Remote Sensing Techniques.” Geoenvironmental Disasters 10 (1): 9. https://doi.org/10.1186/s40677-023-00236-7.\n\n\nSridharan, Vamsi Krishna, Saurav Kumar, and Swetha Madhur Kumar. 2022. “Can Remote Sensing Fill the United States’ Monitoring Gap for Watershed Management?” Water 14 (13): 1985. https://doi.org/10.3390/w14131985.\n\n\nWhitehurst, Daniel, Kunal Joshi, Kevin Kochersberger, and James Weeks. 2022. “Post-Flood Analysis for Damage and Restoration Assessment Using Drone Imagery.” Remote Sensing 14 (19): 4952. https://doi.org/10.3390/rs14194952."
  },
  {
    "objectID": "Week_4.html#applications",
    "href": "Week_4.html#applications",
    "title": "4  Week_4",
    "section": "4.2 Applications",
    "text": "4.2 Applications\n\n4.2.1 How Remote Sensing Data Should Address Policy Objectives\n\n\nFlood Risk Mapping: The use of remote sensing technology in flood prevention can mention its monitoring, provide real-time data, and can provide a guarantee of the timeliness of flood monitoring(Diao, Sang, and Wang 2022).Radar data can be used to focus on the extraction of past flood inundation areas, and to analyse the characteristics of spatial and temporal changes in flooding. At the same time, it can be used to draw high-resolution maps of the impact of river flooding, and use Google Earth Engine to process geospatial data, so as to carry out flood risk management and monitoring of flood disasters(Colacicco et al. 2022).\nImpact Assessment and Recovery Planning: The use of remote sensing data can facilitate post-flood impact assessment and recovery planning. Remote sensing provides clear spatial information for flood inundation mapping, which is critical for timely damage assessment and planning of recovery efforts. By using near real-time (NRT) remote sensing data after a flood event in combination with real-time (RT) volunteer geographic information (VGI), probabilistic flood maps can be generated to identify areas requiring urgent attention(Luo, Liao, and Shen 2023)。In addition, aerial imagery captured by drones can be used to reconstruct 3D models and digital elevation models for flood modelling and damage assessment(Whitehurst et al. 2022). Simulations based on pre- and post-flood digital elevation models can help predict the impact of future rainfall events and guide recovery efforts (Sajjad et al. 2023).\nWatershed management:The use of remote sensing data can improve post-flood impact watershed management. Remote sensing technologies such as satellite imagery can be used to monitor and assess damage caused by floods, including the extent of flooding, infrastructure damage, and changes in land cover and land use (Sridharan, Kumar, and Madhur Kumar 2022). This information helps to assess the effectiveness of watershed development interventions and identify areas for improvement. Geographic Information Systems (GIS) can be integrated with remote sensing data to enhance stakeholder and public participation in the watershed planning process(Quinn et al. 2022). By utilising GIS and remotely sensed datasets, stakeholders can gain valuable information for decision-making and planning(Quinn et al. 2022).\n\n\n\n\n4.2.2 Connecting to the Big Picture\n\n4.2.2.1 With Local Development\n\nThis policy and its associated Strategic Flood Risk Assessment (SFRA) has had a significant impact on the Local Development Strategy, focussing on sustainable infrastructure and flood risk management. The Plan emphasises the importance of managing surface water drainage and the potential impact of local development on downstream watercourses such as the River Carmichael and the River Liffey. It emphasises the need for additional infrastructure to support development sites, Sustainable Urban Drainage Systems (SuDS) to effectively manage surface water run-off and improve water quality(Dublin City Council 2020c).\nSuDS infrastructure has been highlighted as a core strategy in the Local Plan, designed to manage surface water sustainably, whilst ensuring that there is no increased risk of flooding either upstream or downstream. The approach includes a variety of SuDS features such as detention ponds, infiltration trenches and depressions designed to reduce runoff and improve water quality. This holistic water management strategy supports the vision of creating a vibrant and sustainable urban area in Dublin(South Dublin City Council, n.d.).\nIn addition, the Plan sets out the need for a comprehensive review of existing and future infrastructure (including sewerage and water supply networks) to accommodate development while managing environmental impacts. This includes considerations for upgrading existing infrastructure (e.g. water mains and sewerage systems) to meet the needs of new development(South Dublin City Council, n.d.).\n\n\n\n\n\nDublin Flooding Protection Location, Author: I.Cooke\n\n\n\n\n\n\n\n4.2.2.2 With Global Agenda\n\nIn order to address the identified flood risks, the Plan outlines several strategies and measures. These include the Dublin Coastal Flood Protection Project and participation in the EU Interreg Programme IIIB SAFER project which focuses on coastal flood risk. Dublin City Council works closely with the Office of Public Works (OPW), Ireland’s lead agency for flood risk management, under the Catchment Flood Risk Assessment and Management (CFRAM) programme. The programme is at the heart of Ireland’s medium to long term strategy for flood risk reduction and management and involves the production of detailed flood risk maps and management plans for Dublin’s main rivers and coastal areas.(Dublin City Council 2020c)。\nMore broadly the Plan can explicitly link its objectives and strategies to the relevant SDGs, particularly those relating to Sustainable Cities and Communities (SDG 11), Climate Action (SDG 13) and Water Resources Management (SDG 6). By integrating the flood risk management strategy with these objectives, Dublin can demonstrate its commitment to the global sustainable development agenda while addressing local challenges(Anthony F and Max, n.d.)。\nSchemes should ensure compliance with EU Directives relevant to flood risk management, such as the EU Floods Directive, which requires Member States to assess and manage flood risk in order to reduce the impact of flooding on human health, the environment, cultural heritage and economic activities. By aligning the SFRA with these directives, Dublin City Council can integrate European standards into local practice, facilitate cross-border co-operation and share best practice(herve 2021)。\n\n\n\n\n4.2.3 Types of Remotely Sense Data Can be use for the Urban Flooding Analysis\n\n4.2.3.1 General Data\n\nThe following table presents general data\n\n\n\n\n\n\n\n\n\nSatellites\nSensors\nSpectral Measurements\nParameter\n\n\n\n\nLandsat 5, 7, 8\nETM+, OLI\nVisible, Near IR, Middle IR,\nReflectance/True Color Image,\n\n\n\n\nThermal IR\nLand Cover, Surface Inundation\n\n\nTRMM & GPM\nMicrowave\nTMI: 10-85 Ghz; GMI: 10-183 GHZ;\nPrecipitation\n\n\n\nRadiometer and\nPR and DPR (Ku and Ka)\n\n\n\n\nRADAR (TMI, PR,\n\n\n\n\n\nGMI, DPR)\n\n\n\n\nTerra & Aqua\nMODIS\nVisible, Near IR, Middle IR\nReflectance/True Color Image,\n\n\n\n\n\nSurface Inundation, Land Cover\n\n\nSNPP\nVIIRS\nVisible, Near IR, Middle IR\nDay/Night Imagery\n\n\nSMAP\nMicrowave\n1.41 GHz\nSoil Moisture\n\n\n\nRadiometer\n\n\n\n\nSentinel 1A and 1B\nSynthetic\nC-Band\nBackscatter/Surface Inundation\n\n\n\nAperture RADAR\n\n\n\n\n\n(SAR)\n\n\n\n\nSpace Shuttle\nSRTM\nC-Band\nTerrain\n\n\n\n\n4.2.3.2 Global Precipitation Measurement (GPM) Mission\nThe Global Precipitation Measurement (GPM) mission plays a crucial role in analyzing global rainfall patterns. It stands at the forefront of flooding trend analysis, thanks to its comprehensive and derived algorithms. Recognized for its unparalleled popularity and reliability, GPM serves as the primary source of data and analysis method for studying precipitation(Skofronick-Jackson et al. 2018).\nGPM represents an international collaboration, involving a network of satellites dedicated to providing advanced observations of rain and snow across the globe. It builds on the achievements of the Tropical Rainfall Measuring Mission (TRMM) and introduces the concept of a Core Observatory. This central satellite is equipped with sophisticated radar and radiometer systems designed to accurately measure precipitation from space. This Core Observatory also plays a pivotal role in standardizing precipitation measurements collected from a constellation of both research and operational satellites, ensuring consistent and reliable data worldwide(Hou 2012).\n\n\n\n\n\n\n\nGlobal Precipitation Measurement (GPM) Mission, Source: NASA\n\n\n\n\n\n\n4.2.3.3 Relative Data Source Link\n\nGPM IMERG Data Access: https://gpm.nasa.gov/data\nPrecipitation Data Access and Analysis: https://giovanni.gsfc.nasa.gov/giovanni/\nMODerate Resolution Imaging Spectroradiometer (MODIS): https://lpdaac.usgs.gov/ or https://search.earthdata.nasa.gov/\nVisible Infrared Imaging Radiometer Suite (VIIRS): https://worldview.earthdata.nasa.gov/\nSoil Moisture Active Passive (SMAP): https://nsidc.org/data/search#keywords=soil+moisture/\nETC……"
  },
  {
    "objectID": "Week_4.html#reflect-unfinished",
    "href": "Week_4.html#reflect-unfinished",
    "title": "4  Week_4",
    "section": "4.3 Reflect (Unfinished)",
    "text": "4.3 Reflect (Unfinished)\n\nIncorporating the application of remote sensing technologies into the context of the Dublin City Development Plan 2016-2022 and its Strategic Flood Risk Assessment (SFRA) not only broadens the scope of my reflection but also enhances the depth of analysis on how technological advancements can be synergized with urban planning and environmental management practices. This expanded consideration allows for a multifaceted approach towards sustainable urban development, emphasizing the critical role of innovative technologies in addressing complex urban challenges.\nRemote sensing, with its capacity to collect detailed environmental data from a distance, presents an invaluable tool for urban planners and policymakers. By facilitating a comprehensive analysis of land use changes, vegetation cover, water bodies, and urban infrastructure, remote sensing data can significantly contribute to informed decision-making processes. For Dublin, leveraging such technologies means the ability to dynamically monitor urban expansion and its impacts on flood risks, assess vulnerabilities across the urban landscape, and develop targeted strategies for flood mitigation and urban resilience.\nThis integration goes beyond traditional planning methods by enabling a proactive rather than reactive approach to urban development and environmental stewardship. The precision and timeliness of data provided by remote sensing can lead to the early identification of potential flood-prone areas, changes in land cover that may affect hydrological cycles, and the effectiveness of existing flood defense structures. Consequently, this facilitates the optimization of land use planning, infrastructure development, and environmental conservation efforts to mitigate flood risks effectively.\nFurthermore, the application of remote sensing technologies underscores the importance of interdisciplinary collaboration and capacity building among urban planners, environmental scientists, and the broader community. Engaging with a diverse range of stakeholders in the interpretation and application of remote sensing data can foster a more inclusive and participatory approach to urban planning. This collaborative framework not only enhances the understanding and management of flood risks but also promotes a shared sense of responsibility and collective action towards sustainable urban development.\nMoreover, the ongoing advancement in remote sensing technologies, including higher resolution imagery, real-time data acquisition, and improved analytical tools, offers new opportunities for innovation in urban planning and environmental management. As cities like Dublin strive to align their development strategies with global sustainability goals, the integration of such technologies becomes increasingly crucial. It allows for a more nuanced understanding of urban ecosystems, the interconnections between human activities and natural processes, and the pathways towards achieving a harmonious balance between urban development and environmental preservation.\nIn summary, the reflection on integrating remote sensing technologies into Dublin’s urban planning and flood risk management efforts highlights the transformative potential of such tools in advancing sustainable urban development. It points towards a future where technology and data-driven insights become central to crafting resilient, inclusive, and sustainable urban landscapes. This expanded perspective not only enriches my understanding of the complexities involved in urban planning but also inspires a forward-looking approach to leveraging technology for the betterment of our urban environments."
  },
  {
    "objectID": "Week_4.html#reference",
    "href": "Week_4.html#reference",
    "title": "4  Week_4",
    "section": "4.4 Reference",
    "text": "4.4 Reference\n\n\n\n\nAnthony F, Pipa, and Bouchet Max. n.d. “Local Leadership Driving Progress on the Sustainable Development Goals.” https://www.brookings.edu/articles/local-leadership-driving-progress-on-the-sustainable-development-goals/.\n\n\nColacicco, Rosa, Alberto Refice, Raffaele Nutricato, Annarita D’Addabbo, Davide Oscar Nitti, and Domenico Capolongo. 2022. “High Spatial and Temporal Resolution Flood Monitoring Through Integration of Multisensor Remotely Sensed Data and Google Earth Engine Processing.” https://doi.org/10.5194/egusphere-egu22-4403.\n\n\nCooke, I, A D Maguire, O McManus, and B Bliek. 2005. “The Dublin Coastal Protection Project.” WIT Transactions on The Built Environment 78.\n\n\nDiao, Chao, Guoqing Sang, and JunNuo Wang. 2022. “Research on the Application of Remote Sensing Monitoring to Flood Monitoring Based on Sentinel-1A in Linyi City.” 2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS), April. https://doi.org/10.1109/icgmrs55602.2022.9849305.\n\n\nDublin City Council. 2020c. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\n———. 2020a. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\n———. 2020b. “3.5.3 Climate Change and Flood Risk | Dublin City Council.” https://www.dublincity.ie/dublin-city-development-plan-2016-2022/3-addressing-climate-change/35-policies-and-objectives/353-climate-change-and-flood-risk.\n\n\nherve. 2021. “Global Policies in Local Context: Local Transformation Through International Engagement - Platforma.” https://platforma-dev.eu/global-policies-in-local-context-local-transformation-through-international-engagement/, https://platforma-dev.eu/global-policies-in-local-context-local-transformation-through-international-engagement/.\n\n\nHou, Arthur Y. 2012. “Global Precipitation Measurement (GPM) Mission: Overview and Status,” October. https://ntrs.nasa.gov/citations/20120015575.\n\n\nLuo, Huanzhang, Jingjuan Liao, and Guozhuang Shen. 2023. “Combining Remote Sensing and Social Media Data for Flood Mapping: A Case Study in Linhai, Zhejiang Province, China.” Journal of Applied Remote Sensing 17 (2): 024507. https://doi.org/10.1117/1.JRS.17.024507.\n\n\nLyne, Laura. 2021. “Dublin Residents Fearing Worst as Dream Cycleway at Risk Due to Plan Changes.” https://www.dublinlive.ie/news/dublin-news/residents-fear-dream-sutton-sandycove-20368777.\n\n\nO’Connell, Gerard. n.d. “Sandymount Coastal Flood Defence SchemePhase 1&2.”\n\n\nParanunzio, Roberta, Marco Guerrini, Edward Dwyer, Paul J. Alexander, and Barry O’Dwyer. 2022a. “Assessing Coastal Flood Risk in a Changing Climate for Dublin, Ireland.” Journal of Marine Science and Engineering 10 (11): 1715. https://doi.org/10.3390/jmse10111715.\n\n\n———. 2022b. “Assessing Coastal Flood Risk in a Changing Climate for Dublin, Ireland.” Journal of Marine Science and Engineering 10 (11): 1715. https://doi.org/10.3390/jmse10111715.\n\n\nQuinn, Nigel W. T., Vamsi Sridharan, John Ramirez-Avila, Sanaz Imen, Huilin Gao, Rocky Talchabhadel, Saurav Kumar, and Walter McDonald. 2022. “Applications of GIS and Remote Sensing in Public Participation and Stakeholder Engagement for Watershed Management.” Socio-Environmental Systems Modelling 4 (October): 18149–49. https://doi.org/10.18174/sesmo.18149.\n\n\nSajjad, Asif, Jianzhong Lu, Xiaoling Chen, Chikondi Chisenga, and Nausheen Mazhar. 2023. “Rapid Assessment of Riverine Flood Inundation in Chenab Floodplain Using Remote Sensing Techniques.” Geoenvironmental Disasters 10 (1): 9. https://doi.org/10.1186/s40677-023-00236-7.\n\n\nShoari Nejad, Amin, Andrew C. Parnell, Alice Greene, Peter Thorne, Brian P. Kelleher, Robert J. N. Devoy, and Gerard McCarthy. 2022. “A Newly Reconciled Dataset for Identifying Sea Level Rise and Variability in Dublin Bay.” Ocean Science 18 (2): 511–22. https://doi.org/10.5194/os-18-511-2022.\n\n\nSkofronick-Jackson, Gail, Wesley Berg, Chris Kidd, Dalia B. Kirschbaum, Walter A. Petersen, George J. Huffman, and Yukari N. Takayabu. 2018. “Global Precipitation Measurement (GPM): Unified Precipitation Estimation from Space.” In, edited by Constantin Andronache, 175–93. Springer Remote Sensing/Photogrammetry. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-72583-3_7.\n\n\nSouth Dublin City Council. n.d. “Sustainable Drainage Systems (SuDS).” https://www.sdcc.ie/en/services/environment/environmental-health/water-services/sustainable-drainage-systems/https:/www.sdcc.ie/en/services/environment/environmental-health/water-services/sustainable-drainage-systems/sustainable-drainage-systems-suds.html.\n\n\nSridharan, Vamsi Krishna, Saurav Kumar, and Swetha Madhur Kumar. 2022. “Can Remote Sensing Fill the United States’ Monitoring Gap for Watershed Management?” Water 14 (13): 1985. https://doi.org/10.3390/w14131985.\n\n\nWhitehurst, Daniel, Kunal Joshi, Kevin Kochersberger, and James Weeks. 2022. “Post-Flood Analysis for Damage and Restoration Assessment Using Drone Imagery.” Remote Sensing 14 (19): 4952. https://doi.org/10.3390/rs14194952."
  },
  {
    "objectID": "Week_3.html#reference",
    "href": "Week_3.html#reference",
    "title": "3  Week_3",
    "section": "3.4 Reference",
    "text": "3.4 Reference\n\n\n\n\nDeng, Jiqiu, Wuzhou Dong, Yiwei Guo, Xiaoyan Chen, Renhao Zhou, and Wenyi Liu. 2023. “A Novel Remote Sensing Image Enhancement Method, the Pseudo-Tasseled Cap Transformation: Taking Buildings and Roads in GF-2 as an Example.” Applied Sciences 13 (11): 6585. https://doi.org/10.3390/app13116585.\n\n\nDuan, YL, L. Zhang, L. Yan, Taixia Wu, Yan Liu, and Qiuping Tong. 2014. “Relative Radiometric Correction Methods for Remote Sensing Images and Their Applicability Analysis.” Journal of Remote Sensing 18 (January): 597–617. https://doi.org/10.11834/jrs.20143204.\n\n\nJonah, Iyowuna Benjamin, and Taripredo Moses Aketi. n.d. “Atmospheric Correction of Landsat Image | Journal of Environmental and Geographical Studies.” https://gprjournals.org/journals/index.php/JEGS/article/view/120.\n\n\nMuchsin, Fadila, Kuncoro Adi Pradono, Indah Prasasti, Dianovita Dianovita, Kurnia Ulfa, Kiki Winda Veronica, Dandy Aditya Novresiandi, and Andi Ibrahim. 2023. “EFFECT OF ATMOSPHERIC CORRECTION ALGORITHM ON LANDSAT-8 AND SENTINEL-2 CLASSIFICATION ACCURACY IN PADDY FIELD AREA.” International Journal of Remote Sensing and Earth Sciences (IJReSES) 20 (1): 57–65. https://doi.org/10.30536/j.ijreses.2023.v20.a3845.\n\n\nÖzciḣan, Buğrahan, Levent Doğukan Özlü, Mümin İlker Karakap, Halime Sürmeli̇, Ugur Alganci, and Elif Sertel. 2023. “A Comprehensive Analysis of Different Geometric Correction Methods for the Pleiades -1A and Spot-6 Satellite Images.” International Journal of Engineering and Geosciences 8 (2): 146–53. https://doi.org/10.26833/ijeg.1086861.\n\n\nShah, Maitrik, Mehul S Raval, and Srikrishnan Divakaran. 2022. “IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium.” In, 346–49. https://doi.org/10.1109/IGARSS46834.2022.9884900.\n\n\nTarasenkov, M. V., A. V. Zimovaya, V. V. Belov, and M. V. Engel. 2019. “25th International Symposium on Atmospheric and Ocean Optics: Atmospheric Physics.” In, 11208:197–202. SPIE. https://doi.org/10.1117/12.2539123.\n\n\nWang, Yu, Zhenfeng Shao, Tao Lu, Changzhi Wu, and Jiaming Wang. 2023. “Remote Sensing Image Super-Resolution via Multiscale Enhancement Network.” IEEE Geoscience and Remote Sensing Letters 20: 1–5. https://doi.org/10.1109/LGRS.2023.3248069.\n\n\nYan, Shi, Liuwei Sheng, Gu Chao, Liu Hui, Zhang Yang, and Huangchun Hao. 2023. “Multi-Source Satellite Remote Sensing Image Processing and Processing Method Based on Geometric Correction Model.” In, edited by Roumen Kountchev, Kazumi Nakamatsu, Wenfeng Wang, and Roumiana Kountcheva, 293–303. Smart Innovation, Systems and Technologies. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-7184-6_26."
  },
  {
    "objectID": "Week_1.html#application",
    "href": "Week_1.html#application",
    "title": "1  Week_1",
    "section": "1.2 Application",
    "text": "1.2 Application\n\nThroughout the week, remote sensing technology is a method of observing and analysing the Earth and its atmosphere from a distance using radio waves or other forms of electromagnetic waves. This technology enables imaging and analysis of distant targets in a non-contact manner by collecting and processing electromagnetic wave information from the Earth’s surface and atmosphere. With the development of technology, remote sensing has become an important tool in the field of geographic information science and is widely used in a number of research and practical applications(Q. Zhou 2023). In the field of urban environmental monitoring, remote sensing technology provides an efficient means of monitoring air quality, water quality and land use. Urban sprawl, traffic flow and pollution from industrial activities can be observed and analysed from the air through remote sensing technology, which helps in decision-making for urban planning and environmental protection(J. Zhou 2023).In the area of vegetation monitoring, remote sensing can be used to analyse the health, growth dynamics and coverage of plants, and by analysing reflected and absorbed electromagnetic waves of specific wavelengths, scientists are able to assess important parameters such as the biomass, water content and chlorophyll concentration of vegetation. This information is important for the optimisation of agricultural production, forestry management and ecological conservation(Adhikary et al. 2022a).Geological research has also benefited from the application of remote sensing technology, and by analysing the electromagnetic wave reflection characteristics of the earth’s surface, scientists have been able to identify different rock types, the distribution of mineral deposits and changes in topography and geomorphology. This is of great value for the exploration of mineral resources, the early warning of geological disasters and the monitoring of environmental changes(Torres Gil, Valdelamar Martínez, and Saba 2023).Agriculture is one of the areas in which remote sensing technology is most widely used. In addition to being used for assessing plant health and yield estimation, remote sensing is used to monitor irrigation needs, detect weeds and pests and make weather forecasts. This makes agricultural production more precise and efficient, helping to increase crop yields and reduce resource wastage(Adhikary et al. 2022b).\nIn addition, synthetic aperture radar (SAR) technology, as an advanced remote sensing technology, has a wide range of applications. By using radar waves to penetrate the limitations of cloud cover and lighting conditions, it provides a unique perspective for surface observation. This technology is capable of acquiring high-quality image data under any weather conditions, including dense fog, cloud cover, rain and snow, as well as at night. As a result, SAR has become an important tool for geological exploration, topographic mapping, disaster monitoring and prevention, traffic surveillance, and agricultural and forest monitoring, among other fields.(Hu et al. 2022)。\nSAR systems work by transmitting and receiving microwave signals, using the returned signals to calculate the position, shape and other characteristics of objects on the ground. A key advantage of this active sensing technology is its sensitivity to the type of ground material and moisture content, allowing it to play an important role in monitoring vegetation-covered areas, urban environments and bodies of water, where SAR imagery is unique in analysing surface changes, assessing the impacts of disasters and carrying out environmental monitoring, owing to its unique imaging properties(Navalgund, Jayaraman, and Roy 2007)."
  },
  {
    "objectID": "Week_1.html#reflecting",
    "href": "Week_1.html#reflecting",
    "title": "1  Week_1",
    "section": "1.3 Reflecting",
    "text": "1.3 Reflecting\n\nReflecting on the week’s learning, I am struck by the profound impact that remote sensing has on our understanding of the world. The ability to observe and analyse our planet from a distance provides a unique perspective that is not possible through ground-based observations alone. It literally allows us to see the bigger picture, providing a comprehensive understanding of large-scale environmental patterns, urban development and even climate change.\nRemote sensing is interdisciplinary in nature. It’s not just a tool for geographers or environmental scientists; it integrates physics, engineering, environmental science and even policy-making. This integration demonstrates the collaborative effort required to address complex global issues. For example, remote sensing data can inform policies on urban planning, agricultural practices and disaster management, making it a critical tool for sustainable development.\nAnother aspect is the rapid evolution of remote sensing technology. With innovations such as high-resolution imagery and real-time data analysis, the potential applications of this technology are expanding at an incredible rate."
  },
  {
    "objectID": "Week_1.html#reflection",
    "href": "Week_1.html#reflection",
    "title": "1  Week_1",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\nReflecting on the week’s learning, the profound impact of remote sensing on our understanding of the world is truly remarkable. This technology, with its ability to observe and analyse our planet from afar, offers a unique perspective that ground-based observations simply cannot match. It’s like having a bird’s-eye view of the world, which opens up a whole new dimension in comprehending large-scale environmental patterns, urban sprawl, and the intricate dynamics of climate change.\nWhat strikes me the most is how remote sensing serves as a bridge across various disciplines. It’s not confined to the realm of geography or environmental science; rather, it embodies a synergy of physics, engineering, environmental science, and even policy-making. This multidisciplinary approach highlights the collective effort needed to tackle the complex challenges our world faces today. For instance, the data derived from remote sensing technologies play a pivotal role in shaping policies related to urban planning, optimizing agricultural practices, and enhancing disaster management strategies. It underscores the technology’s indispensability in driving sustainable development forward.\nThe rapid advancement in remote sensing technologies is nothing short of astonishing. Innovations such as high-resolution imagery and the capability for real-time data analysis are broadening the horizons of its applications at an unprecedented pace. These advancements are not only improving our current capabilities but are also paving the way for new possibilities in monitoring and managing the Earth’s resources more effectively. This week’s exploration into the world of remote sensing has deepened my appreciation for this powerful tool and its potential to contribute to a more sustainable and informed future."
  },
  {
    "objectID": "Week_4.html#reflection",
    "href": "Week_4.html#reflection",
    "title": "4  Week_4",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nIncorporating the application of remote sensing technologies into the context of the Dublin City Development Plan 2016-2022 and its Strategic Flood Risk Assessment (SFRA) not only broadens the scope of my reflection but also enhances the depth of analysis on how technological advancements can be synergized with urban planning and environmental management practices. This expanded consideration allows for a multifaceted approach towards sustainable urban development, emphasizing the critical role of innovative technologies in addressing complex urban challenges.\nRemote sensing, with its capacity to collect detailed environmental data from a distance, presents an invaluable tool for urban planners and policymakers. By facilitating a comprehensive analysis of land use changes, vegetation cover, water bodies, and urban infrastructure, remote sensing data can significantly contribute to informed decision-making processes. For Dublin, leveraging such technologies means the ability to dynamically monitor urban expansion and its impacts on flood risks, assess vulnerabilities across the urban landscape, and develop targeted strategies for flood mitigation and urban resilience.\nThis integration goes beyond traditional planning methods by enabling a proactive rather than reactive approach to urban development and environmental stewardship. The precision and timeliness of data provided by remote sensing can lead to the early identification of potential flood-prone areas, changes in land cover that may affect hydrological cycles, and the effectiveness of existing flood defense structures. Consequently, this facilitates the optimization of land use planning, infrastructure development, and environmental conservation efforts to mitigate flood risks effectively.\nFurthermore, the application of remote sensing technologies underscores the importance of interdisciplinary collaboration and capacity building among urban planners, environmental scientists, and the broader community. Engaging with a diverse range of stakeholders in the interpretation and application of remote sensing data can foster a more inclusive and participatory approach to urban planning. This collaborative framework not only enhances the understanding and management of flood risks but also promotes a shared sense of responsibility and collective action towards sustainable urban development. Moreover, the ongoing advancement in remote sensing technologies, including higher resolution imagery, real-time data acquisition, and improved analytical tools, offers new opportunities for innovation in urban planning and environmental management. As cities like Dublin strive to align their development strategies with global sustainability goals, the integration of such technologies becomes increasingly crucial. It allows for a more nuanced understanding of urban ecosystems, the interconnections between human activities and natural processes, and the pathways towards achieving a harmonious balance between urban development and environmental preservation.\nIn summary, the reflection on integrating remote sensing technologies into Dublin’s urban planning and flood risk management efforts highlights the transformative potential of such tools in advancing sustainable urban development. It points towards a future where technology and data-driven insights become central to crafting resilient, inclusive, and sustainable urban landscapes. This expanded perspective not only enriches my understanding of the complexities involved in urban planning but also inspires a forward-looking approach to leveraging technology for the betterment of our urban environments."
  },
  {
    "objectID": "Week_6.html#knowledge-gain-from-the-lecture",
    "href": "Week_6.html#knowledge-gain-from-the-lecture",
    "title": "5  Week_6",
    "section": "5.1 Knowledge gain From the Lecture",
    "text": "5.1 Knowledge gain From the Lecture\nGoogle Earth Engine是Google提供的对大量全球尺度地球科学资料（尤其是卫星数据）进行在线可视化计算和分析处理的云平台。它的特点是允许大规模的地理空间分析，运行速度很快，有在客户端运行的代码，并且将数据储存在的服务器上.\nGEE 中的栅格数据和矢量数据:\n\n栅格数据称为”Image”，具有波段（bands）。\n矢量数据称为”Feature”，具有几何形状和属性（dictionary of properties）。\n\nGEE 中的图像缩放:\n\n指图像的分辨率，即每个像素代表的实际地面距离。\nGEE 会根据分析需求自动选择合适的缩放级别。\n\nGEE中的投影:\nGEE 支持多种投影，包括 Mercator 投影、Albers 投影、等距圆柱投影等。用户可以选择合适的投影进行分析。\n如何使用GEE\n\n\n\n\n\nHow to use GEE, Source: Google Earth Engine\n\n\n\n\nGEE中可以进行的操作：\n\n几何操作：例如空间操作，连接（Joins），区域统计（比如邻域的平均温度），图像或特定值的筛选。\n机器学习，包括监督学习和非监督学习，使用TensorFlow进行深度学习，探索变量之间的关系。\n应用/输出：在线图表，可扩展的使用GEE数据的地理空间应用\n\nGEE中的Reduce the Image :\nReducing the image by region 和 reducing the image by neighbor 都是用于对图像进行区域化或邻域化操作的函数。它们的主要区别在于：\n\nReducing the image by region 是根据指定的区域对图像进行操作。每个区域可以是任意形状，可以重叠。该函数会对每个区域内的所有像素进行指定的计算，并返回一个包含区域统计结果的新图像。\nReducing the image by neighbor 是根据指定的邻域对图像进行操作。每个像素的邻域是指其周围一定范围内的像素。该函数会对每个像素及其邻域内的所有像素进行指定的计算，并返回一个包含像素新值的图像。\n\nGEE中的Linear Regression & Join (暂时写不出来)"
  },
  {
    "objectID": "Week_6.html#practical",
    "href": "Week_6.html#practical",
    "title": "5  Week_6",
    "section": "5.2 Practical",
    "text": "5.2 Practical\n\n5.2.1 Compare with RGB & NDVI\n\n\n\n\n\nCompare with RGB & NDVI\n\n\n5.2.2 PCA Analysis\n选取个区域，首先标准化图像波段，计算协方差矩阵，提取特征值和特征向量，然后将图像数据投影到主成分空间。最后，它将PCA结果的第一主成分展示在地图上。\n\n\n\n\n\nPCA Analysis"
  },
  {
    "objectID": "Week_6.html#applications",
    "href": "Week_6.html#applications",
    "title": "5  Week_6",
    "section": "5.3 Applications",
    "text": "5.3 Applications\n\n5.3.1 General Applications\nGEE一直是遥感大数据处理的关注焦点。GEE是一个基于云的平台，可使用Google的云在全球范围内并行处理地理空间数据。GEE是一个免费的云平台，承载着超过40年的PB规模的遥感数据，例如Landsat，MODIS，美国国家海洋和大气管理局高级超高分辨率辐射计（NOAA AVHRR），Sentinel 1、2、3和5- P; 和高级陆地观测卫星（ALOS）数据(Aghamiri et al., n.d.)。 GEE还包括气候-天气和地球物理数据集。还提供其他现成的产品，例如增强植被指数（EVI）和归一化植被指数（NDVI）。除了可以使用大量原始遥感图像存储库之外，用户还可以访问GEE数据目录中的预处理图像，云去除图像和镶嵌图像 (Ritika, n.d.)。\n\n\n\n\n\nA summary of the algorithms and capabilities available in code editor-Google Earth Engine, Author: (Tamiminia et al. 2020)\n\n\n\n\n下面是一些GEE在实际上的应用。\n\n\n\n\n\nGEE in Different Applications, Author: (Tamiminia et al. 2020)\n\n\n\n\n\n\n5.3.2 GEE和数据类型\n在学术界对于GEE的使用中，大部分都是采用了光学图，其原因很大程度上要归功于Landsat影像的40年免费存档，光学遥感数据仍然是最常用的数据源。GEE数据目录提供了1972年至今的光学卫星图像，使研究人员能够进行地球监测研究(Pham-Duc et al. 2023)。此外，GEE用户的广泛应用表明，光学图像对于非远程传感专家来说更易于处理和解释。这就是为什么GEE在广泛的科学领域中遍及全球的原因之一。同时，SAR和光学卫星数据的结合能够帮助研究人员解决云层遮挡等问题。特别是在热带地区，由于云层的持续覆盖以及森林火灾等情况，光学图像的效能会受到极大影响。因此，结合光学和SAR数据可以提高分类的准确性，并提供更多信息来监测地表变化(Lea et al. 2023).\n\n\n5.3.3 GEE和传感器类型\nLandsat被认为是GEE中重要的遥感数据源，因为它提供了地球表面的连续图像。Landsat 9卫星将于2020年发射，目的是继续执行Landsat计划在监测地球资源方面的关键作用。可以在区域和全球范围内进行长期的土地覆盖变化研究(Pham-Duc et al. 2023)。\nSentinel-1是卫星图像的另一个流行来源，并且取得了非常准确的分类结果。Sentinel-1由两颗卫星组成，分别由2014年和2016年发射的Sentinel-1A和Sentinel 1-B组成，空间分辨率为10 m，重访时间为6天(Arias Cuenca 2023)。它配备了双极化C波段SAR传感器，可以在全天候，白天和夜晚的情况下提供数据。Sentinel-2任务包括两颗卫星组成的星座，即Sentinel-2A（于2015年发射）和Sentinel-2B（于2017年发射），它们提供空间分辨率为10 m，20 m和60 m的光学图像，以及大约5天的时间分辨率(Xu, Heremans, and Somers 2022; Lechner et al. 2022)\n中分辨率成像光谱仪（MODIS）于1999年在Terra卫星上发射，并在2002年在Aqua卫星上发射。研究人员可以在1天的重访时间访问36个光谱带和三种变化的空间分辨率（250 m，500 m和1 km）的GEE中的MODIS数据。即使MODIS的空间分辨率很低，它的高时间分辨率也使研究人员可以监视短期和长期的全球环境变化（动力学）(Wu and Xiong 2020)。\n\n\n5.3.4 遥感数据分析\n\n5.3.4.1 机器学习技术\n机器学习是人工智能的一个子集，它处理算法设计以训练模型以做出决策或预测。机器学习方法可分为两大类：参数化和非参数化。参数化机器学习算法使用固定数量的参数或假设。机器学习方法已被有效地用于遥感数据处理。分类，聚类，回归和降维是机器学习算法的四个主要分析类别(Shaveta 2023)。 回归是一种监督式机器学习方法，旨在基于一组协变量来估计或预测输出变量。线性回归的另一个积极方面是它的快速计算速度，这是地理大数据分析中的重要因素(“Google Earth Engine and Machine Learning for Earth Monitoring,” n.d.)。同时MLR模型在预测过程中会处理因变量和自变量之间的非线性关系。\n\n\n5.3.4.2 其他GEE图像处理功能\nGEE提供了多种图像处理工具，适用于遥感数据的分析。这些工具涵盖了时间序列分析、特征提取、图像的彩色合成以及图像预处理等方面，主要针对卫星图像，而不是基于机器学习的方法(“Google Earth Engine and Machine Learning for Earth Monitoring,” n.d.)。随着地球表面快速变化，卫星图像的时间序列分析变得至关重要，它帮助追踪趋势、监测变化并发展预测模型。GEE因其能处理高分辨率或大量数据而在多项研究中被用于此类分析，特别是在监测地表变化方面表现出色。特征提取技术，通过分析图像的光谱和几何属性，帮助识别图像中的区域关系，这对于资源节约和信息保留非常关键(Pham-Duc et al. 2023)。另外，GEE的视觉解释工具在土地监测研究中广泛应用，通过色彩合成图像提取关键信息。此外，GEE的图像预处理功能支持图像镶嵌、云层处理和错误检测，尽管云覆盖是处理光学数据时的主要挑战，但GEE提供了有效的工具和算法以支持这些工作(Lea et al. 2023)。"
  },
  {
    "objectID": "Week_6.html#reflection",
    "href": "Week_6.html#reflection",
    "title": "5  Week_6",
    "section": "5.4 Reflection",
    "text": "5.4 Reflection\nGEE已经成为最受欢迎的地理空间和大数据分析平台之一。尽管如此，仍然有扩展的空间。特别是，GEE为地理空间处理提供了一个易于使用且免费的平台，但是用户无法控制可能导致某些计算问题的并行处理环境的细节。这意味着GEE管理着计算的各个方面，例如源分配，并行性，数据分发和重试，而用户无法影响自己动手（DIY）并行化（Gorelick et al.，2017）。通常，GEE限制可分为三大类：计算，数据集和算法。 值得注意的是，GEE具有一些计算限制，包括时间，内存和存储。关于时限问题，GEE中有两种计算模式：按需和批处理。前者处理的运行次数有限，而后者可以在代码运行时运行。因此，将批处理用于大量计算是合理的，因为任务以按需模式运行。此外，在某些情况下，对大量数据集执行处理时，GEE可能会遇到内存问题。尽管脚本可能是没有逻辑错误的有效JavaScript，但是有时用户在并行化和执行计算时会遇到内部错误，例如内部服务错误，计算超时，超出用户内存限制以及过多的并发聚合。这些错误称为缩放错误，当输出太大，数量太多或计算时间很长时，可能会发生。关于存储，用户可以将结果保存在Google云端硬盘，Google云和GEE资产中。但是，应考虑将有限的250 GB容量用于在GEE资产中保存数据。GEE表资产的大小和形状也有一些限制。 尽管GEE包含大量的图像档案，但是对于许多研究而言，历史和高分辨率数据的价值有限。具体而言，在GEE中有13％的研究专注于灾难测绘，尤其是干旱监测。GEE还可以提供可靠的信息来监视其他灾难，例如地震和洪水图。此外，GEE当前提供高分辨率图像，包括RGB和多光谱集合中的国家农业图像计划（NAIP）和Planet Skysat。美国NAIP提供1 m分辨率的航拍图像数据。自2003-2018年以来，这些图像在GEE中可用，周期为3年和5年。从2014年到2016年，GEE还提供RGB和多光谱/平移集合的Planet Skysat影像。RGB影像以0.8 m分辨率（离地面最低图像1 m）提供，而R，G，B，近红外波段具有约2 m的分辨率，泛波段具有0.8分辨率（离最低点为1 m）。因此，需要高空间和时间分辨率的图像。 到目前为止，Sentinel-1图像是GEE中唯一可用的SAR数据；然而，通过增加从ALOS PALSAR收集的L波段数据来满足多种应用的需求，需要更长的波长，例如作物制图，开辟了新的途径。与具有中等渗透能力并主要与树冠上部相互作用的C波段相比，L波段具有更深的渗透能力并且可以与茎和枝相互作用，因此使其在多种应用中具有优势。 在GEE中，新算法的实现可能具有挑战性。在过去的几年中，由于深度学习方法与传统的机器学习工具相比具有优越性，因此在遥感领域受到了广泛的关注（Mahdianpari et al.，2018b ; Mohammadimanesh et al.，2019b ; Nogueira et al.， 2017，Rezaee et al.，2018，Sun & Wang，2018，Zhang et al.，2018，Zhu et al.，2017）。特别是深度神经网络已广泛用于图像分类任务，并且在分类精度方面显示出令人鼓舞的结果（Maggiori et al.，2016）。但是，GEE尚不直接支持深度学习算法。在深度学习方面，选择开源框架至关重要。TensorFlow是开源深度学习框架中最受欢迎的框架，例如Caffe，Microsoft CNTK，MXNet，Facebook Torch，Deeplearning4j and Theano（Zhu et al.，2017）。尽管尚不直接支持深度学习分类器，但GEE最近已与TensorFlow链接（自2019年9月起）。尤其是，用户现在可以访问软件包，从而允许他们与TensorFlow保存在Google AI平台上的模型格式进行交互（DeLancey et al.，2020）。GEE API提供了以TFRecord格式导入/导出图像，训练和测试数据集的机会。TFRecord格式可以处理大量数据，它允许用户以批量处理方式运行分类器，而无需存储所有数据。因此，此功能无疑可以应对大数据分析中的挑战。 根据GEE在基于像素的分类中的最佳性能，结果表明大多数研究已使用基于像素的方法完成。然而，这将引起在大面积上寻找高质量参考数据的问题。此外，如果成功实施了复杂的无监督分类算法，则GEE可能更具说服力。例如，目前GEE代码编辑器仅支持K-means，X-means，LVQ和Cobweb。由于遥感图像的固有特性（例如非正态分布数据）和混合像素的存在，实现复杂的算法（例如ISODATA，模糊K均值，概率K均值和基于内核的聚类方法）至关重要。 总体而言，与基于矢量的处理相比，GEE被证明更适合图像分析。此外，由于使用多个CPU进行处理，因此难以完成基于像素的像素空间关系的分析。此外，图像分割和水文建模选项受到限制。因此，近年来建议对基于对象的图像分析，重型矢量运算以及提供高分辨率卫星图像进行改进。"
  },
  {
    "objectID": "Week_6.html#reference",
    "href": "Week_6.html#reference",
    "title": "5  Week_6",
    "section": "5.5 Reference",
    "text": "5.5 Reference\n\n\n\n\nAghamiri, Mahtab, Amineh Ghorbani, Jolien Ubacht, Igor Nikolic, and Paulein Herder. n.d. “Enabling Citizen Participation in Sustainable Collec- Tive Action In Smart Cities: The Case Of Buiksloter- Ham.”\n\n\nArias Cuenca, María. 2023. “Sentinel-1 time series applications over agricultural fields: proposal, evaluation and comparison of different methodologies.” https://doi.org/10.48035/Tesis/2454/45156.\n\n\n“Google Earth Engine and Machine Learning for Earth Monitoring.” n.d. https://pos.sissa.it/429/021.\n\n\nLea, James, Robert Fitt, Stephen Brough, Georgia Carr, Jonathan Dick, Natasha Jones, Eli Saetnan, and Richard Webster. 2023. “Google Earth Engine Climate Tool (GEEClimT): Enabling Rapid, Easy Access to Global Climate Reanalysis Data.” https://doi.org/10.5194/egusphere-egu23-7760.\n\n\nLechner, Michael, Alena Dostálová, Markus Hollaus, Clement Atzberger, and Markus Immitzer. 2022. “Combination of Sentinel-1 and Sentinel-2 Data for Tree Species Classification in a Central European Biosphere Reserve.” Remote Sensing 14 (11): 2687. https://doi.org/10.3390/rs14112687.\n\n\nPham-Duc, Binh, Ho Nguyen, Hien Phan, and Quan Tran-Anh. 2023. “Trends and Applications of Google Earth Engine in Remote Sensing and Earth Science Research: A Bibliometric Analysis Using Scopus Database.” Earth Science Informatics 16 (3): 2355–71. https://doi.org/10.1007/s12145-023-01035-2.\n\n\nRitika, Prasai. n.d. “Earth Engine Application to Retrieve Long-Term Terrestrial and Aquatic Time Series of Satellite Reflectance Data.” International Journal of Multidisciplinary Research and Growth Evaluation.\n\n\nShaveta. 2023. “A Review on Machine Learning.” International Journal of Science and Research Archive 9 (1): 281–85. https://doi.org/10.30574/ijsra.2023.9.1.0410.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and B. Brisco. 2020. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing, May. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nWu, A., and X. Xiong. 2020. “Sensors, Systems, and Next-Generation Satellites XXIV.” In, 11530:267–77. SPIE. https://doi.org/10.1117/12.2573018.\n\n\nXu, Fei, Stien Heremans, and Ben Somers. 2022. “Urban Land Cover Mapping with Sentinel-2: A Spectro-Spatio-Temporal Analysis.” Urban Informatics 1 (1): 8. https://doi.org/10.1007/s44212-022-00008-y."
  },
  {
    "objectID": "Week_7.html#knowledge-gain-from-the-lecture",
    "href": "Week_7.html#knowledge-gain-from-the-lecture",
    "title": "6  Week_7",
    "section": "6.1 Knowledge gain From the Lecture",
    "text": "6.1 Knowledge gain From the Lecture\nClassification and regression trees (CART)\n\nClassification\n\n分类树用于将数据分类到两个或更多的离散类别 回归树处理线性回归不适用的情况 通过将数据分割成小块来改进模型的预测能力 在创建决策树时，最终的叶子节点可能是类别的混合（不纯），并使用基尼不纯度来量化这种不纯度。选择最低不纯度的属性作为树的顶部来开始决策过程。 计算基尼不纯度，并用它来评估在构建决策树时分割数据的质量，其值越小表示数据越纯净。\n\n\n\n\n\nLand Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition, Source: (Phan, Kuch, and Lehnert 2020)\n\n\n\n\n\nRegression trees\n\n回归树预测连续值，例如污染量，而分类树预测离散值，例如土地覆盖类型。 当线性回归不能很好地拟合数据时，建议使用回归树作为替代方案。在回归树中，数据根据阈值或节点划分为多个部分。计算这些部分的残差平方和（SSR），并且具有最低SSR的阈值成为树的起点或根。可以重复该过程以进一步分割数据，并且可以设置最小观察次数以防止过度拟合。\n\n\n\n\n\nTree classification procedure in Google Earth Engine, Source: (Laengner, Siteur, and Wal 2019)\n\n\n\n\nOverfitting\n如果一个叶节点只包含一个人或一个像素值，就可能出现过拟合。最好的模型具有低偏差和低变异性，能够在不同数据集（如训练集和测试集）之间做出一致的预测。为了防止决策树过度生长的方法，其方法包括限制树的生长（例如，一个叶子至少包含20个像素），以及最弱连接剪枝（基于树得分的剪枝）。\n每棵树的叶子数量和调整α值（正则化参数）来减少过拟合。从α=0开始，逐渐增加α值直到剪枝可以降低树得分，然后保存这些α值。树得分是残差平方和（SSR）加上树的惩罚（α乘以叶子数T）。不同的α值会产生不同的子树和树得分。使用不同的α值来训练数据，并在测试数据上计算SSR，以选择得分最小的树。用交叉验证（10次交叉验证）来重复上述过程，从而找到平均而言在测试数据上SSR最低的α值。然后选择这个α值对应的、使用全部数据训练的树。对于分类树，SSR将被不纯度度量（如基尼不纯度）所替代。\nRandom Tress\n随机森林由许多分类决策树组成，通过对数据进行自助采样（bootstrap samples），并从随机选择的变量中构建决策树。在节点上，算法会再次从变量的随机子集中选择。这个过程会不断重复，最终得到多棵树，即一个”森林”。当有新数据通过这些树时，每棵树都会给出一个预测结果，最终选择票数最多的选项作为最终预测。\n随机森林中的”bagging”技术，即通过替换数据进行自助采样。每棵树大约使用70%的训练数据进行训练，剩下30%的数据被称为袋外数据（OOB）。袋外数据被用来测试森林，以评估模型的性能，最后选择得票最多的分类结果。袋外数据分类错误的比例被称为OOB错误。\n随机森林中不进行剪枝，树可以尽可能地生长。袋外错误是通过计算没有使用某些值（例如数据中的行）的所有树的平均预测错误来得出的。验证数据与袋外数据不同，它从未被包含在决策树的构建中。\nHow to apply to the imagery\n图像分类的两种主要方法：监督学习和无监督学习。监督学习通过机器学习模式识别从数据中学习并对新数据打标签，而无监督学习则通过聚类分析未预先定义的数据，然后对这些聚类进行标签。\n监督学习：\n\n监督学习的通用基本上都遵循流程包括：类别定义、预处理、训练、像素分配和准确性评估。\n\n无监督学习:\n\nDBSCAN算法，它通过设定一个半径（Epsilon）和最小点数来形成聚类，并可通过迭代和PCA进行优化。\nISODATA算法，k-means的一个变体，它增加了合并过近的聚类或分割过长的聚类的功能，并根据聚类中的像素数、迭代次数等条件来控制聚类过程.\n“Cluster busting”的方法，它通过掩盖和重新分类那些难以打标签或标签不正确的聚类来提高分类精度.\n\nMaximum likelihood\nMaximum likelihood & Support Vector Machine 最大似然估计（Maximum Likelihood Estimation，MLE）是一种统计方法，用于估计概率模型中的参数。该方法的基本思想是：从所有可能的参数值中，选择最能解释观察到的数据的参数值。例如在遥感中，它使用概率来将图像中的每个像素分配给最可能的土地覆盖类型，并可以设置概率阈值来决定是否进行分类。\n\n\n\n\n\nMaximum likelihood classifier, Source: (Núñez et al. 2019)\n\n\n\n\nSupport Vector Machine\n支持向量机（SVM）是一种监督学习模型，用于分类和回归分析。假设我们有一个训练数据集，其中每个数据点都属于两个类别中的一个。SVM 的目标是找到一个超平面，使得该超平面能够将两类数据点尽可能分开。\n\n\n\n\n\nSVM example of linearly separable data, Source: (Sheykhmousa and Mahdianpari 2020)"
  },
  {
    "objectID": "Week_7.html#practical",
    "href": "Week_7.html#practical",
    "title": "6  Week_7",
    "section": "6.2 Practical",
    "text": "6.2 Practical\n\n6.2.1 监督分类\n选择一个Study Area，在地图上选择training feature collections，在下图的选择了forest, water,developed,herbaceous作为collect feature.使用ee.Classifier.smileCart) 并对其进行训练。但是结果的呈现效果不是很好的，可能是初始的数据集的选择上不是很好。\n\n\n\n\n\nSupervised trained Classification Result\n\n\n\n\n\n\n6.2.2 监督分类\nSame result of Unsupervised trained Classification\n\n\n\n\n\nUnsupervised trained Classification Result"
  },
  {
    "objectID": "Week_7.html#application",
    "href": "Week_7.html#application",
    "title": "6  Week_7",
    "section": "6.3 Application",
    "text": "6.3 Application\n遥感机器学习的根源可以追溯到上世纪90年代。它最初被引入作为一种自动化知识基础建设的远程感知的方法。此后它不断发展并在各个领域找到了应用，包括遥感和地球科学(Challa, Sridhar, and Shyam Mohan 2022)。深度学习等机器学习算法因其能够分析大量数据并实现高精度而在遥感领域广受欢迎(Jeon 2023)。这些算法已用于图像分类、场景理解和材料识别等任务(Rewhel et al. 2023)。具有特定领域属性的数据集的可用性进一步促进了机器学习技术在遥感中的应用。\n机器学习算法有三大类。一是监督机器学习，二是无监督机器学习，三是加强学习。监督和非监督的区别在于使用监督算法,有一个数据集包含的输出列而在使用无监督算法,一个只有一个巨大的数据集,它的职责是集群算法基于关系数据集到各种不同的类之间已经确定不同的记录[Ling (2023)](Raju et al. 2023)。\n由于其分类的准确性，随机森林算法在遥感社区越来越受欢迎。这些是集成分类器，基本上意味着他们利用下面的多个决策树。RF分类器受欢迎的一个主要原因是它们有助于缓解高维问题(Bahrami, Hassani, and Maghsoudi 2018)。它们提供了一个可变的重要性(VI)，可以减少高光谱数据的维数。变量的重要性本质上是衡量一个特定输入的变化对输出的影响[Solorio-Ramírez et al. (2023)](Rina et al. 2023)。\nSVMs是监督学习模型，可用于回归和分类问题。它们主要用于分类问题。他们的工作方式是在一个n维空间(特征)中绘制的点(特征)，然后用一个超平面来划分这些点。从森林分类到多光谱遥感图像分割，在遥感中几乎所有类型的分类问题都使用SVMs(Feizi and Nazemi 2022)。就像其他算法一样，他们的成功取决于问题的性质，一个人必须分别测试每个算法，然后根据每个算法的性能做出决定(Hazra et al. 2021)。\n过度拟合模型通常需要建立一个过于复杂的模型来解释研究数据中的特性和异常值。这意味着,如果你使用相同类型的数据(它的数据类型已经训练)评估模型,你会得到一个非常高的预测、分类精度(Schmidt, n.d.)。然而,如果你只是修改一些输入，(这模型没有见过)，那么，预测、分类精度就会下降。你可以通过使用更大的数据集来修复过度拟合，并适当地分割数据集。此外，减少模型定义的复杂性是有益的，这样就不会对所有极端的边界情况进行分类(Rezaei and Sabokrou, n.d.)。\n加一个"
  },
  {
    "objectID": "Week_7.html#reflection",
    "href": "Week_7.html#reflection",
    "title": "6  Week_7",
    "section": "6.4 Reflection",
    "text": "6.4 Reflection\n这节课主要学习了一些机器学习的技术在遥感中的应用，讲述了使用机器学习来解决什么样的问题。在上面所陈述的方法里面，哪个才是最适用的呢？这个问题的答案取决于一个人想要解决的问题。在某些情况下，当您有多个维度但记录有限时，SVM可能会更好地工作。如果你有很多的记录，但很少的维度(特性),神经网络(NN)可能产生更好的预测/分类精度。人们经常需要在你的数据集上测试多种算法，然后选择最有效的算法。通常，需要为不同的算法调整各种参数(i)。对射频、隐藏层数、神经网络神经元的数量以及对SVMs的”决策函数形状”等进行了研究。很多时候，将多个算法组合在一起可以获得更好的准确性，这就是所谓的合奏。还可以将SVM和神经网络、SVM和RF(可能性无穷)组合起来，以提高预测精度。再次，须测试多个合奏以选择最好的合奏。\n同样重要的是要注意,预测精度可能会改变根据特定功能试图使用分类、预测的目的而改变。例如，Shang和Chisholm(2014)讨论了如何将澳大利亚本土森林物种分类，他们决定使用最先进的遥感算法。在树叶、树冠和社区层面对树木进行分类。他们测试了各种算法(SVM、AdaBoost和Random Forest)，并发现每种算法在不同级别上都优于其他算法。在叶级，随机森林获得了最佳分类精度(94.7%)，支持向量机在冠层(84.5%)和社区水平(75.5%)的表现优于其他算法。\n另一个影响算法选择的因素是数据是否线性可分。例如，线性分类算法期望数据可以被线性空间中的直线分割。假设数据是线性可分的，可能适用于大多数情况，但在某些场景下是正确的,并会降低预测/分类精度。因此，我们需要确保使用的算法能够处理可用的数据。\n不可能只看一种算法，从理论上决定它是否会为你的数据集产生最好的结果，因为很多机器学习算法都是黑盒算法。这意味着很难看出算法是如何达到特定的结果的。因此，首先根据问题的类型来缩小算法选择的范围，然后在数据集的一部分应用缩小算法，看看哪一种性能最好。\n机器学习有着光明的未来，因为越来越多的人正在学习机器学习的基本知识，并将其应用于日常工作和研究中。新的算法每隔一天就会出现，分类的准确率也随之提高。这些问题在遥感(测绘地皮)中似乎很困难，有时甚至是不可能的，但每天都被新出现的算法解决。在不久的将来，世界上大多数的分析工作将由机器学习算法完成。"
  },
  {
    "objectID": "Week_8.html#knowledge-gain-from-the-lecture",
    "href": "Week_8.html#knowledge-gain-from-the-lecture",
    "title": "7  Week_8",
    "section": "7.1 Knowledge gain From the Lecture",
    "text": "7.1 Knowledge gain From the Lecture\nObject based image analysis (OBIA)\n这是一种考虑地面物体如何在栅格单元上表示的分析方法。 Simple Linear Iterative Clustering算法是生成超像素的最常用方法。它将图像分割成具有相似颜色和空间位置的区域，称为超像素。超像素分割可以用于图像降噪、边缘检测、纹理分析等任务。SLIC算法的基本思想是迭代地更新每个像素点的聚类标签。在每个迭代步骤中，算法会计算每个像素点与其相邻像素点的距离，并将其分配给距离最近的聚类中心。\n可能这个概念有些的抽象对于非初学者来说，我把它细致化的解释一下 想象一下，你有一张由许多像素点组成的图像。你想将这些像素点分成若干个组，使得每个组中的像素点具有相似的颜色和空间位置。\nSLIC算法就像是一个将像素点分组的”游戏”。游戏的规则如下：\n首先，你需要在图像中随机选择一些点作为”聚类中心”。 然后，你需要计算每个像素点与所有聚类中心的距离。 每个像素点将被分配给距离它最近的聚类中心。 接下来，你需要更新每个聚类中心的坐标，使其位于该聚类中所有像素点的平均位置。 重复步骤2到4，直到所有像素点都被分配给某个聚类中心。 游戏结束后，你将得到一组具有相似颜色和空间位置的像素点，即超像素。\n\n\n\n\n\nComparison of Simple Linear Iterative Clustering (SLIC) and SLICO superpixel adherence to natural image boundaries derived using initial clustering of 10 × 10 pixels., Source: (Csillik 2017)\n\n\n\n\nSub pixel analysis\n亚像素分析是指在图像的像素之间进行分析的技术。传统图像处理方法只关注每个像素的灰度值，而亚像素分析则可以利用像素之间灰度的细微差别来获取更精确的信息。其应用范围很广，包括：图像增强，边缘检测，纹理分析，目标识别.\n\n\n\n\n\nSuperpixel Generation Algorithm\n\n\n\n\n评估遥感数据分类准确度\n讲述了生产遥感数据后如何进行准确度评估，这是机器学习工作流程的一部分。其中的三个重要指标是：制图者准确率（Producer’s Accuracy）、用户准确率（User’s Accuracy）和总体准确率（Overall Accuracy），以及如何利用混淆矩阵（Confusion Matrix）来计算这些指标。\n模型预测结果正确时： 真阳性（TP）是模型正确预测阳性类别； 真阴性（TN）是模型正确预测阴性类别。 模型预测结果错误时： 假阳性（FP）是模型错误地预测为阳性，但实际为阴性； 假阴性（FN）是模型错误地预测为阴性，但实际为阳性。\n计算上面的指标是如下表\n\n\n\n\n\n\n\n\nAccuracy Metric\nFormula\nShort Definition\n\n\n\n\nProducer’s Accuracy\nTP / (TP + FN)\nCorrect classification proportion compared to ground truth.\n\n\nUser’s Accuracy\nTP / (TP + FP)\nCorrect classification proportion out of all classified.\n\n\nOverall Accuracy\n(TP + TN) / (TP + FP + FN + TN)\nProportion of all correctly classified pixels.\n\n\n\n在此基础上可以使用凯帕系数来进行有效评估分类模型的性能，确保分类结果的可靠性和准确性。凯帕系数的值范围从-1（完全不一致）到1（完全一致）。值为0表示一致性与随机机会相同，而值接近1表示非常高的一致性。其计算方法是（实际一致性 - 随机一致性）/（1 - 随机一致性）。\n\n\n\n\n\nExample of Accuracies and kappa coefficient of land use:land cover (LULC) classifications in the SMA, Source: (Priyankara et al. 2019)\n\n\n\n\nF1 Score\n当你的数据集中的类别是不平衡的，即一个类的样本数量远多于另一个类，卡帕系数将不使用，但是F1 Score特别有用。在这种情况下，单纯使用准确率可能不足以反映模型的性能，因为模型可能只是在预测主导类别方面表现良好，而忽视了少数类。F1 Score通过平衡精确率（预测为正类别中实际为正类别的比例）和召回率（实际为正类别中预测为正类别的比例），提供了一个更全面的性能度量。如果你的任务中同样重视精确率和召回率，即你希望减少假阳性和假阴性的数量，那么F1 Score是一个合适的选择。它确保了你不会因为提高另一个而牺牲了其中一个指标。尽管F1 Score可以扩展到多类分类问题，但它主要适用于二分类问题，尤其是当正负样本的重要性基本相等时。在研究二分类问题时候可以引用ROC曲线，其提供了一种在不同类别分布或不同的代价/权重条件下比较多个分类器的方法。即使在数据集随时间变化或在不同数据集上，ROC曲线和AUC值也能为模型的比较提供一致的评估标准。\nSpatial cross validation\n在传统的machine Learning交叉验证方法中，数据集被随机分成训练集和测试集。模型在训练集上进行训练，并在测试集上进行评估。然而，这种随机划分的方法忽略了遥感数据中一个关键特性——空间自相关，即相邻区域之间往往具有相似的属性。\n举一个例子现在有一张包含多种地形的大型遥感图像，比如森林、湖泊和城市区域。任务目标是创建一个计算机模型，这个模型可以查看这张图像的任何部分，并准确地告诉你那里是森林、湖泊还是城市。为了训练这个模型，你需要从图像中选取一些样本（即图像的一小部分），告诉模型这些样本分别属于哪种地形。然后，模型会学习这些样本，尝试理解不同地形的外观。\n但这里有个问题：如果你随机选择样本，那么靠得很近的样本可能会同时出现在训练数据（模型用来学习的数据）和测试数据（用来检验模型准确性的数据）中。这就像是在考试前就已经知道了部分考题，这可能会让模型看起来表现得很好，但实际上它可能并没有真正学到如何区分不同的地形，而只是记住了那些特定的样本。\n空间交叉验证就是为了解决这个问题。我们不是随机选择样本，而是将整个图像分成几个大块区域。我们可以确保某些区域仅用于训练模型，而其他区域则用于测试模型。这样，我们就可以确信，模型在评估时遇到的数据是它之前从未见过的，这有助于我们更准确地判断模型的实际性能。\n举个例子，假设你有一张包含城市、森林和湖泊的大地图。你将地图分成了东、西两部分。你用东半部分的数据训练你的模型，这意味着模型将看到并学习这一区域的城市、森林和湖泊是什么样的。然后，你用西半部分的数据测试模型，看看它是否能准确识别出它从未”见过”的地区的不同地形。通过这种方式，你可以更好地评估模型在处理新、未知区域时的实际表现能力。\n\n\n\n\n\nImportance of spatial predictor variable selection in machine learning applications – Moving from data reproduction to spatial prediction, Source: (Meyer et al. 2019)"
  },
  {
    "objectID": "Week_7.html#reference",
    "href": "Week_7.html#reference",
    "title": "6  Week_7",
    "section": "6.5 Reference",
    "text": "6.5 Reference\n\n\n\n\nBahrami, Yousef, Hossein Hassani, and Abbas Maghsoudi. 2018. “Investigating the Capabilities of Multispectral Remote Sensors Data to Map Alteration Zones in the Abhar Area, NW Iran.” Geosystem Engineering 24 (December): 1–13. https://doi.org/10.1080/12269328.2018.1557083.\n\n\nChalla, Nagendra Panini, Parupally Sridhar, and J. S. Shyam Mohan. 2022. “A Machine Learning Perspective for Remote Sensing.” In, edited by Pala Gireesh Kumar, Kolluru V. L. Subramaniam, S. Moses Santhakumar, and Neelima Satyam D., 553–59. Lecture Notes in Civil Engineering. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-0189-8_45.\n\n\nFeizi, Amir, and Alireza Nazemi. 2022. “Classifying Random Variables Based on Support Vector Machine and a Neural Network Scheme.” Journal of Experimental & Theoretical Artificial Intelligence 0 (0): 1–24. https://doi.org/10.1080/0952813X.2022.2104385.\n\n\nHazra, Simanta, Shreyasee Ghosh, Shibsankar Bala, and Debasis Chakraborty. 2021. “2021 2nd International Conference for Emerging Technology (INCET).” In, 1–6. https://doi.org/10.1109/INCET51464.2021.9456237.\n\n\nJeon, Gwanggil. 2023. “Advanced Machine Learning and Deep Learning Approaches for Remote Sensing.” Remote Sensing 15 (11): 2876. https://doi.org/10.3390/rs15112876.\n\n\nLaengner, Marieke, Koen Siteur, and Daphne Wal. 2019. “Trends in the Seaward Extent of Saltmarshes Across Europe from Long-Term Satellite Data.” Remote Sensing 11 (July): 1653. https://doi.org/10.3390/rs11141653.\n\n\nLing, Qingyang. 2023. “Machine Learning Algorithms Review.” Applied and Computational Engineering 4 (May): 91–98. https://doi.org/10.54254/2755-2721/4/20230355.\n\n\nNúñez, Juan Manuel, Sandra Medina-Fernández, F. Gerardo Ávila, and Jorge Montejano. 2019. “High-Resolution Satellite Imagery Classification for Urban Form Detection.” In, 1–9. https://doi.org/10.5772/intechopen.82729.\n\n\nPhan, Thanh Noi, Verena Kuch, and Lukas W. Lehnert. 2020. “Land Cover Classification Using Google Earth Engine and Random Forest ClassifierThe Role of Image Composition.” Remote Sensing 12 (15): 2411. https://doi.org/10.3390/rs12152411.\n\n\nRaju, G. S Bapi, Chintala Manasa, Nandikatti Durga Bhavani, Jadi Amulya, and Dangatla Shirisha. 2023. “2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS).” In, 104–9. https://doi.org/10.1109/ICICCS56967.2023.10142906.\n\n\nRewhel, Ekram M., Jianqiang Li, Amal A. Hamed, Hatem M. Keshk, Amira S. Mahmoud, Sayed A. Sayed, Ehab Samir, et al. 2023. “Deep Learning Methods Used in Remote Sensing Images: A Review.” Journal of Environmental & Earth Sciences 5 (1): 33–64. https://doi.org/10.30564/jees.v5i1.5232.\n\n\nRezaei, Hossein, and Mohammad Sabokrou. n.d. “Quantifying Overfitting: Evaluating Neural Network Performance Through Analysis of Null Space.” https://doi.org/10.48550/arXiv.2305.19424.\n\n\nRina, Su, Hong Ying, Yu Shan, Wala Du, Yang Liu, Rong Li, and Dingzhu Deng. 2023. “Application of Machine Learning to Tree Species Classification Using Active and Passive Remote Sensing: A Case Study of the Duraer Forestry Zone.” Remote Sensing 15 (10): 2596. https://doi.org/10.3390/rs15102596.\n\n\nSchmidt, James. n.d. “Testing for Overfitting.” https://doi.org/10.48550/arXiv.2305.05792.\n\n\nSheykhmousa, Reza M, and Masoud Mahdianpari. 2020. “Support Vector Machine Vs. Random Forest for Remote Sensing Image Classification: A Meta-Analysis and Systematic Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, October. https://doi.org/10.1109/JSTARS.2020.3026724.\n\n\nSolorio-Ramírez, José-Luis, Raúl Jiménez-Cruz, Yenny Villuendas-Rey, and Cornelio Yáñez-Márquez. 2023. “Random Forest Algorithm for the Classification of Spectral Data of Astronomical Objects.” Algorithms 16 (6): 293. https://doi.org/10.3390/a16060293."
  },
  {
    "objectID": "Week_8.html#practical",
    "href": "Week_8.html#practical",
    "title": "7  Week_8",
    "section": "7.2 Practical",
    "text": "7.2 Practical\n\n7.2.0.1 Accuracy Assessment Result & Hyperparameter Tuning\n引入一个米兰的参考数据集，定义了一系列预测波段，将数据集分为训练集和测试集，80%用于训练，20%用于测试。训练随机森林分类器，用于根据输入的波段数据预测目标类别。使用测试集评估了模型的准确性，并生成了一个混淆矩阵来详细了解模型的性能(以下是结果)。\n\n\n\n\n\nAccuracy Assessment Result\n\n\n\n\n整体精度为83.33%，表示模型正确分类的样本比例。模型对每个预测类别的可信度较高，Kappa值为0.773意味着有较好的一致性。"
  },
  {
    "objectID": "Week_8.html#application",
    "href": "Week_8.html#application",
    "title": "7  Week_8",
    "section": "7.3 Application",
    "text": "7.3 Application\n基于对象的图像分析（OBIA）已广泛应用于遥感应用。OBIA 方法通过考虑分割对象之间的空间关系并结合先验知识，已应用于提高高分辨率（HR）遥感图像的分类精度。例如，一项研究提出了一种新颖的HR遥感图像分类方案，该方案利用知识图（KG）来保留空间关系并提高分类精度(Gun and Chen 2023)。另一项研究评估了用于山体滑坡检测的基于规则的 OBIA 方法，该方法将深度学习模型的概率与图像分割和基于规则的分类相结合，以提高准确性(Ghorbanzadeh, Gholamnia, and Ghamisi 2023)。OBIA 还被用于定量遥感，例如用于纳米卫星的微型多光谱地球观测成像仪的设计和分析(Kivastik et al. 2022)。此外，OBIA 已与分类器集成策略相集成，以使用超高分辨率 (VHR) 卫星数据改进复杂城市地区的土地覆盖分类(Han et al. 2020)。\nF1 分数用于遥感的各种应用。在面向对象的遥感图像分类实验中，F1分数用于评估不同特征选择方法的性能。Fisher Score-mRMR（Fm）方法结合了Fisher Score和最小冗余最大相关性（mRMR）特征选择方法来提高遥感图像分类的效率和准确性(Lv et al. 2022)。在穿墙雷达成像（TWRI）中，F1分数用于评估压缩感知（CS）算法的性能。它用于评估算法在考虑不同水平的信噪比 (SNR) 和压缩率的情况下重建具有正确检测到的目标的图像的能力(John and Brad 2018)。在城市数据分类的背景下，F1分数用于评估特征缩减技术在提高城市结构分类精度方面的有效性(Zemmoudj, Kemmouche, and Chibani 2014)。\n空间交叉验证是遥感分类中的一项重要技术。它有助于解释遥感数据中存在的空间自相关性，并确保预测误差的无偏估计(Xudong et al. 2022)。几项研究强调了空间交叉验证在准确评估分类性能方面的重要性。例如，卡拉西亚克等人。证明空间留一交叉验证提供了预测误差的无偏估计，并且与结果地图的真实质量一致(Karasiak et al. 2022)。类似地，Stock 和 Subramaniam 提出了一种称为 iSLOOCV 的方法，该方法迭代并集成一系列间隔距离上的误差估计，以解释海洋遥感数据中的空间自相关性(Andy and Ajit 2022)。研究发现，考虑空间依赖性的基于分层统计的抽样方法与其他样本选择方法相比，可以产生更高的分类精度(Routh et al. 2018)。这些研究强调了空间交叉验证在准确评估分类性能和提高遥感分类结果可靠性方面的重要性。"
  },
  {
    "objectID": "Week_8.html#reflection",
    "href": "Week_8.html#reflection",
    "title": "7  Week_8",
    "section": "7.4 Reflection",
    "text": "7.4 Reflection"
  },
  {
    "objectID": "Week_8.html#reference",
    "href": "Week_8.html#reference",
    "title": "7  Week_8",
    "section": "7.5 Reference",
    "text": "7.5 Reference\n\n\n\n\nAndy, Stock, and Subramaniam Ajit. 2022. “Iterative Spatial Leave-One-Out Cross-Validation and Gap-Filling Based Data Augmentation for Supervised Learning Applications in Marine Remote Sensing.” https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2107113.\n\n\nCsillik, Ovidiu. 2017. “Fast Segmentation and Classification of Very High Resolution Remote Sensing Data Using SLIC Superpixels.” Remote Sensing 9 (March): 243. https://doi.org/10.3390/rs9030243.\n\n\nGhorbanzadeh, Omid, Khalil Gholamnia, and Pedram Ghamisi. 2023. “The Application of ResU-Net and OBIA for Landslide Detection from Multi-Temporal Sentinel-2 Images.” Big Earth Data 7 (4): 961–85. https://doi.org/10.1080/20964471.2022.2031544.\n\n\nGun, Zhao, and Jianyu Chen. 2023. “Novel Knowledge Graph- and Knowledge Reasoning-Based Classification Prototype for OBIA Using High Resolution Remote Sensing Imagery.” Remote Sensing 15 (2): 321. https://doi.org/10.3390/rs15020321.\n\n\nHan, Ruimei, Pei Liu, Guangyan Wang, Hanwei Zhang, and Xilong Wu. 2020. “Advantage of Combining OBIA and Classifier Ensemble Method for Very High-Resolution Satellite Imagery Classification.” Journal of Sensors 2020 (November): e8855509. https://doi.org/10.1155/2020/8855509.\n\n\nJohn, F. Silny, and A. Flanders Brad. 2018. “Imaging Spectrometer f-Number Optimization for Remote Sensing of Gases.” https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10768/2323616/Imaging-spectrometer-F-number-optimization-for-remote-sensing-of-gases/10.1117/12.2323616.full#_=_.\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning 111 (7): 2715–40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nKivastik, Joosep, Hans Hubert Sams, Silvar Muru, Hendrik Ehrpais, Tõnis Eenmäe, Joel Kuusk, Andris Slavinskis, and Mihkel Pajusalu. 2022. “Optical Design and Analysis of Theia: A Scientific-Grade Multispectral Imager for Nanosatellites.” IEEE Journal on Miniaturization for Air and Space Systems 3 (4): 242–48. https://doi.org/10.1109/JMASS.2022.3210661.\n\n\nLv, Chengzhe, Yuefeng Lu, Miao Lu, Xinyi Feng, Huadan Fan, Changqing Xu, and Lei Xu. 2022. “A Classification Feature Optimization Method for Remote Sensing Imagery Based on Fisher Score and mRMR.” Applied Sciences 12 (September): 8845. https://doi.org/10.3390/app12178845.\n\n\nMeyer, Hanna, Christoph Reudenbach, Stephan Wöllauer, and Thomas Nauss. 2019. Importance of Spatial Predictor Variable Selection in Machine Learning Applications – Moving from Data Reproduction to Spatial Prediction.\n\n\nPriyankara, Prabath, Manjula Ranagalage, Dr Dissanayake, Takehiro Morimoto, and Yuji Murayama. 2019. “Spatial Process of Surface Urban Heat Island in Rapidly Growing Seoul Metropolitan Area for Sustainable Urban Planning Using Landsat Data.” Journal of Climate 7 (September): 110. https://doi.org/10.3390/cli7090110.\n\n\nRouth, Devin, Lindsi Seegmiller, Charlie Bettigole, Catherine Kuhn, Chadwick Oliver, and Henry Glick. 2018. “Improving the Reliability of Mixture Tuned Matched Filtering Remote Sensing Classification Results Using Supervised Learning Algorithms and Cross-Validation.” Remote Sensing 10 (October): 1675. https://doi.org/10.3390/rs10111675.\n\n\nXudong, Zhao, Zhang Mengmeng, Ran Tao Ran, Li Wei, and Philips Wilfried. 2022. “Cross-Domain Classification of Multisource Remote Sensing Data Using Fractional Fusion and Spatial-Spectral Domain Adaptation.” https://ieeexplore.ieee.org/document/9829269.\n\n\nZemmoudj, Salah, Akila Kemmouche, and Youeef Chibani. 2014. “2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR).” In, 371–75. https://doi.org/10.1109/SOCPAR.2014.7008035."
  },
  {
    "objectID": "Week_6.html#reflection-未完成",
    "href": "Week_6.html#reflection-未完成",
    "title": "5  Week_6",
    "section": "5.4 Reflection 未完成",
    "text": "5.4 Reflection 未完成\nGEE已经成为最受欢迎的地理空间和大数据分析平台之一。尽管如此，仍然有扩展的空间。特别是，GEE为地理空间处理提供了一个易于使用且免费的平台，但是用户无法控制可能导致某些计算问题的并行处理环境的细节。这意味着GEE管理着计算的各个方面，例如源分配，并行性，数据分发和重试，而用户无法影响自己动手（DIY）并行化（Gorelick et al.，2017）。通常，GEE限制可分为三大类：计算，数据集和算法。 值得注意的是，GEE具有一些计算限制，包括时间，内存和存储。关于时限问题，GEE中有两种计算模式：按需和批处理。前者处理的运行次数有限，而后者可以在代码运行时运行。因此，将批处理用于大量计算是合理的，因为任务以按需模式运行。此外，在某些情况下，对大量数据集执行处理时，GEE可能会遇到内存问题。尽管脚本可能是没有逻辑错误的有效JavaScript，但是有时用户在并行化和执行计算时会遇到内部错误，例如内部服务错误，计算超时，超出用户内存限制以及过多的并发聚合。这些错误称为缩放错误，当输出太大，数量太多或计算时间很长时，可能会发生。关于存储，用户可以将结果保存在Google云端硬盘，Google云和GEE资产中。但是，应考虑将有限的250 GB容量用于在GEE资产中保存数据。GEE表资产的大小和形状也有一些限制。 尽管GEE包含大量的图像档案，但是对于许多研究而言，历史和高分辨率数据的价值有限。具体而言，在GEE中有13％的研究专注于灾难测绘，尤其是干旱监测。GEE还可以提供可靠的信息来监视其他灾难，例如地震和洪水图。此外，GEE当前提供高分辨率图像，包括RGB和多光谱集合中的国家农业图像计划（NAIP）和Planet Skysat。美国NAIP提供1 m分辨率的航拍图像数据。自2003-2018年以来，这些图像在GEE中可用，周期为3年和5年。从2014年到2016年，GEE还提供RGB和多光谱/平移集合的Planet Skysat影像。RGB影像以0.8 m分辨率（离地面最低图像1 m）提供，而R，G，B，近红外波段具有约2 m的分辨率，泛波段具有0.8分辨率（离最低点为1 m）。因此，需要高空间和时间分辨率的图像。 到目前为止，Sentinel-1图像是GEE中唯一可用的SAR数据；然而，通过增加从ALOS PALSAR收集的L波段数据来满足多种应用的需求，需要更长的波长，例如作物制图，开辟了新的途径。与具有中等渗透能力并主要与树冠上部相互作用的C波段相比，L波段具有更深的渗透能力并且可以与茎和枝相互作用，因此使其在多种应用中具有优势。 在GEE中，新算法的实现可能具有挑战性。在过去的几年中，由于深度学习方法与传统的机器学习工具相比具有优越性，因此在遥感领域受到了广泛的关注（Mahdianpari et al.，2018b ; Mohammadimanesh et al.，2019b ; Nogueira et al.， 2017，Rezaee et al.，2018，Sun & Wang，2018，Zhang et al.，2018，Zhu et al.，2017）。特别是深度神经网络已广泛用于图像分类任务，并且在分类精度方面显示出令人鼓舞的结果（Maggiori et al.，2016）。但是，GEE尚不直接支持深度学习算法。在深度学习方面，选择开源框架至关重要。TensorFlow是开源深度学习框架中最受欢迎的框架，例如Caffe，Microsoft CNTK，MXNet，Facebook Torch，Deeplearning4j and Theano（Zhu et al.，2017）。尽管尚不直接支持深度学习分类器，但GEE最近已与TensorFlow链接（自2019年9月起）。尤其是，用户现在可以访问软件包，从而允许他们与TensorFlow保存在Google AI平台上的模型格式进行交互（DeLancey et al.，2020）。GEE API提供了以TFRecord格式导入/导出图像，训练和测试数据集的机会。TFRecord格式可以处理大量数据，它允许用户以批量处理方式运行分类器，而无需存储所有数据。因此，此功能无疑可以应对大数据分析中的挑战。 根据GEE在基于像素的分类中的最佳性能，结果表明大多数研究已使用基于像素的方法完成。然而，这将引起在大面积上寻找高质量参考数据的问题。此外，如果成功实施了复杂的无监督分类算法，则GEE可能更具说服力。例如，目前GEE代码编辑器仅支持K-means，X-means，LVQ和Cobweb。由于遥感图像的固有特性（例如非正态分布数据）和混合像素的存在，实现复杂的算法（例如ISODATA，模糊K均值，概率K均值和基于内核的聚类方法）至关重要。 总体而言，与基于矢量的处理相比，GEE被证明更适合图像分析。此外，由于使用多个CPU进行处理，因此难以完成基于像素的像素空间关系的分析。此外，图像分割和水文建模选项受到限制。因此，近年来建议对基于对象的图像分析，重型矢量运算以及提供高分辨率卫星图像进行改进。"
  },
  {
    "objectID": "Week_1.html#knowledge-from-the-lecture",
    "href": "Week_1.html#knowledge-from-the-lecture",
    "title": "1  Week_1",
    "section": "1.1 Knowledge From the Lecture",
    "text": "1.1 Knowledge From the Lecture\n\nThis week’s learning journey into the realm of remote sensing, unveiling the intricate world of electromagnetic waves and their interactions with Earth’s surface. Remote sensing, as I’ve learned, involves acquiring information about objects or areas from a distance, typically from aircraft or satellites, and is a vital tool in understanding our planet.\n\n\n1.1.1 Foundational Concepts of Remote Sensing\n\nOne of the foundational concepts we explored was the difference between passive and active remote sensing. Passive remote sensing relies on natural energy, usually from the sun, whereas active remote sensing systems emit their own energy to illuminate objects. This distinction is crucial for understanding the varied applications of remote sensing technologies like LiDAR, radar, and satellite imagery in observing earth’s landscapes, urban areas, and atmospheric conditions.\n\n\n\n\n\nPassive & Active Remote Sensing, Source: Abeer Nazar Abdul-Hameed\n\n\n\n\n\n\n\n1.1.2 Electromagnetic Waves: Core of Remote Sensing\n\nMuch of our learning knowledge focused on electromagnetic waves, the heart of remote sensing. These waves, a form of energy that propagates through electric and magnetic fields, are the backbone of how remote sensors collect data. Remote sensing is based on this principle to detect the reflection of electromagnetic waves by surface objects and their emission of electromagnetic waves, so as to extract information about these objects and complete the identification of objects at a distance.\n\n\n\n\n\n\nThe Electromagnetic Spectrum, Source: Cssonawala\n\n\n\n\n\n\n1.1.3 Interactions with Earth’s Surface\n\nWe have looked at the complexities of how electromagnetic radiation (EMR) interacts with the Earth’s surface. EMR can be absorbed, transmitted or scattered by the surface and atmosphere. Scattering, in particular, explains phenomena such as the blue colour of the sky or the blackness of the lunar sky due to the absence of an atmosphere.\n\n\n\n\n\n\nInteraction of EMR with Earth’s Surface, Source: Geographicbook\n\n\n\n\n\n\n1.1.4 Synthetic Aperture Radar (SAR) and its Applications\n\nThe Synthetic Aperture Radar (SAR) was another fascinating topic. SAR’s ability to ‘see through clouds’ using longer wavelengths is revolutionary, offering a consistent observation capability irrespective of weather conditions. This technology’s potential in areas like topography, vegetation analysis, and urban planning is immense, showcasing how advanced remote sensing techniques can overcome environmental challenges\nThe study of SAR data also introduced us to the concept of polarization, a property of electromagnetic waves that describes their oscillation direction. This property is crucial for understanding how radar signals interact with different surface properties and is instrumental in enhancing the efficiency and bandwidth of communications.\n\n\n\n1.1.5 Technical Insights and Data Formats in Remote Sensing\n\nOn the technical side, we learned about the different data formats used in remote sensing, such as GeoTIFF, and the importance of resolutions - spatial, spectral, temporal and radiometric. These resolutions define the quality and type of data acquired, and influence how effectively we can interpret and use the data for various applications such as land cover mapping and environmental monitoring.\nIn the literature, these concepts are used to analyse environmental change, urban development and geological features. Understanding remote sensing data and their interpretation is essential for researchers and policy makers to make informed decisions."
  },
  {
    "objectID": "Week_3.html#knowledge-from-the-lecture",
    "href": "Week_3.html#knowledge-from-the-lecture",
    "title": "3  Week_3",
    "section": "3.1 Knowledge From the Lecture",
    "text": "3.1 Knowledge From the Lecture\n\nThis week’s study focuses on remote sensing image processing, with the main areas of interest being geometric corrections, atmospheric corrections, orthometric corrections, radiometric corrections and various image enhancement techniques.\n\n\n3.1.1 Correction\n\n3.1.1.1 Geometric Correction\n\nGeometric correction is the basis of image correction and addresses image distortion due to sensor and other factors. The goal of this correction is to make the image conform to the selected map projection system, adjusting the geometry of the entire image by modelling the relationship between control points (points with known geographic coordinates) on the image and the image coordinates.\n\n\n\n\n\n\nHow Geometric Correction Work, Source: Xiaopeng\n\n\n\n\n\n\n3.1.1.2 Atmospheric Correction\n\nAtmospheric corrections are essential to address distortions and inaccuracies in remotely sensed images caused by variations in the Earth’s atmosphere, sensor angles, and terrain. Several different correction methods were learned in class: Relative Atmospheric Correction, Pseudo-Invariant Correction, Absolute Atmospheric Correction, and Empirical Line Correction.\n\nThe different methods and characteristics of atmospheric correction have been summarised in the table below:\n\n\n\n\n\n\n\n\nMethod\nKey Steps\nFeature\n\n\n\n\nRelative\nSpectrally stable landmarks, linear relations, band operation\nConsistency between images\n\n\nAbsolute\nComplex models for atmospheric effects, surface reflectance\nPrecise, accurate surface information\n\n\nPseudo-Invariant\nHigh-quality reference, PIF, linear regression\nStable reference points, reduce atmospheric effects\n\n\nEmpirical Line\nGround reflectance, average DN values, linear regression\nUtilizes ground data for satellite correction\n\n\n\n\n\n3.1.1.3 Radiometric Correction\n\nThe role of radiometric correction in adjusting the pixel values of satellite imagery to accurately reflect the radiation at the Earth’s surface has been investigated. The main objective of radiometric correction is to convert the raw digital numbers (DN) acquired into physically meaningful units such as radiance or reflectance. This conversion is critical because DN values are arbitrary and can vary between sensors, acquisitions and platforms, making it difficult to consistently compare and analyse data. By converting DN values to radiance or reflectance, radiometric correction enables quantitative measurements and meaningful comparisons between different images and sensors.\n\n\n\n\n\n\nProcess of Radiometric Calibration\n\n\n\n\n\n\n3.1.1.4 Reflection of Collerallation\n\nIn the course of study, certain questions arise as to when atmospheric corrections are needed and whether or not the images we buy or otherwise acquire have been atmospherically corrected. In layman’s terms, if we need to use an image that truly reflects the Sun’s radiation for quantitative inversion or to obtain information about the Earth, accurately identify features, etc., then we need to make an atmospheric correction. When we buy an image, the description document says that it is radiometrically corrected. In fact, this radiometric correction refers to the coarse radiometric correction, which is just a systematic atmospheric correction, which has the same meaning as the systematic geometric correction.\nAt the moment there are many models and methods on the market, since there are how many methods, then there is the problem of method selection. Here is a summary for reference:\n\nif it is a fine quantitative study, then choose the atmospheric correction method based on the radiative transfer model.\nif you are doing dynamic monitoring, then you can choose relative atmospheric correction or simpler methods.\nif the parameters are missing, there is no choice but to choose the simpler method.\n\n\n\n\n\n3.1.2 Data Join Sets/Enhancement\n\n3.1.2.1 Data Join Sets\n\nAn area may need more than one satellite image to be spliced, using mosaic in the R package for the two datasets to be spliced. When selecting images, try to select two images with similar time and date, due to the different date of the image, the image display is different, the reason may be (cloud cover, sunshine), need to use the image increase technique to operate.\n\n\n\n\n3.1.3 Enhancement\n\n3.1.3.1 Ratio\n\nThe ratio is the difference between two spectral bands with a specific spectral response, using CampTown’s data for NDVI (The Normalised Difference Vegetation Index) The Normalised Difference Vegetation Index is based on the fact that healthy and green vegetation reflects more in the near infrared but absorbs in the red wavelengths. Therefore, the red wavelength band is used for the operation in the formula below.\n\\[\nNDVI = \\frac{NIR - Red}{NIR + Red}\n\\]\nThe following figure shows the image after manipulation for NDVI (a. After NDVI Formula, b. Extraction only if NDVI is equal to or greater than 0.2)\n\n\n\n\n\n\nProcess of Radiometric Calibration\n\n\n\n\nThis case above can be applied to other index calculations such as NDWI (Normalised Difference Water Index) and NDDI (Normalised Difference Drought Index). These are calculated using the reflectance of different objects in different light waves.\n\n\n3.1.3.2 Texture\n\nThe extraction method of texture features is relatively simple, it is to use an active window to slide continuously on the image, calculate the variance, mean, maximum, minimum and the difference between the two and the information entropy in the window, etc., respectively, to form the corresponding texture image, when the spectral characteristics of the target are relatively close to each other, the texture features can play a positive role in distinguishing the target. When the spectral characteristics of the target are close, the texture features can play a positive role in distinguishing the target. After selecting the appropriate dynamic range of the data and extracting the texture features, the texture features of the image can be highlighted, which is conducive to the extraction of constructive information. Below is an example of a texture treatment for the Cape Town area.\n\n\n\n\n\n\nAfter of Texture Process"
  },
  {
    "objectID": "Week_6.html#knowledge-from-the-lecture",
    "href": "Week_6.html#knowledge-from-the-lecture",
    "title": "5  Week_6",
    "section": "5.1 Knowledge From the Lecture",
    "text": "5.1 Knowledge From the Lecture\nGoogle Earth Engine是Google提供的对大量全球尺度地球科学资料（尤其是卫星数据）进行在线可视化计算和分析处理的云平台。它的特点是允许大规模的地理空间分析，运行速度很快，有在客户端运行的代码，并且将数据储存在的服务器上.\nGEE 中的栅格数据和矢量数据:\n\n栅格数据称为”Image”，具有波段（bands）。\n矢量数据称为”Feature”，具有几何形状和属性（dictionary of properties）。\n\nGEE 中的图像缩放:\n\n指图像的分辨率，即每个像素代表的实际地面距离。\nGEE 会根据分析需求自动选择合适的缩放级别。\n\nGEE中的投影:\nGEE 支持多种投影，包括 Mercator 投影、Albers 投影、等距圆柱投影等。用户可以选择合适的投影进行分析。\n如何使用GEE\n\n\n\n\n\nHow to use GEE, Source: Google Earth Engine\n\n\n\n\nGEE中可以进行的操作：\n\n几何操作：例如空间操作，连接（Joins），区域统计（比如邻域的平均温度），图像或特定值的筛选。\n机器学习，包括监督学习和非监督学习，使用TensorFlow进行深度学习，探索变量之间的关系。\n应用/输出：在线图表，可扩展的使用GEE数据的地理空间应用\n\nGEE中的Reduce the Image :\nReducing the image by region 和 reducing the image by neighbor 都是用于对图像进行区域化或邻域化操作的函数。它们的主要区别在于：\n\nReducing the image by region 是根据指定的区域对图像进行操作。每个区域可以是任意形状，可以重叠。该函数会对每个区域内的所有像素进行指定的计算，并返回一个包含区域统计结果的新图像。\nReducing the image by neighbor 是根据指定的邻域对图像进行操作。每个像素的邻域是指其周围一定范围内的像素。该函数会对每个像素及其邻域内的所有像素进行指定的计算，并返回一个包含像素新值的图像。\n\nGEE中的Linear Regression & Join (暂时写不出来)"
  },
  {
    "objectID": "Week_7.html#knowledge-from-the-lecture",
    "href": "Week_7.html#knowledge-from-the-lecture",
    "title": "6  Week_7",
    "section": "6.1 Knowledge From the Lecture",
    "text": "6.1 Knowledge From the Lecture\nClassification and regression trees (CART)\n\nClassification\n\n分类树用于将数据分类到两个或更多的离散类别 回归树处理线性回归不适用的情况 通过将数据分割成小块来改进模型的预测能力 在创建决策树时，最终的叶子节点可能是类别的混合（不纯），并使用基尼不纯度来量化这种不纯度。选择最低不纯度的属性作为树的顶部来开始决策过程。 计算基尼不纯度，并用它来评估在构建决策树时分割数据的质量，其值越小表示数据越纯净。\n\n\n\n\n\nLand Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition, Source: (Phan, Kuch, and Lehnert 2020)\n\n\n\n\n\nRegression trees\n\n回归树预测连续值，例如污染量，而分类树预测离散值，例如土地覆盖类型。 当线性回归不能很好地拟合数据时，建议使用回归树作为替代方案。在回归树中，数据根据阈值或节点划分为多个部分。计算这些部分的残差平方和（SSR），并且具有最低SSR的阈值成为树的起点或根。可以重复该过程以进一步分割数据，并且可以设置最小观察次数以防止过度拟合。\n\n\n\n\n\nTree classification procedure in Google Earth Engine, Source: (Laengner, Siteur, and Wal 2019)\n\n\n\n\nOverfitting\n如果一个叶节点只包含一个人或一个像素值，就可能出现过拟合。最好的模型具有低偏差和低变异性，能够在不同数据集（如训练集和测试集）之间做出一致的预测。为了防止决策树过度生长的方法，其方法包括限制树的生长（例如，一个叶子至少包含20个像素），以及最弱连接剪枝（基于树得分的剪枝）。\n每棵树的叶子数量和调整α值（正则化参数）来减少过拟合。从α=0开始，逐渐增加α值直到剪枝可以降低树得分，然后保存这些α值。树得分是残差平方和（SSR）加上树的惩罚（α乘以叶子数T）。不同的α值会产生不同的子树和树得分。使用不同的α值来训练数据，并在测试数据上计算SSR，以选择得分最小的树。用交叉验证（10次交叉验证）来重复上述过程，从而找到平均而言在测试数据上SSR最低的α值。然后选择这个α值对应的、使用全部数据训练的树。对于分类树，SSR将被不纯度度量（如基尼不纯度）所替代。\nRandom Tress\n随机森林由许多分类决策树组成，通过对数据进行自助采样（bootstrap samples），并从随机选择的变量中构建决策树。在节点上，算法会再次从变量的随机子集中选择。这个过程会不断重复，最终得到多棵树，即一个”森林”。当有新数据通过这些树时，每棵树都会给出一个预测结果，最终选择票数最多的选项作为最终预测。\n随机森林中的”bagging”技术，即通过替换数据进行自助采样。每棵树大约使用70%的训练数据进行训练，剩下30%的数据被称为袋外数据（OOB）。袋外数据被用来测试森林，以评估模型的性能，最后选择得票最多的分类结果。袋外数据分类错误的比例被称为OOB错误。\n随机森林中不进行剪枝，树可以尽可能地生长。袋外错误是通过计算没有使用某些值（例如数据中的行）的所有树的平均预测错误来得出的。验证数据与袋外数据不同，它从未被包含在决策树的构建中。\nHow to apply to the imagery\n图像分类的两种主要方法：监督学习和无监督学习。监督学习通过机器学习模式识别从数据中学习并对新数据打标签，而无监督学习则通过聚类分析未预先定义的数据，然后对这些聚类进行标签。\n监督学习：\n\n监督学习的通用基本上都遵循流程包括：类别定义、预处理、训练、像素分配和准确性评估。\n\n无监督学习:\n\nDBSCAN算法，它通过设定一个半径（Epsilon）和最小点数来形成聚类，并可通过迭代和PCA进行优化。\nISODATA算法，k-means的一个变体，它增加了合并过近的聚类或分割过长的聚类的功能，并根据聚类中的像素数、迭代次数等条件来控制聚类过程.\n“Cluster busting”的方法，它通过掩盖和重新分类那些难以打标签或标签不正确的聚类来提高分类精度.\n\nMaximum likelihood\nMaximum likelihood & Support Vector Machine 最大似然估计（Maximum Likelihood Estimation，MLE）是一种统计方法，用于估计概率模型中的参数。该方法的基本思想是：从所有可能的参数值中，选择最能解释观察到的数据的参数值。例如在遥感中，它使用概率来将图像中的每个像素分配给最可能的土地覆盖类型，并可以设置概率阈值来决定是否进行分类。\n\n\n\n\n\nMaximum likelihood classifier, Source: (Núñez et al. 2019)\n\n\n\n\nSupport Vector Machine\n支持向量机（SVM）是一种监督学习模型，用于分类和回归分析。假设我们有一个训练数据集，其中每个数据点都属于两个类别中的一个。SVM 的目标是找到一个超平面，使得该超平面能够将两类数据点尽可能分开。\n\n\n\n\n\nSVM example of linearly separable data, Source: (Sheykhmousa and Mahdianpari 2020)"
  },
  {
    "objectID": "Week_8.html#knowledge-from-the-lecture",
    "href": "Week_8.html#knowledge-from-the-lecture",
    "title": "7  Week_8",
    "section": "7.1 Knowledge From the Lecture",
    "text": "7.1 Knowledge From the Lecture\nObject based image analysis (OBIA)\n这是一种考虑地面物体如何在栅格单元上表示的分析方法。 Simple Linear Iterative Clustering算法是生成超像素的最常用方法。它将图像分割成具有相似颜色和空间位置的区域，称为超像素。超像素分割可以用于图像降噪、边缘检测、纹理分析等任务。SLIC算法的基本思想是迭代地更新每个像素点的聚类标签。在每个迭代步骤中，算法会计算每个像素点与其相邻像素点的距离，并将其分配给距离最近的聚类中心。\n可能这个概念有些的抽象对于非初学者来说，我把它细致化的解释一下 想象一下，你有一张由许多像素点组成的图像。你想将这些像素点分成若干个组，使得每个组中的像素点具有相似的颜色和空间位置。\nSLIC算法就像是一个将像素点分组的”游戏”。游戏的规则如下：\n首先，你需要在图像中随机选择一些点作为”聚类中心”。 然后，你需要计算每个像素点与所有聚类中心的距离。 每个像素点将被分配给距离它最近的聚类中心。 接下来，你需要更新每个聚类中心的坐标，使其位于该聚类中所有像素点的平均位置。 重复步骤2到4，直到所有像素点都被分配给某个聚类中心。 游戏结束后，你将得到一组具有相似颜色和空间位置的像素点，即超像素。\n\n\n\n\n\nComparison of Simple Linear Iterative Clustering (SLIC) and SLICO superpixel adherence to natural image boundaries derived using initial clustering of 10 × 10 pixels., Source: (Csillik 2017)\n\n\n\n\nSub pixel analysis\n亚像素分析是指在图像的像素之间进行分析的技术。传统图像处理方法只关注每个像素的灰度值，而亚像素分析则可以利用像素之间灰度的细微差别来获取更精确的信息。其应用范围很广，包括：图像增强，边缘检测，纹理分析，目标识别.\n\n\n\n\n\nSuperpixel Generation Algorithm\n\n\n\n\n评估遥感数据分类准确度\n讲述了生产遥感数据后如何进行准确度评估，这是机器学习工作流程的一部分。其中的三个重要指标是：制图者准确率（Producer’s Accuracy）、用户准确率（User’s Accuracy）和总体准确率（Overall Accuracy），以及如何利用混淆矩阵（Confusion Matrix）来计算这些指标。\n模型预测结果正确时： 真阳性（TP）是模型正确预测阳性类别； 真阴性（TN）是模型正确预测阴性类别。 模型预测结果错误时： 假阳性（FP）是模型错误地预测为阳性，但实际为阴性； 假阴性（FN）是模型错误地预测为阴性，但实际为阳性。\n计算上面的指标是如下表\n\n\n\n\n\n\n\n\nAccuracy Metric\nFormula\nShort Definition\n\n\n\n\nProducer’s Accuracy\nTP / (TP + FN)\nCorrect classification proportion compared to ground truth.\n\n\nUser’s Accuracy\nTP / (TP + FP)\nCorrect classification proportion out of all classified.\n\n\nOverall Accuracy\n(TP + TN) / (TP + FP + FN + TN)\nProportion of all correctly classified pixels.\n\n\n\n在此基础上可以使用凯帕系数来进行有效评估分类模型的性能，确保分类结果的可靠性和准确性。凯帕系数的值范围从-1（完全不一致）到1（完全一致）。值为0表示一致性与随机机会相同，而值接近1表示非常高的一致性。其计算方法是（实际一致性 - 随机一致性）/（1 - 随机一致性）。\n\n\n\n\n\nExample of Accuracies and kappa coefficient of land use:land cover (LULC) classifications in the SMA, Source: (Priyankara et al. 2019)\n\n\n\n\nF1 Score\n当你的数据集中的类别是不平衡的，即一个类的样本数量远多于另一个类，卡帕系数将不使用，但是F1 Score特别有用。在这种情况下，单纯使用准确率可能不足以反映模型的性能，因为模型可能只是在预测主导类别方面表现良好，而忽视了少数类。F1 Score通过平衡精确率（预测为正类别中实际为正类别的比例）和召回率（实际为正类别中预测为正类别的比例），提供了一个更全面的性能度量。如果你的任务中同样重视精确率和召回率，即你希望减少假阳性和假阴性的数量，那么F1 Score是一个合适的选择。它确保了你不会因为提高另一个而牺牲了其中一个指标。尽管F1 Score可以扩展到多类分类问题，但它主要适用于二分类问题，尤其是当正负样本的重要性基本相等时。在研究二分类问题时候可以引用ROC曲线，其提供了一种在不同类别分布或不同的代价/权重条件下比较多个分类器的方法。即使在数据集随时间变化或在不同数据集上，ROC曲线和AUC值也能为模型的比较提供一致的评估标准。\nSpatial cross validation\n在传统的machine Learning交叉验证方法中，数据集被随机分成训练集和测试集。模型在训练集上进行训练，并在测试集上进行评估。然而，这种随机划分的方法忽略了遥感数据中一个关键特性——空间自相关，即相邻区域之间往往具有相似的属性。\n举一个例子现在有一张包含多种地形的大型遥感图像，比如森林、湖泊和城市区域。任务目标是创建一个计算机模型，这个模型可以查看这张图像的任何部分，并准确地告诉你那里是森林、湖泊还是城市。为了训练这个模型，你需要从图像中选取一些样本（即图像的一小部分），告诉模型这些样本分别属于哪种地形。然后，模型会学习这些样本，尝试理解不同地形的外观。\n但这里有个问题：如果你随机选择样本，那么靠得很近的样本可能会同时出现在训练数据（模型用来学习的数据）和测试数据（用来检验模型准确性的数据）中。这就像是在考试前就已经知道了部分考题，这可能会让模型看起来表现得很好，但实际上它可能并没有真正学到如何区分不同的地形，而只是记住了那些特定的样本。\n空间交叉验证就是为了解决这个问题。我们不是随机选择样本，而是将整个图像分成几个大块区域。我们可以确保某些区域仅用于训练模型，而其他区域则用于测试模型。这样，我们就可以确信，模型在评估时遇到的数据是它之前从未见过的，这有助于我们更准确地判断模型的实际性能。\n举个例子，假设你有一张包含城市、森林和湖泊的大地图。你将地图分成了东、西两部分。你用东半部分的数据训练你的模型，这意味着模型将看到并学习这一区域的城市、森林和湖泊是什么样的。然后，你用西半部分的数据测试模型，看看它是否能准确识别出它从未”见过”的地区的不同地形。通过这种方式，你可以更好地评估模型在处理新、未知区域时的实际表现能力。\n\n\n\n\n\nImportance of spatial predictor variable selection in machine learning applications – Moving from data reproduction to spatial prediction, Source: (Meyer et al. 2019)"
  }
]