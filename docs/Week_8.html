<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Remote sensing learning Diary - 7&nbsp; Week_8 Classification II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Week_9.html" rel="next">
<link href="./Week_7.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Week_8.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_8 Classification II</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Remote sensing learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week_1 Intro to Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week_2 Presentation of Snetinel-5p</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Week_3 Corrections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week_4 Flooding Issues In Dublin</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week_6 Intro to GEE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_7 Classification I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_8 Classification II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Week_9 SAR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Bibliography</strong></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#knowledge-from-the-lecture" id="toc-knowledge-from-the-lecture" class="nav-link active" data-scroll-target="#knowledge-from-the-lecture"><span class="header-section-number">7.1</span> <strong>Knowledge From the Lecture</strong></a>
  <ul class="collapse">
  <li><a href="#object-based-image-analysis-obia" id="toc-object-based-image-analysis-obia" class="nav-link" data-scroll-target="#object-based-image-analysis-obia"><span class="header-section-number">7.1.1</span> Object based image analysis (OBIA)</a></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">7.5</span> <strong>Reference</strong></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_8 Classification II</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="knowledge-from-the-lecture" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="knowledge-from-the-lecture"><span class="header-section-number">7.1</span> <strong>Knowledge From the Lecture</strong></h2>
<section id="object-based-image-analysis-obia" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored"><span class="header-section-number">7.1.1</span> Object based image analysis (OBIA)</h3>
<div style="text-align: justify;">
<p>This is an analytical method that considers how ground objects are represented on raster cells. The Simple Linear Iterative Clustering algorithm is the most common method for generating hyperpixels. It segments the image into regions with similar colours and spatial locations called hyperpixels. Hyperpixel segmentation can be used for tasks such as image noise reduction, edge detection, texture analysis etc.The basic idea of SLIC algorithm is to iteratively update the clustering labels for each pixel point. In each iterative step, the algorithm calculates the distance of each pixel point from its neighbouring pixel points and assigns it to the closest cluster centre.</p>
<p>The SLIC algorithm is like a “game” of grouping pixels. The rules of the game are as follows:</p>
<ul>
<li><p>First, need to randomly select some points in the image as “cluster centres”. Then, you need to calculate the distance of each pixel from all the cluster centres.</p></li>
<li><p>Each pixel will be assigned to the cluster centre closest to it.</p></li>
<li><p>Next, the coordinates of each cluster centre need to be updated so that they are located at the average position of all pixels in the cluster.</p></li>
<li><p>Repeat the above steps until all pixel points are assigned to a cluster centre.</p></li>
<li><p>Tour At the end of the game, a set of pixel points with similar colours and spatial locations, i.e., hyperpixels, will be obtained.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_8/Comparison of Simple Linear Iterative Clustering (SLIC) and SLICO superpixel adherence to natural image boundaries derived using initial clustering of 10 × 10 pixels..png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Comparison of Simple Linear Iterative Clustering (SLIC) and SLICO superpixel adherence to natural image boundaries derived using initial clustering of 10 × 10 pixels., Source: <a href="https://www.researchgate.net/publication/314492084_Fast_Segmentation_and_Classification_of_Very_High_Resolution_Remote_Sensing_Data_Using_SLIC_Superpixels"><span class="citation" data-cites="csillik2017">(</span></a><a href="#ref-csillik2017" role="doc-biblioref">Csillik 2017</a>)</figcaption>
</figure>
</div>
</div>
</div>
<section id="sub-pixel-analysis" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="sub-pixel-analysis"><span class="header-section-number">7.1.2</span> Sub pixel analysis</h3>
<p>Subpixel analysis is a technique that analyses an image between its pixels. While traditional image processing methods focus only on the grey value of each pixel, subpixel analysis can take advantage of the subtle differences in grey scale between pixels to obtain more precise information. It has a wide range of applications, including: image enhancement, edge detection, texture analysis, target recognition.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_8/Superpixel Generation Algorithm.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Superpixel Generation Algorithm</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="assessment-of-the-accuracy-of-classification-of-remotely-sensed-data" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="assessment-of-the-accuracy-of-classification-of-remotely-sensed-data"><span class="header-section-number">7.1.3</span> Assessment of the accuracy of classification of remotely sensed data</h3>
<p>Describes how accuracy assessment is performed after producing remote sensing data as part of the machine learning workflow. Three of the key metrics are Producer’s Accuracy, User’s Accuracy, and Overall Accuracy, and how these metrics can be calculated using the Confusion Matrix.</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>True Positive (TP)</td>
<td>The model correctly predicts the positive class.</td>
</tr>
<tr class="even">
<td>True Negative (TN)</td>
<td>The model correctly predicts the negative class.</td>
</tr>
<tr class="odd">
<td>False Positive (FP)</td>
<td>The model incorrectly predicts positive, but the actual class is negative.</td>
</tr>
<tr class="even">
<td>False Negative (FN)</td>
<td>The model incorrectly predicts negative, but the actual class is positive.</td>
</tr>
</tbody>
</table>
<p>On this basis the Kappa coefficient can be used to carry out an effective assessment of the performance of the classification model to ensure the reliability and accuracy of the classification results. The value of the Kappa coefficient ranges from -1 (complete inconsistency) to 1 (complete agreement). A value of 0 indicates that the consistency is the same as random chance, while a value close to 1 indicates very high consistency. It is calculated as (actual consistency - random consistency)/(1 - random consistency).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_8/Accuracies and kappa coefficient of land use:land cover (LULC) classifications in the SMA.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Example of Accuracies and kappa coefficient of land use:land cover (LULC) classifications in the SMA, Source: <a href="https://www.researchgate.net/figure/Accuracies-and-kappa-coefficient-of-land-use-land-cover-LULC-classifications-in-the_tbl2_335755723"><span class="citation" data-cites="priyankara2019">(</span></a><a href="#ref-priyankara2019" role="doc-biblioref">Priyankara et al. 2019</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="f1-score" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="f1-score"><span class="header-section-number">7.1.4</span> F1 Score</h3>
<p>When the classes in your dataset are unbalanced, i.e.&nbsp;one class has far more samples than another, the kappa coefficient will not be used, but the F1 Score is particularly useful. In this case, using precision alone may not be sufficient to reflect the model’s performance, as the model may only perform well in predicting the dominant class while ignoring a few.The F1 Score provides a more comprehensive performance metric by balancing precision (the proportion of predicted-positive classes that are actually positive) and recall (the proportion of actual-positive classes that are predicted-positive). If precision and recall are equally valued in your task, i.e.&nbsp;you want to reduce the number of false positives and false negatives, then F1 Score is an appropriate choice. It ensures that you don’t sacrifice one of the metrics by improving the other. Although the F1 Score can be extended to multi-class classification problems, it is mainly suitable for binary classification problems, especially when the importance of positive and negative samples is essentially equal. The ROC curve can be invoked when studying binary classification problems, which provides a way to compare multiple classifiers under different class distributions or different cost/weight conditions. ROC curves and AUC values provide a consistent evaluation criterion for model comparisons, even when the data sets vary over time or across data sets.</p>
</section>
<section id="spatial-cross-validation" class="level3" data-number="7.1.5">
<h3 data-number="7.1.5" class="anchored" data-anchor-id="spatial-cross-validation"><span class="header-section-number">7.1.5</span> Spatial cross validation</h3>
<p>In the traditional machine Learning cross-validation approach, the dataset is randomly divided into a training set and a test set. Models are trained on the training set and evaluated on the test set. However, this random division approach ignores a key property —— spatial autocorrelation in remotely sensed data, i.e., neighbouring regions often have similar attributes to each other.</p>
<p>As an example now there is a large remote sensing image that contains a variety of terrain such as forests, lakes and urban areas. The goal of the task is to create a computer model that can look at any part of this image and tell you exactly whether it is a forest, lake or city. To train this model, you need to select some samples from the image (i.e., a small part of the image) and tell the model which terrain each of these samples belongs to. The model then learns these samples and tries to understand the appearance of the different terrains.</p>
<p>But here’s the catch: if you randomly select samples, then samples that are very close together may appear in both the training data (the data the model uses to learn) and the test data (the data used to check the model’s accuracy). This is like knowing part of the test questions before you take the test, which may make the model seem to perform well, but in reality it may not have actually learnt how to differentiate between different terrains, but only remembered those particular samples.</p>
<p>Spatial cross-validation is designed to solve this problem. Instead of randomly selecting samples, we divide the entire image into several large regions. We can make sure that certain regions are only used to train the model, while others are used to test the model. This way, we can be sure that the model is evaluated with data it has never seen before, which helps us to judge the actual performance of the model more accurately.</p>
<p>For example, suppose you have a large map containing cities, forests, and lakes. You divide the map into two parts, east and west. You train your model with the data from the eastern half, which means that the model will see and learn what the cities, forests, and lakes in this area look like. Then you test the model on the western half of the map to see if it can accurately recognise different terrain in areas it has never “seen” before. In this way, you can better assess how well the model actually performs when dealing with new and unknown areas.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_8/Concept of random and spatial cross-validation.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Importance of spatial predictor variable selection in machine learning applications – Moving from data reproduction to spatial prediction, Source: <a href="https://www.researchgate.net/figure/Concept-of-random-and-spatial-cross-validation-CV-A-total-dataset-here-9-different_fig3_335318909"><span class="citation" data-cites="meyer2019">(</span></a><a href="#ref-meyer2019" role="doc-biblioref">Meyer et al. 2019</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="practical" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="practical"><span class="header-section-number">7.2</span> <strong>Practical</strong></h2>
<section id="accuracy-assessment-result-hyperparameter-tuning" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="accuracy-assessment-result-hyperparameter-tuning"><span class="header-section-number">7.2.1</span> Accuracy Assessment Result &amp; Hyperparameter Tuning</h3>
<p>A reference dataset of Milan was introduced, defining a series of prediction bands, and the dataset was divided into a training and a test set, with 80% used for training and 20% for testing. A Random Forest classifier was trained for predicting the target category based on the input band data. The accuracy of the model was evaluated using the test set and a confusion matrix was generated to detail the performance of the model (results below).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_8/Accuracy Assessment Result.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Accuracy Assessment Result</figcaption>
</figure>
</div>
</div>
</div>
<p>The overall accuracy of 83.33% indicates the proportion of samples correctly classified by the model. The model has high confidence for each predicted category with a Kappa value of 0.773 implying good agreement.</p>
</section>
</section>
<section id="application" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="application"><span class="header-section-number">7.3</span> <strong>Application</strong></h2>
<p>Object-based image analysis (OBIA) techniques have been widely used in remote sensing, especially in improving the accuracy of high-resolution (HR) remote sensing image classification. By considering the spatial relationship between segmented objects and integrating the a priori knowledge, the OBIA method not only improves the classification accuracy, but also enhances the recognition of complex surface features. For example, Gun and Chen <span class="citation" data-cites="gun2023">(<a href="#ref-gun2023" role="doc-biblioref">2023</a>)</span> proposed a novel classification scheme for HR remotely sensed images, which maintains spatial relationships and significantly improves classification accuracy by utilising a knowledge graph (KG). In addition, Ghorbanzadeh, Gholamnia, and Ghamisi <span class="citation" data-cites="ghorbanzadeh2023">(<a href="#ref-ghorbanzadeh2023" role="doc-biblioref">2023</a>)</span> evaluated a rule-based OBIA landslide detection method that combines a probabilistic deep learning model with image segmentation and rule-based classification to effectively improve the detection accuracy.</p>
<p>The application of F1 score in remote sensing image analysis shows that it is an important tool for evaluating the performance of different feature selection methods in object-oriented remote sensing image classification experiments.The F1 score provides a balanced and reliable performance evaluation metric in remote sensing by combining precision and recall.Lv et al. <span class="citation" data-cites="lv2022">(<a href="#ref-lv2022" role="doc-biblioref">2022</a>)</span> provide a balanced and reliable performance evaluation metric in remote sensing by combining the Fisher Score and the minimum redundancy maximum relevance (mRMR) feature selection method, showing how the F1 score can be used to improve the efficiency and accuracy of remote sensing image classification. Meanwhile, in the Through-the-Wall Radar Imaging (TWRI) technique, the F1 score is used to evaluate the ability of compression-aware (CS) algorithms to reconstruct images at different signal-to-noise ratios (SNR) and compression rates, as studied by John and Brad<span class="citation" data-cites="john2018">(<a href="#ref-john2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>The importance of spatial cross-validation as an important technique in remote sensing data classification is that it provides an unbiased estimate of the prediction error and ensures the reliability of remote sensing data analysis. This approach pays special attention to the spatial autocorrelation of the data and ensures the generalisation ability of the classification model through spatial leave-one-out cross-validation or similar techniques.Karasiak et al. <span class="citation" data-cites="karasiak2022">(<a href="#ref-karasiak2022" role="doc-biblioref">2022</a>)</span> showed how spatial leave-one-out cross-validation can provide unbiased estimation of the prediction error and ensures the fidelity of the resultant maps. Similarly, Routh et al. <span class="citation" data-cites="routh2018">(<a href="#ref-routh2018" role="doc-biblioref">2018</a>)</span> showed through the iSLOOCV method how spatial autocorrelation can be taken into account in marine remote sensing data to improve classification accuracy through the integration of iterative error estimation over an interval range.</p>
</section>
<section id="reflection" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="reflection"><span class="header-section-number">7.4</span> <strong>Reflection</strong></h2>
<p>The journey through remote sensing is exhilarating, merging complex technology with real-world applications and personal development. My recent deep dive into advanced techniques like Object-Based Image Analysis (OBIA), subpixel analysis, and hyperpixel algorithms, along with accuracy assessment practices, has profoundly expanded my understanding of remote sensing’s potential and challenges. The transformative learning of OBIA, which emphasizes the significance of object-oriented analysis over mere pixel examination, has revolutionized my approach to data interpretation, particularly through hands-on applications in areas like landslide detection with deep learning, thereby enriching my practical understanding of the field’s innovative frontiers.</p>
<p>The hands-on engagement with accuracy assessment methodologies, especially through random forest classifiers, offered deep insights into the practical application of theoretical knowledge, emphasizing the storytelling aspect of data and the power of analytical tools to uncover it. Additionally, delving into spatial cross-validation illuminated the importance of acknowledging spatial autocorrelation to enhance the generalizability and reliability of models, a crucial step in ensuring their effectiveness on unseen data. This educational journey not only bolstered my knowledge and analytical prowess but also stoked a deeper passion for remote sensing, inspiring confidence to navigate new challenges and apply these techniques to make meaningful real-world impacts.</p>
</section>
</div>
</section>
</section>
<section id="reference" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="reference"><span class="header-section-number">7.5</span> <strong>Reference</strong></h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-csillik2017" class="csl-entry" role="listitem">
Csillik, Ovidiu. 2017. <span>“Fast Segmentation and Classification of Very High Resolution Remote Sensing Data Using SLIC Superpixels.”</span> <em>Remote Sensing</em> 9 (March): 243. <a href="https://doi.org/10.3390/rs9030243">https://doi.org/10.3390/rs9030243</a>.
</div>
<div id="ref-ghorbanzadeh2023" class="csl-entry" role="listitem">
Ghorbanzadeh, Omid, Khalil Gholamnia, and Pedram Ghamisi. 2023. <span>“The Application of ResU-Net and OBIA for Landslide Detection from Multi-Temporal Sentinel-2 Images.”</span> <em>Big Earth Data</em> 7 (4): 961–85. <a href="https://doi.org/10.1080/20964471.2022.2031544">https://doi.org/10.1080/20964471.2022.2031544</a>.
</div>
<div id="ref-gun2023" class="csl-entry" role="listitem">
Gun, Zhao, and Jianyu Chen. 2023. <span>“Novel Knowledge Graph- and Knowledge Reasoning-Based Classification Prototype for OBIA Using High Resolution Remote Sensing Imagery.”</span> <em>Remote Sensing</em> 15 (2): 321. <a href="https://doi.org/10.3390/rs15020321">https://doi.org/10.3390/rs15020321</a>.
</div>
<div id="ref-john2018" class="csl-entry" role="listitem">
John, F. Silny, and A. Flanders Brad. 2018. <span>“Imaging Spectrometer f-Number Optimization for Remote Sensing of Gases.”</span> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10768/2323616/Imaging-spectrometer-F-number-optimization-for-remote-sensing-of-gases/10.1117/12.2323616.full#_=_">https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10768/2323616/Imaging-spectrometer-F-number-optimization-for-remote-sensing-of-gases/10.1117/12.2323616.full#_=_</a>.
</div>
<div id="ref-karasiak2022" class="csl-entry" role="listitem">
Karasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. <span>“Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.”</span> <em>Machine Learning</em> 111 (7): 2715–40. <a href="https://doi.org/10.1007/s10994-021-05972-1">https://doi.org/10.1007/s10994-021-05972-1</a>.
</div>
<div id="ref-lv2022" class="csl-entry" role="listitem">
Lv, Chengzhe, Yuefeng Lu, Miao Lu, Xinyi Feng, Huadan Fan, Changqing Xu, and Lei Xu. 2022. <span>“A Classification Feature Optimization Method for Remote Sensing Imagery Based on Fisher Score and mRMR.”</span> <em>Applied Sciences</em> 12 (September): 8845. <a href="https://doi.org/10.3390/app12178845">https://doi.org/10.3390/app12178845</a>.
</div>
<div id="ref-meyer2019" class="csl-entry" role="listitem">
Meyer, Hanna, Christoph Reudenbach, Stephan Wöllauer, and Thomas Nauss. 2019. <em>Importance of Spatial Predictor Variable Selection in Machine Learning Applications – Moving from Data Reproduction to Spatial Prediction</em>.
</div>
<div id="ref-priyankara2019" class="csl-entry" role="listitem">
Priyankara, Prabath, Manjula Ranagalage, Dr Dissanayake, Takehiro Morimoto, and Yuji Murayama. 2019. <span>“Spatial Process of Surface Urban Heat Island in Rapidly Growing Seoul Metropolitan Area for Sustainable Urban Planning Using Landsat Data.”</span> <em>Journal of Climate</em> 7 (September): 110. <a href="https://doi.org/10.3390/cli7090110">https://doi.org/10.3390/cli7090110</a>.
</div>
<div id="ref-routh2018" class="csl-entry" role="listitem">
Routh, Devin, Lindsi Seegmiller, Charlie Bettigole, Catherine Kuhn, Chadwick Oliver, and Henry Glick. 2018. <span>“Improving the Reliability of Mixture Tuned Matched Filtering Remote Sensing Classification Results Using Supervised Learning Algorithms and Cross-Validation.”</span> <em>Remote Sensing</em> 10 (October): 1675. <a href="https://doi.org/10.3390/rs10111675">https://doi.org/10.3390/rs10111675</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Week_7.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_7 Classification I</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Week_9.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Week_9 SAR</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>