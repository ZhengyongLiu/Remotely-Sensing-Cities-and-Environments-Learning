<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Remote sensing learning Diary - 5&nbsp; Week_6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Week_7.html" rel="next">
<link href="./Week_4.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Week_6.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week_6</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Remote sensing learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week_1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week_2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Week_3</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week_4</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_6.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week_6</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_7</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Bibliography</strong></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#knowledge-from-the-lecture" id="toc-knowledge-from-the-lecture" class="nav-link active" data-scroll-target="#knowledge-from-the-lecture"><span class="header-section-number">5.1</span> <strong>Knowledge From the Lecture</strong></a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">5.5</span> Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week_6</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="knowledge-from-the-lecture" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="knowledge-from-the-lecture"><span class="header-section-number">5.1</span> <strong>Knowledge From the Lecture</strong></h2>
<div style="text-align: justify;">
<p>Google Earth Engine is a cloud-based platform provided by Google for online visual computation and analysis of large amounts of global-scale geoscience data (especially satellite data). It is characterised by allowing large-scale geospatial analyses, running very fast, having code that runs on the client side, and storing the data on the server.</p>
<section id="raster-and-vector-data-in-gee" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="raster-and-vector-data-in-gee"><span class="header-section-number">5.1.1</span> Raster and vector data in GEE</h3>
<ol type="1">
<li>Raster data, called “Image”, has bands.</li>
<li>Vector data, called “Feature”, has geometry and a dictionary of properties.。</li>
</ol>
</section>
<section id="image-scaling-in-gee" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="image-scaling-in-gee"><span class="header-section-number">5.1.2</span> Image scaling in GEE</h3>
<ol type="1">
<li>Refers to the resolution of the image, i.e.&nbsp;the actual ground distance represented by each pixel.</li>
<li>GEE automatically selects the appropriate zoom level based on the analysis requirements.</li>
</ol>
</section>
<section id="projection-in-gee" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="projection-in-gee"><span class="header-section-number">5.1.3</span> Projection in GEE</h3>
<p>GEE supports a variety of projections, including Mercator projection, Albers projection, and isometric cylindrical projection. The user can select the appropriate projection for analysis.</p>
</section>
<section id="how-to-use-gee" class="level3" data-number="5.1.4">
<h3 data-number="5.1.4" class="anchored" data-anchor-id="how-to-use-gee"><span class="header-section-number">5.1.4</span> How to use GEE</h3>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_6/ How to use GEE.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">How to use GEE, Source: <a href="https://earthengine.google.com/platform/">Google Earth Engine</a></figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="operations-that-can-be-performed-in-gee" class="level3" data-number="5.1.5">
<h3 data-number="5.1.5" class="anchored" data-anchor-id="operations-that-can-be-performed-in-gee"><span class="header-section-number">5.1.5</span> Operations that can be performed in GEE</h3>
<ol type="1">
<li>Geometric operations: e.g.&nbsp;spatial operations, joins (Joins), region statistics (e.g.&nbsp;average temperature of a neighbourhood), filtering of images or specific values.</li>
<li>Machine learning, both supervised and unsupervised, deep learning using TensorFlow, exploring relationships between variables.</li>
<li>Applications/outputs: online graphs, scalable geospatial applications using GEE data</li>
</ol>
</section>
<section id="reduce-the-image-in-gee" class="level3" data-number="5.1.6">
<h3 data-number="5.1.6" class="anchored" data-anchor-id="reduce-the-image-in-gee"><span class="header-section-number">5.1.6</span> Reduce the Image in GEE</h3>
<p>Reducing the image by region and reducing the image by neighbour are both functions that are used to regionalise or neighbourhoodise an image. The main difference between them is:</p>
<ol type="1">
<li><p>Reducing the image by region operates on the image according to a specified region. Each region can be any shape and can overlap. The function performs the specified computation on all pixels within each region and returns a new image containing the statistics of the region.</p></li>
<li><p>Reducing the image by neighbour is to operate on the image according to the specified neighbourhood. The neighbourhood of each pixel is the pixels within a certain range around it. This function performs the specified computation on each pixel and all pixels within its neighbourhood, and returns an image containing the pixel’s new value.</p></li>
</ol>
</section>
<section id="linear-regression-join-in-gee-暂时写不出来" class="level3" data-number="5.1.7">
<h3 data-number="5.1.7" class="anchored" data-anchor-id="linear-regression-join-in-gee-暂时写不出来"><span class="header-section-number">5.1.7</span> Linear Regression &amp; Join in GEE (暂时写不出来)</h3>
</section>
<section id="practical" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="practical"><span class="header-section-number">5.2</span> <strong>Practical</strong></h2>
<section id="compare-with-rgb-ndvi" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="compare-with-rgb-ndvi"><span class="header-section-number">5.2.1</span> Compare with RGB &amp; NDVI</h3>
<div class="cell">
<div class="cell-output-display">
<iframe style="height:600px; width:100%" src="https://ee-liulzy1999.projects.earthengine.app/view/rgb--ndvi-roller-shutter"></iframe>
</div>
</div>
<p><a href="https://ee-liulzy1999.projects.earthengine.app/view/rgb--ndvi-roller-shutter">Compare with RGB &amp; NDVI</a> Slide the slider to see the changes in RGB and NDVI.</p>
</section>
<section id="pca-analysis" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="pca-analysis"><span class="header-section-number">5.2.2</span> PCA Analysis</h3>
<p>Selecting a region, it first normalizes the image bands, calculates the covariance matrix, extracts the eigenvalues and eigenvectors, and then projects the image data into the principal component space. Finally, it displays the first principal component of the PCA result on the map.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_6/PCA Analysis.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">PCA Analysis</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="applications" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="applications"><span class="header-section-number">5.3</span> <strong>Applications</strong></h2>
<section id="general-applications" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="general-applications"><span class="header-section-number">5.3.1</span> General Applications</h3>
<p>GEE has been the focus of attention in remote sensing big data processing.GEE is a cloud-based platform for parallel processing of geospatial data globally using Google’s cloud.GEE is a free cloud-based platform hosting more than 40 years of petabyte-sized remote sensing data, such as Landsat, MODIS, National Oceanic and Atmospheric Administration’s Advanced Ultra-High Resolution Radiometer (NOAA AVHRR), Sentinel 1, 2, 3, and 5-P; and Advanced Land Observing Satellite (ALOS) data<span class="citation" data-cites="aghamiri">(<a href="#ref-aghamiri" role="doc-biblioref">Aghamiri et al., n.d.</a>)</span>. GEE also includes climate-weather and geophysical datasets. Other off-the-shelf products such as the Enhanced Vegetation Index (EVI) and the Normalised Vegetation Index (NDVI) are also available. In addition to having access to a large repository of raw remote sensing imagery, users can access pre-processed imagery, cloud removal imagery and mosaics in the GEE data catalogue<span class="citation" data-cites="ritika">(<a href="#ref-ritika" role="doc-biblioref">Ritika, n.d.</a>)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_6/A summary of the algorithms and capabilities available in code editor-Google Earth Engine.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">A summary of the algorithms and capabilities available in code editor-Google Earth Engine, Author: <a href="https://www.researchgate.net/publication/341228837_Google_Earth_Engine_for_geo-big_data_applications_A_meta-analysis_and_systematic_review"><span class="citation" data-cites="tamiminia2020">(</span></a><a href="#ref-tamiminia2020" role="doc-biblioref">Tamiminia et al. 2020</a>)</figcaption>
</figure>
</div>
</div>
</div>
<p>Here are some applications of GEE in practice.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_6/GEE in Different Applications.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">GEE in Different Applications, Author: <a href="https://www.researchgate.net/publication/341228837_Google_Earth_Engine_for_geo-big_data_applications_A_meta-analysis_and_systematic_review"><span class="citation" data-cites="tamiminia2020">(</span></a><a href="#ref-tamiminia2020" role="doc-biblioref">Tamiminia et al. 2020</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="gee-and-data-types" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="gee-and-data-types"><span class="header-section-number">5.3.2</span> GEE and data types</h3>
<p>Much of the academic use of GEE has been optical, thanks in large part to the 40-year free archive of Landsat imagery, and optical remote sensing data is still the most commonly used data source.The GEE data catalogue provides optical satellite imagery from 1972 to the present day, allowing researchers to conduct Earth monitoring studies<span class="citation" data-cites="pham-duc2023">(<a href="#ref-pham-duc2023" role="doc-biblioref">Pham-Duc et al. 2023</a>)</span>. In addition, the wide range of applications by GEE users shows that optical images are easier to process and interpret for non-remote sensing experts. This is one of the reasons why GEE has a global reach in a wide range of scientific fields. At the same time, the combination of SAR and optical satellite data can help researchers to solve problems such as cloud cover. Especially in the tropics, the efficacy of optical images can be greatly affected due to continuous cloud cover and situations such as forest fires. Therefore, combining optical and SAR data can improve the accuracy of classification and provide more information to monitor surface changes.<span class="citation" data-cites="lea2023">(<a href="#ref-lea2023" role="doc-biblioref">Lea et al. 2023</a>)</span>.</p>
</section>
<section id="gee-and-sensor-type" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="gee-and-sensor-type"><span class="header-section-number">5.3.3</span> GEE and sensor type</h3>
<p>Landsat is considered an important source of remote sensing data in the GEE, as it provides a continuous image of the Earth’s surface.The Landsat 9 satellite will be launched in 2020 with the aim of continuing the Landsat programme’s key role in monitoring the Earth’s resources. Long-term land cover change studies can be carried out on a regional and global scale<span class="citation" data-cites="pham-duc2023">(<a href="#ref-pham-duc2023" role="doc-biblioref">Pham-Duc et al. 2023</a>)</span>.</p>
<p>Sentinel-1 is another popular source of satellite imagery and has achieved very accurate classification results.Sentinel-1 consists of two satellites, Sentinel-1A and Sentinel 1-B, which were launched in 2014 and 2016, respectively, with a spatial resolution of 10 m and a revisit time of 6 days<span class="citation" data-cites="ariascuenca2023">(<a href="#ref-ariascuenca2023" role="doc-biblioref">Arias Cuenca 2023</a>)</span>. It is equipped with a dual-polarised C-band SAR sensor that provides data in all-weather, day and night conditions.The Sentinel-2 mission consists of a constellation of two satellites, Sentinel-2A (launched in 2015) and Sentinel-2B (launched in 2017), which provide spatially resolved 10 m, 20 m and 60 m optical images, and temporal resolution of about 5 days<span class="citation" data-cites="xu2022 lechner2022">(<a href="#ref-xu2022" role="doc-biblioref">Xu, Heremans, and Somers 2022</a>; <a href="#ref-lechner2022" role="doc-biblioref">Lechner et al. 2022</a>)</span>.</p>
<p>The Moderate Resolution Imaging Spectroradiometer (MODIS) was launched on the Terra satellite in 1999 and on the Aqua satellite in 2002. Researchers can access MODIS data in GEE in 36 spectral bands and at three varying spatial resolutions (250 m, 500 m, and 1 km) at 1-day revisit times. Even though MODIS has a low spatial resolution, its high temporal resolution allows researchers to monitor short- and long-term global environmental change (dynamics)<span class="citation" data-cites="wu2020">(<a href="#ref-wu2020" role="doc-biblioref">Wu and Xiong 2020</a>)</span>.</p>
</section>
<section id="remote-sensing-data-analysis" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="remote-sensing-data-analysis"><span class="header-section-number">5.3.4</span> Remote sensing data analysis</h3>
<section id="machine-learning-techniques" class="level4" data-number="5.3.4.1">
<h4 data-number="5.3.4.1" class="anchored" data-anchor-id="machine-learning-techniques"><span class="header-section-number">5.3.4.1</span> Machine learning techniques</h4>
<p>Machine learning is a subset of artificial intelligence that deals with the design of algorithms to train models to make decisions or predictions. Machine learning methods can be divided into two broad categories: parametric and non-parametric. Parametric machine learning algorithms use a fixed number of parameters or assumptions. Machine learning methods have been effectively used for remote sensing data processing. Classification, clustering, regression and dimensionality reduction are the four main categories of analysis for machine learning algorithms<span class="citation" data-cites="shaveta2023">(<a href="#ref-shaveta2023" role="doc-biblioref">Shaveta 2023</a>)</span>. Regression is a supervised machine learning method designed to estimate or predict output variables based on a set of covariates. Another positive aspect of linear regression is its fast computational speed, which is an important factor in geographic big data analysis<span class="citation" data-cites="googlee">(<a href="#ref-googlee" role="doc-biblioref"><span>“Google Earth Engine and Machine Learning for Earth Monitoring,”</span> n.d.</a>)</span>. Also the MLR model deals with the non-linear relationship between the dependent and independent variables in the prediction process.</p>
</section>
<section id="other-gee-image-processing-functions" class="level4" data-number="5.3.4.2">
<h4 data-number="5.3.4.2" class="anchored" data-anchor-id="other-gee-image-processing-functions"><span class="header-section-number">5.3.4.2</span> Other GEE image processing functions</h4>
<p>GEE provides a wide range of image processing tools suitable for the analysis of remotely sensed data. These tools cover time series analysis, feature extraction, colour compositing of images and image preprocessing, mainly for satellite images, rather than machine learning-based methods<span class="citation" data-cites="googlee">(<a href="#ref-googlee" role="doc-biblioref"><span>“Google Earth Engine and Machine Learning for Earth Monitoring,”</span> n.d.</a>)</span>. With the rapid changes in the Earth’s surface, time-series analysis of satellite imagery has become critical, helping to track trends, monitor changes and develop predictive models.GEE has been used for such analyses in a number of studies because of its ability to handle high resolution or large amounts of data, and is particularly good at monitoring changes in the land surface. Feature extraction techniques, by analysing spectral and geometric attributes of images, help to identify regional relationships in images, which is critical for resource conservation and information retention<span class="citation" data-cites="pham-duc2023">(<a href="#ref-pham-duc2023" role="doc-biblioref">Pham-Duc et al. 2023</a>)</span>. In addition, GEE’s visual interpretation tools are widely used in land monitoring studies to extract key information from colour composite images. In addition, GEE’s image pre-processing capabilities support image mosaicing, cloud processing and error detection, and although cloud coverage is a major challenge when working with optical data, GEE provides effective tools and algorithms to support these tasks<span class="citation" data-cites="lea2023">(<a href="#ref-lea2023" role="doc-biblioref">Lea et al. 2023</a>)</span>.</p>
<p>On the algorithmic side, there are challenges in implementing new algorithms, especially deep learning models. Although GEE has recently established a connection to TensorFlow, enabling users to interact with models stored on the Google AI platform, it does not directly support deep learning classifiers. Most research has used pixel-based classification methods and there is a need for better support for complex unsupervised classification algorithms as well as improvements in object-based image analysis, heavy vector manipulation, and the availability of high-resolution satellite imagery<span class="citation" data-cites="nia">(<a href="#ref-nia" role="doc-biblioref">Nia et al., n.d.</a>)</span>.</p>
</section>
</section>
</section>
<section id="reflection" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="reflection"><span class="header-section-number">5.4</span> <strong>Reflection</strong></h2>
<p>Reflecting on the comprehensive insights gained from the past week’s deep dive into Google Earth Engine (GEE), my intellectual journey through the realm of remote sensing has been both illuminating and transformative. The exploration extended beyond the fundamental technicalities of GEE’s raster and vector data handling; it ventured into the practical applications and profound implications of this powerful tool in understanding and interacting with our planet.</p>
<p>The nuanced understanding of image reduction techniques—distinguishing between region-based and neighbor-based reductions—was particularly revelatory. It highlighted GEE’s nuanced capacity to distill vast amounts of geospatial data into actionable insights. This aspect of GEE not only enhances its analytical precision but also expands its utility across various research and operational contexts, enabling a more targeted and efficient analysis of environmental phenomena.</p>
<p>The enlightening exploration of GEE’s vast capabilities has significantly broadened my perspective, revealing the interdisciplinary potential of remote sensing technology. It’s fascinating to see how the integration of various data types—from climate variables to topographical features—can offer a more comprehensive understanding of environmental dynamics. This integrative approach not only enhances the accuracy of environmental assessments but also fosters a more holistic understanding of our planet’s intricate systems.</p>
<p>The reflective journey through this week has been a blend of learning, discovery, and inspiration. It has fortified my appreciation for the critical role of remote sensing in environmental science and its potential to inform and inspire sustainable interventions. The insights gained are not merely academic; they resonate with the pressing need for innovative solutions to global environmental challenges. As I look forward to the continuation of this academic journey, I am motivated by the potential to contribute meaningfully to our collective understanding and stewardship of the Earth, leveraging the powerful capabilities of GEE to illuminate the path toward a sustainable future.</p>
<p>This experiential learning has not only enriched my technical proficiency but also deepened my commitment to leveraging technology in pursuit of environmental sustainability. The profound capabilities of GEE—to process, analyze, and visualize complex geospatial datasets—offer a compelling glimpse into the future of environmental monitoring and analysis. Embracing this technology’s potential can revolutionize our approach to confronting and mitigating the pressing environmental challenges of our time.</p>
</section>
</div>
</section>
<section id="reference" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="reference"><span class="header-section-number">5.5</span> Reference</h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-aghamiri" class="csl-entry" role="listitem">
Aghamiri, Mahtab, Amineh Ghorbani, Jolien Ubacht, Igor Nikolic, and Paulein Herder. n.d. <span>“Enabling Citizen Participation in Sustainable Collec- Tive Action In Smart Cities: The Case Of Buiksloter- Ham.”</span>
</div>
<div id="ref-ariascuenca2023" class="csl-entry" role="listitem">
Arias Cuenca, María. 2023. <span>“Sentinel-1 time series applications over agricultural fields: proposal, evaluation and comparison of different methodologies.”</span> <a href="https://doi.org/10.48035/Tesis/2454/45156">https://doi.org/10.48035/Tesis/2454/45156</a>.
</div>
<div id="ref-googlee" class="csl-entry" role="listitem">
<span>“Google Earth Engine and Machine Learning for Earth Monitoring.”</span> n.d. <a href="https://pos.sissa.it/429/021">https://pos.sissa.it/429/021</a>.
</div>
<div id="ref-lea2023" class="csl-entry" role="listitem">
Lea, James, Robert Fitt, Stephen Brough, Georgia Carr, Jonathan Dick, Natasha Jones, Eli Saetnan, and Richard Webster. 2023. <span>“Google Earth Engine Climate Tool (GEEClimT): Enabling Rapid, Easy Access to Global Climate Reanalysis Data.”</span> <a href="https://doi.org/10.5194/egusphere-egu23-7760">https://doi.org/10.5194/egusphere-egu23-7760</a>.
</div>
<div id="ref-lechner2022" class="csl-entry" role="listitem">
Lechner, Michael, Alena Dostálová, Markus Hollaus, Clement Atzberger, and Markus Immitzer. 2022. <span>“Combination of Sentinel-1 and Sentinel-2 Data for Tree Species Classification in a Central European Biosphere Reserve.”</span> <em>Remote Sensing</em> 14 (11): 2687. <a href="https://doi.org/10.3390/rs14112687">https://doi.org/10.3390/rs14112687</a>.
</div>
<div id="ref-nia" class="csl-entry" role="listitem">
Nia, Vahid Partovi, Guojun Zhang, Ivan Kobyzev, Michael R. Metel, Xinlin Li, Ke Sun, Sobhan Hemati, et al. n.d. <span>“Mathematical Challenges in Deep Learning.”</span> <a href="https://doi.org/10.48550/arXiv.2303.15464">https://doi.org/10.48550/arXiv.2303.15464</a>.
</div>
<div id="ref-pham-duc2023" class="csl-entry" role="listitem">
Pham-Duc, Binh, Ho Nguyen, Hien Phan, and Quan Tran-Anh. 2023. <span>“Trends and Applications of Google Earth Engine in Remote Sensing and Earth Science Research: A Bibliometric Analysis Using Scopus Database.”</span> <em>Earth Science Informatics</em> 16 (3): 2355–71. <a href="https://doi.org/10.1007/s12145-023-01035-2">https://doi.org/10.1007/s12145-023-01035-2</a>.
</div>
<div id="ref-ritika" class="csl-entry" role="listitem">
Ritika, Prasai. n.d. <span>“Earth Engine Application to Retrieve Long-Term Terrestrial and Aquatic Time Series of Satellite Reflectance Data.”</span> <em>International Journal of Multidisciplinary Research and Growth Evaluation</em>.
</div>
<div id="ref-shaveta2023" class="csl-entry" role="listitem">
Shaveta. 2023. <span>“A Review on Machine Learning.”</span> <em>International Journal of Science and Research Archive</em> 9 (1): 281–85. <a href="https://doi.org/10.30574/ijsra.2023.9.1.0410">https://doi.org/10.30574/ijsra.2023.9.1.0410</a>.
</div>
<div id="ref-tamiminia2020" class="csl-entry" role="listitem">
Tamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and B. Brisco. 2020. <span>“Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.”</span> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, May. <a href="https://doi.org/10.1016/j.isprsjprs.2020.04.001">https://doi.org/10.1016/j.isprsjprs.2020.04.001</a>.
</div>
<div id="ref-wu2020" class="csl-entry" role="listitem">
Wu, A., and X. Xiong. 2020. <span>“Sensors, Systems, and Next-Generation Satellites XXIV.”</span> In, 11530:267–77. SPIE. <a href="https://doi.org/10.1117/12.2573018">https://doi.org/10.1117/12.2573018</a>.
</div>
<div id="ref-xu2022" class="csl-entry" role="listitem">
Xu, Fei, Stien Heremans, and Ben Somers. 2022. <span>“Urban Land Cover Mapping with Sentinel-2: A Spectro-Spatio-Temporal Analysis.”</span> <em>Urban Informatics</em> 1 (1): 8. <a href="https://doi.org/10.1007/s44212-022-00008-y">https://doi.org/10.1007/s44212-022-00008-y</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Week_4.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week_4</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Week_7.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_7</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>