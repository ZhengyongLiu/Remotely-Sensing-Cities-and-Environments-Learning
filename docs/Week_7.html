<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Remote sensing learning Diary - 7&nbsp; Week_7 Classification I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Week_8.html" rel="next">
<link href="./Week_6.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Week_7.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_7 Classification I</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Remote sensing learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">About Me</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week_1 Intro to Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Week_2 Presentation of Snetinel-5p</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week_3 Corrections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week_4 Flooding Issues In Dublin</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_6 Intro to GEE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_7.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_7 Classification I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Week_8 Classification II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week_9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Week_9 SAR</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#knowledge-from-the-lecture" id="toc-knowledge-from-the-lecture" class="nav-link active" data-scroll-target="#knowledge-from-the-lecture"><span class="header-section-number">7.1</span> <strong>Knowledge From the Lecture</strong></a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">7.5</span> <strong>Reference</strong></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Week_7 Classification I</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="knowledge-from-the-lecture" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="knowledge-from-the-lecture"><span class="header-section-number">7.1</span> <strong>Knowledge From the Lecture</strong></h2>
<div style="text-align: justify;">
<section id="classification-and-regression-trees-cart" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="classification-and-regression-trees-cart"><span class="header-section-number">7.1.1</span> Classification and regression trees (CART)</h3>
<section id="classification" class="level4" data-number="7.1.1.1">
<h4 data-number="7.1.1.1" class="anchored" data-anchor-id="classification"><span class="header-section-number">7.1.1.1</span> Classification</h4>
<p>Classification trees are used to categorise data into two or more discrete categories Regression trees deal with situations where linear regression does not apply Improve the predictive power of the model by splitting the data into smaller chunks When creating a decision tree, the final leaf nodes may be a mixture of categories (impurity) and the Gini impurity is used to quantify this impurity. Select the attribute with the lowest impurity as the top of the tree to begin the decision process. Calculate the Gini impurity and use it to assess the quality of the data segmented when constructing the decision tree, with smaller values indicating purer data</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/Land Cover Classification in GEE.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Land Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition, Source: <a href="https://www.mdpi.com/2072-4292/12/15/2411"><span class="citation" data-cites="phan2020">(</span></a><a href="#ref-phan2020" role="doc-biblioref">Phan, Kuch, and Lehnert 2020</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="regression-trees" class="level4" data-number="7.1.1.2">
<h4 data-number="7.1.1.2" class="anchored" data-anchor-id="regression-trees"><span class="header-section-number">7.1.1.2</span> Regression trees</h4>
<p>Regression trees predict continuous values, such as the amount of pollution, while classification trees predict discrete values, such as land cover type. When linear regression does not fit the data well, regression trees are recommended as an alternative. In a regression tree, the data is divided into multiple parts based on thresholds or nodes. The sum of squared residuals (SSR) of these parts is calculated and the threshold with the lowest SSR becomes the starting point or root of the tree. The process can be repeated to further segment the data, and a minimum number of observations can be set to prevent overfitting.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/Unsupervised-decision-tree-classification-procedure-in-Google-Earth-Engine-performed-for.ppm" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Tree classification procedure in Google Earth Engine, Source: <a href="https://www.researchgate.net/publication/334404370_Trends_in_the_Seaward_Extent_of_Saltmarshes_across_Europe_from_Long-Term_Satellite_Data"><span class="citation" data-cites="laengner2019">(</span></a><a href="#ref-laengner2019" role="doc-biblioref">Laengner, Siteur, and Wal 2019</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="overfitting" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="overfitting"><span class="header-section-number">7.1.2</span> Overfitting</h3>
<p>If a leaf node contains only one person or one pixel value, overfitting may occur. The best models have low bias and low variability and are able to make consistent predictions across different datasets (e.g., training and test sets). To prevent overgrowth of the decision tree, its methods include limiting the growth of the tree (e.g., a leaf contains at least 20 pixels), and weakest link pruning (pruning based on the tree score). The number of leaves per tree and the value of α (regularisation parameter) were adjusted to reduce overfitting. Starting from α = 0, the α values were gradually increased until the pruning could reduce the tree score, and then these α values were saved. The tree score is the sum of squared residuals (SSR) plus the tree penalty (α multiplied by the number of leaves T). Different α values produce different subtrees and tree scores. Use different values of α to train the data and calculate the SSR on the test data to select the tree with the smallest score. Repeat the above process with cross-validation (10 cross validations) so as to find the α value that on average has the lowest SSR on the test data. The tree corresponding to this α-value, trained using all the data, is then selected. For classification trees, the SSR will be replaced by an impurity metric (e.g., Gini impurity).</p>
</section>
<section id="random-tress" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="random-tress"><span class="header-section-number">7.1.3</span> Random Tress</h3>
<p>A random forest consists of a number of categorical decision trees that are constructed by self-sampling the data (bootstrap samples) and constructing decision trees from randomly selected variables. At the nodes, the algorithm again selects from a random subset of variables. This process is repeated over and over again, resulting in multiple trees, or a “forest”. As new data passes through these trees, each tree gives a prediction, and the one with the most votes is chosen as the final prediction. The “bagging” technique in Random Forest is self-sampling by replacing data. Each tree is trained using approximately 70% of the training data, and the remaining 30% is called out-of-bag (OOB) data. The out-of-bag data is used to test the forest to evaluate the performance of the model and finally the classification result with the most votes is selected. The percentage of classification errors for out-of-bag data is known as OOB error. No pruning is done in a random forest and the tree can grow as much as possible. The out-of-bag error is derived by calculating the average prediction error for all trees that do not use certain values (e.g., rows in the data). Validation data, unlike out-of-bag data, is never included in the construction of the decision tree.</p>
</section>
<section id="how-to-apply-to-the-imagery" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="how-to-apply-to-the-imagery"><span class="header-section-number">7.1.4</span> How to apply to the imagery</h3>
<p>Two main approaches to image classification: supervised learning and unsupervised learning. Supervised learning learns from data and labels new data through machine learning pattern recognition, while unsupervised learning analyses undefined data through clustering and then labels these clusters.</p>
<p>Supervised Learning:</p>
<ol type="1">
<li>Generic of supervised learning basically follows the process includes: category definition, preprocessing, training, pixel assignment and accuracy assessment.</li>
</ol>
<p>Unsupervised Learning:</p>
<ol type="1">
<li>The DBSCAN algorithm, which forms clusters by setting a radius (Epsilon) and a minimum number of points, and can be optimised by iteration and PCA.</li>
<li>The ISODATA algorithm, a variant of k-means, which adds the ability to merge clusters that are too close together or to split clusters that are too long, and controls the clustering process according to the number of pixels in the cluster, the number of iterations, etc. 3. the “Cluster busting” algorithm, which forms clusters by setting a radius (Epsilon) and a minimum number of points.</li>
<li>The “Cluster busting” method, which improves classification accuracy by masking and reclassifying clusters that are difficult to label or incorrectly labelled.</li>
</ol>
<p><strong>Maximum likelihood</strong></p>
<p>Maximum likelihood &amp; Support Vector Machine Maximum Likelihood Estimation (MLE) is a statistical method for estimating parameters in probabilistic models. The basic idea of the method is to select the parameter value that best explains the observed data from all possible parameter values. In remote sensing, for example, it uses probabilities to assign each pixel in an image to the most likely land cover type, and probability thresholds can be set to determine whether or not to classify it.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/Maximum likelihood classifier.pbm" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Maximum likelihood classifier, Source: <a href="https://www.researchgate.net/figure/Maximum-likelihood-classifier-Source-adapted-from-59_fig2_331160604"><span class="citation" data-cites="núñez2019">(</span></a><a href="#ref-núñez2019" role="doc-biblioref">Núñez et al. 2019</a>)</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Support Vector Machine</strong></p>
<p>Support Vector Machine (SVM) is a supervised learning model used for classification and regression analysis. Suppose we have a training dataset in which each data point belongs to one of two classes.The goal of the SVM is to find a hyperplane such that the hyperplane separates the two classes of data points as much as possible.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/SVM example of linearly separable data.png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">SVM example of linearly separable data, Source: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206124"><span class="citation" data-cites="sheykhmousa2020">(</span></a><a href="#ref-sheykhmousa2020" role="doc-biblioref">Sheykhmousa and Mahdianpari 2020</a>)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="practical" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="practical"><span class="header-section-number">7.2</span> <strong>Practical</strong></h2>
<section id="supervised-classification" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="supervised-classification"><span class="header-section-number">7.2.1</span> Supervised Classification</h3>
<p>Select a Study Area, select the training feature collections on the map, in the following figure selected forest, water,developed,herbaceous as the collect feature.Use ee.Classifier.smileCart) and train it. But the result is not very good, maybe the initial data set selection is not very good.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/Supervised trained Classification .png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Supervised trained Classification Result</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="unsupervised-classification" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="unsupervised-classification"><span class="header-section-number">7.2.2</span> Unsupervised Classification</h3>
<p>Same result of Unsupervised trained Classification</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Figure/Week_7/Unsupervised trained Classification .png" class="img-fluid figure-img" style="width:110.0%"></p>
<figcaption class="figure-caption">Unsupervised trained Classification Result</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="application" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="application"><span class="header-section-number">7.3</span> <strong>Application</strong></h2>
<p>The roots of remote sensing machine learning can be traced back to the 1990s. It was initially introduced as an approach to remote sensing for automated knowledge infrastructure building. Since then it has evolved and found applications in a variety of fields, including remote sensing and geoscience<span class="citation" data-cites="challa2022">(<a href="#ref-challa2022" role="doc-biblioref">Challa, Sridhar, and Shyam Mohan 2022</a>)</span>. Machine learning algorithms such as deep learning are popular in remote sensing due to their ability to analyse large amounts of data and achieve high accuracy<span class="citation" data-cites="jeon2023">(<a href="#ref-jeon2023" role="doc-biblioref">Jeon 2023</a>)</span>. These algorithms have been used for tasks such as image classification, scene understanding and material recognition<span class="citation" data-cites="rewhel2023">(<a href="#ref-rewhel2023" role="doc-biblioref">Rewhel et al. 2023</a>)</span>. The availability of datasets with domain-specific attributes further facilitates the application of machine learning techniques in remote sensing.</p>
<p>The popularity of the Random Forest algorithm in the remote sensing community is attributed to its excellent classification accuracy. The algorithm utilises an integrated classifier consisting of multiple decision trees to effectively deal with high-dimensional data, and especially excels in reducing the dimensionality of hyperspectral data, thanks to the variable importance scores it provides<span class="citation" data-cites="bahrami2018">(<a href="#ref-bahrami2018" role="doc-biblioref">Bahrami, Hassani, and Maghsoudi 2018</a>)</span>. I believe that Random Forest is efficient because it incorporates the judgement of numerous decision trees to improve the overall accuracy by aggregating their predictions and adapting to the complexity and diversity of remote sensing data.</p>
<p>Support Vector Machines (SVMs) are particularly suitable for dealing with classification problems, distinguishing categories by defining optimal hyperplanes in high-dimensional spaces. It has demonstrated its strong performance in applications such as classification of multispectral remote sensing images<span class="citation" data-cites="feizi2022">(<a href="#ref-feizi2022" role="doc-biblioref">Feizi and Nazemi 2022</a>)</span>.The ability of SVM to deal with nonlinear and high-dimensional data is particularly well suited to the needs of the remote sensing domain, but its optimal performance relies on accurate kernel function selection and parameter tuning.</p>
<p>Overfitting is a problem that occurs when model complexity is too high, causing the model to memorise noise in the training data rather than regularities. While such a model is effective on the training set, it may not generalise to new data. Strategies to avoid overfitting include using appropriate dataset sizes, simplifying model complexity, and employing methods such as cross-validation to ensure that models generalise well<span class="citation" data-cites="schmidt">(<a href="#ref-schmidt" role="doc-biblioref">Schmidt, n.d.</a>)</span>. Understanding the limitations of the model and continuously monitoring its predictive ability on new data during training are key to avoiding overfitting.</p>
</section>
<section id="reflection" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="reflection"><span class="header-section-number">7.4</span> <strong>Reflection</strong></h2>
<p>Reviewing this week’s learning diary on remote sensing, I found the exploration of classification trees and regression trees (CART) particularly enlightening. The distinction between classification trees, which categorize data into discrete sets, and regression trees, which predict continuous values, is a fundamental concept that resonates with me. The application of the Gini impurity measure in the improved classification tree decision process highlights the importance of data purity and precision in environmental analysis, which I had not fully appreciated before.</p>
<p>The discussion of overfitting is equally crucial, illustrating the delicate balance needed to avoid creating overly complex models. The strategies mentioned, such as limiting tree growth or applying the weakest link pruning, are practical solutions that I could envision applying in future projects to improve model reliability.</p>
<p>The introduction of random forests expanded my understanding of set learning techniques. This approach combines multiple decision trees, improves prediction accuracy and controls overfitting, and demonstrates the power of collective intelligence over a single predictive model, which is fascinating.</p>
<p>Applying these concepts to images, especially through supervised and unsupervised learning, is the most fascinating part. Practical examples, such as the use of random forest classifiers in Google Earth Engine, give us a first-hand sense of the potential of remote sensing in environmental analysis. It’s curious to think about the wide range of applications these methods have, from land cover classification to pollution monitoring.</p>
<p>This week’s diary reveals the multifaceted nature of remote sensing and machine learning, giving me a greater appreciation of their role in understanding and protecting the environment. The evolving nature of these technologies, and their potential to have a profound impact on real-world issues, is incredibly motivating.</p>
</section>
</div>
</section>
<section id="reference" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="reference"><span class="header-section-number">7.5</span> <strong>Reference</strong></h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-bahrami2018" class="csl-entry" role="listitem">
Bahrami, Yousef, Hossein Hassani, and Abbas Maghsoudi. 2018. <span>“Investigating the Capabilities of Multispectral Remote Sensors Data to Map Alteration Zones in the Abhar Area, NW Iran.”</span> <em>Geosystem Engineering</em> 24 (December): 1–13. <a href="https://doi.org/10.1080/12269328.2018.1557083">https://doi.org/10.1080/12269328.2018.1557083</a>.
</div>
<div id="ref-challa2022" class="csl-entry" role="listitem">
Challa, Nagendra Panini, Parupally Sridhar, and J. S. Shyam Mohan. 2022. <span>“A Machine Learning Perspective for Remote Sensing.”</span> In, edited by Pala Gireesh Kumar, Kolluru V. L. Subramaniam, S. Moses Santhakumar, and Neelima Satyam D., 553–59. Lecture Notes in Civil Engineering. Singapore: Springer Nature. <a href="https://doi.org/10.1007/978-981-19-0189-8_45">https://doi.org/10.1007/978-981-19-0189-8_45</a>.
</div>
<div id="ref-feizi2022" class="csl-entry" role="listitem">
Feizi, Amir, and Alireza Nazemi. 2022. <span>“Classifying Random Variables Based on Support Vector Machine and a Neural Network Scheme.”</span> <em>Journal of Experimental &amp; Theoretical Artificial Intelligence</em> 0 (0): 1–24. <a href="https://doi.org/10.1080/0952813X.2022.2104385">https://doi.org/10.1080/0952813X.2022.2104385</a>.
</div>
<div id="ref-jeon2023" class="csl-entry" role="listitem">
Jeon, Gwanggil. 2023. <span>“Advanced Machine Learning and Deep Learning Approaches for Remote Sensing.”</span> <em>Remote Sensing</em> 15 (11): 2876. <a href="https://doi.org/10.3390/rs15112876">https://doi.org/10.3390/rs15112876</a>.
</div>
<div id="ref-laengner2019" class="csl-entry" role="listitem">
Laengner, Marieke, Koen Siteur, and Daphne Wal. 2019. <span>“Trends in the Seaward Extent of Saltmarshes Across Europe from Long-Term Satellite Data.”</span> <em>Remote Sensing</em> 11 (July): 1653. <a href="https://doi.org/10.3390/rs11141653">https://doi.org/10.3390/rs11141653</a>.
</div>
<div id="ref-núñez2019" class="csl-entry" role="listitem">
Núñez, Juan Manuel, Sandra Medina-Fernández, F. Gerardo Ávila, and Jorge Montejano. 2019. <span>“High-Resolution Satellite Imagery Classification for Urban Form Detection.”</span> In, 1–9. <a href="https://doi.org/10.5772/intechopen.82729">https://doi.org/10.5772/intechopen.82729</a>.
</div>
<div id="ref-phan2020" class="csl-entry" role="listitem">
Phan, Thanh Noi, Verena Kuch, and Lukas W. Lehnert. 2020. <span>“Land Cover Classification Using Google Earth Engine and Random Forest Classifier<span></span>The Role of Image Composition.”</span> <em>Remote Sensing</em> 12 (15): 2411. <a href="https://doi.org/10.3390/rs12152411">https://doi.org/10.3390/rs12152411</a>.
</div>
<div id="ref-rewhel2023" class="csl-entry" role="listitem">
Rewhel, Ekram M., Jianqiang Li, Amal A. Hamed, Hatem M. Keshk, Amira S. Mahmoud, Sayed A. Sayed, Ehab Samir, et al. 2023. <span>“Deep Learning Methods Used in Remote Sensing Images: A Review.”</span> <em>Journal of Environmental &amp; Earth Sciences</em> 5 (1): 33–64. <a href="https://doi.org/10.30564/jees.v5i1.5232">https://doi.org/10.30564/jees.v5i1.5232</a>.
</div>
<div id="ref-schmidt" class="csl-entry" role="listitem">
Schmidt, James. n.d. <span>“Testing for Overfitting.”</span> <a href="https://doi.org/10.48550/arXiv.2305.05792">https://doi.org/10.48550/arXiv.2305.05792</a>.
</div>
<div id="ref-sheykhmousa2020" class="csl-entry" role="listitem">
Sheykhmousa, Reza M, and Masoud Mahdianpari. 2020. <span>“Support Vector Machine Vs. Random Forest for Remote Sensing Image Classification: A Meta-Analysis and Systematic Review.”</span> <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, October. <a href="https://doi.org/10.1109/JSTARS.2020.3026724">https://doi.org/10.1109/JSTARS.2020.3026724</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Week_6.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week_6 Intro to GEE</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Week_8.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Week_8 Classification II</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>