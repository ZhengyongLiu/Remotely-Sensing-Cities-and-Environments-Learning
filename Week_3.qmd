---
title: "Week_3"
---

## **Knowledge gain From the Lecture**

::: {style="text-align: justify;"}
This week's study focuses on remote sensing image processing, with the main areas of interest being geometric corrections, atmospheric corrections, orthometric corrections, radiometric corrections and various image enhancement techniques.
:::

### Correction

#### Geometric Correction

::: {style="text-align: justify;"}
Geometric correction is the basis of image correction and addresses image distortion due to sensor and other factors. The goal of this correction is to make the image conform to the selected map projection system, adjusting the geometry of the entire image by modelling the relationship between control points (points with known geographic coordinates) on the image and the image coordinates.
:::

```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='How Geometric Correction Work, Source: <a href="https://www.semanticscholar.org/paper/A-Geometric-Correction-Method-of-Plane-Image-Based-Xiaopeng-Leilei/0d46695027b1a9bab5c88c1c0e822760f31d23e6">Xiaopeng</a>'}
knitr::include_graphics('Figure/Week_3/Geometric correction.png')
```
::: {style="text-align: justify;"}
Based on the above calibration process, it can be done by the following equation
For a point \((x, y)\) in the distorted image, the corresponding point \((x', y')\) in the geometrically corrected image can be calculated using:

$$
x' = a_0 + a_1 x + a_2 y + a_3 x^2 + a_4 xy + a_5 y^2 + \ldots
$$
$$
y' = b_0 + b_1 x + b_2 y + b_3 x^2 + b_4 xy + b_5 y^2 + \ldots
$$

Here, \(a_0, a_1, \ldots, a_n\) and \(b_0, b_1, \ldots, b_n\) are coefficients determined through a calibration process using ground control points (GCPs), which are points whose true position is known. The number of terms in the polynomial (and thus the number of coefficients) depends on the degree of the polynomial required to model the distortion adequately. A first-degree polynomial correction (affine transformation) would not include the squared terms, for example.
:::

#### Atmospheric Correction

::: {style="text-align: justify;"}
Atmospheric corrections are essential to address distortions and inaccuracies in remotely sensed images caused by variations in the Earth's atmosphere, sensor angles, and terrain. Several different correction methods were learned in class: **Relative Atmospheric Correction**, **Pseudo-Invariant Correction**, **Absolute Atmospheric Correction**, and **Empirical Line Correction**.
:::

The different methods and characteristics of atmospheric correction have been summarised in the table below:

| Method               | Key Steps                                                     | Feature                                             |
|-------------------|----------------------------|--------------------------|
| **Relative**         | Spectrally stable landmarks, linear relations, band operation | Consistency between images                          |
| **Absolute**         | Complex models for atmospheric effects, surface reflectance   | Precise, accurate surface information               |
| **Pseudo-Invariant** | High-quality reference, PIF, linear regression                | Stable reference points, reduce atmospheric effects |
| **Empirical Line**   | Ground reflectance, average DN values, linear regression      | Utilizes ground data for satellite correction       |

#### Radiometric Correction

::: {style="text-align: justify;"}
The role of radiometric correction in adjusting the pixel values of satellite imagery to accurately reflect the radiation at the Earth's surface has been investigated. The main objective of radiometric correction is to convert the raw digital numbers (DN) acquired into physically meaningful units such as radiance or reflectance. This conversion is critical because DN values are arbitrary and can vary between sensors, acquisitions and platforms, making it difficult to consistently compare and analyse data. By converting DN values to radiance or reflectance, radiometric correction enables quantitative measurements and meaningful comparisons between different images and sensors.
:::

```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='Process of Radiometric Calibration'}
knitr::include_graphics('Figure/Week_3/Process of Radiometric Calibration.png')
```

#### Reflection of Collerallation

::: {style="text-align: justify;"}
In the course of study, certain questions arise as to when atmospheric corrections are needed and whether or not the images we buy or otherwise acquire have been atmospherically corrected. In layman's terms, if we need to use an image that truly reflects the Sun's radiation for quantitative inversion or to obtain information about the Earth, accurately identify features, etc., then we need to make an atmospheric correction. When we buy an image, the description document says that it is radiometrically corrected. In fact, this radiometric correction refers to the coarse radiometric correction, which is just a systematic atmospheric correction, which has the same meaning as the systematic geometric correction.

At the moment there are many models and methods on the market, since there are how many methods, then there is the problem of method selection. Here is a summary for reference:

1.  if it is a fine quantitative study, then choose the atmospheric correction method based on the radiative transfer model.
2.  if you are doing dynamic monitoring, then you can choose relative atmospheric correction or simpler methods.
3.  if the parameters are missing, there is no choice but to choose the simpler method.
:::

### Data Join Sets/Enhancement

#### Data Join Sets
::: {style="text-align: justify;"}
An area may need more than one satellite image to be spliced, using mosaic in the R package for the two datasets to be spliced. When selecting images, try to select two images with similar time and date, due to the different date of the image, the image display is different, the reason may be (cloud cover, sunshine), need to use the image increase technique to operate.
:::
### Enhancement

#### Ratio
::: {style="text-align: justify;"}
The ratio is the difference between two spectral bands with a specific spectral response, using CampTown's data for NDVI (The Normalised Difference Vegetation Index) The Normalised Difference Vegetation Index is based on the fact that healthy and green vegetation reflects more in the near infrared but absorbs in the red wavelengths. Therefore, the red wavelength band is used for the operation in the formula below.
$$
NDVI = \frac{NIR - Red}{NIR + Red}
$$


The following figure shows the image after manipulation for NDVI (a. After NDVI Formula, b. Extraction only if NDVI is equal to or greater than 0.2)
:::
```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='Process of Radiometric Calibration'}
knitr::include_graphics('Figure/Week_3/NDVI.png')
```

#### Texture (Unfinished)
::: {style="text-align: justify;"}
Due to the limitations of R, it takes a long time to run if the map is loaded too large, so only a small part of CampTown was selected for processing. Most of the area can be loaded in Google Earth Engine afterwards. Below is the texture processed study area.
:::

```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='Process of Radiometric Calibration'}
knitr::include_graphics('Figure/Week_3/Texture.png')
```

#### Principal Component Analysis (Unfinished)
```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='Process of Radiometric Calibration'}
knitr::include_graphics('Figure/Week_3/Principal Component Analysis.png')
```

```{r  echo=FALSE, out.width='110%', fig.align='center', fig.cap='Process of Radiometric Calibration'}
knitr::include_graphics('Figure/Week_3/Principal Component Analysis result.png')
```
### Other Enhancement

| Technique                          | Description                                                      | Application                                                      |
|-------------------|---------------------------|---------------------------|
| Low Pass Filter                    | Smoothes image by averaging pixels.                              | Reduces noise for better burn area detection.                    |
| High Pass Filter                   | Enhances contrast by highlighting local changes.                 | Improves distinction between burned/unburned areas.              |
| Embossing                          | Modifies coefficients to create shadowy edge relief.             | Highlights burn area edges for clearer boundaries.               |
| Principal Component Analysis (PCA) | Transforms multispectral data to smaller, uncorrelated datasets. | Simplifies data for easier burn area analysis in Landsat images. |
| Multi-date PCA                     | Combines different time point bands for PCA.                     | Identifies temporal changes in burn areas across Landsat images. |
| Texture Analysis                   | Analyzes spatial variation in grayscale.                         | Enhances burn area detection through texture metrics.            |
| Image Fusion                       | Merges data from multiple sources/sensors.                       | Integrates different resolutions for more detailed analysis.     |

## Application in Literature (Unfinished)

These methodologies have wide applications in geospatial science literature, particularly in environmental monitoring, land use mapping, and disaster assessment. Atmospheric correction techniques are essential in longitudinal studies using satellite data, ensuring consistency across different times and conditions. Image enhancements are particularly vital in extracting detailed information from remote sensing data, contributing to more accurate and reliable interpretations in various research areas.

Geometric corrections are commonly applied in studies involving spatial accuracy, while orthorectification is used extensively in mapping applications. Radiometric calibration's role in ensuring data accuracy over different periods is crucial in change detection and environmental studies. Overall, these techniques are fundamental to the field of geospatial sciences, enabling the extraction of meaningful and accurate information from raw satellite data.

## Personal Reflection (Unfinished)

The depth of knowledge gained from this course has been profound. Understanding the technical aspects of image correction and enhancement has provided a clear perspective on the importance and complexity of these processes in remote sensing. It's intriguing to see how various correction techniques can significantly improve the quality of satellite imagery, leading to more reliable data interpretation.

The potential of these techniques in addressing global challenges, such as environmental monitoring and disaster management, is particularly inspiring. The course has deepened my appreciation for the field of geospatial sciences and its impact on our understanding of the Earth.
